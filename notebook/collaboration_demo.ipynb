{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orpe import ProvenanceExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = ProvenanceExplorer(\"../collaborative_demo_t1.openrefine.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = ProvenanceExplorer(\"../collaborative_demo_t2.openrefine.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "['state_1', 'col0_0', 'col0_1', 'state_2', 'col1_0', 'col1_1', 'state_3', 'col2_0', 'col2_1', 'state_4', 'col1_2', 'state_5', 'col5_0', 'col4_0', 'state_6', 'col4_1', 'state_7', 'col5_1', 'state_9', 'col2_2']\n"
     ]
    }
   ],
   "source": [
    "parallel_workflow = op1.parallel_workflow()\n",
    "process_nodes,parallel_graph,gv_string = op1.gv_template(parallel_workflow)\n",
    "print(parallel_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col0_0', 'col1_0', 'col2_0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('col0_0', 'col0_1')\n",
      "('col1_0', 'col4_1')\n",
      "('col1_0', 'col5_1')\n",
      "('col2_0', 'col2_2')\n",
      "('col0_0', 'col0_1')\n",
      "('col1_0', 'col4_1')\n",
      "('col1_0', 'col5_1')\n",
      "('col2_0', 'col2_2')\n"
     ]
    }
   ],
   "source": [
    "# source to sink comparison\n",
    "ps1 = []\n",
    "for ss in source_nodes:\n",
    "    pt = op1.parallel_state(parallel_graph,ss)\n",
    "    #print(pt)\n",
    "    ps1.append(pt)\n",
    "\n",
    "ps2 = []\n",
    "pw2 = op2.parallel_workflow()\n",
    "pn2,pg2,gv2 = op2.gv_template(parallel_workflow)\n",
    "sn2 = [node for node, indegree in dict(pg2.in_degree(pg2.nodes())).items() if indegree == 0]\n",
    "for ss in sn2:\n",
    "    pt = op1.parallel_state(parallel_graph,ss)\n",
    "    #print(pt)\n",
    "    ps2.append(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS0:  [[{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Book Title', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"}]]\n",
      "PS1:  [(['state_1'], ['col0_0', 'col0_1'])]\n",
      "DFS: ['state_1']\n",
      "PS0:  [[{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"}, {'op': 'core/mass-edit', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': 'value', 'edits': [{'from': [' P. Kyle Stanford'], 'fromBlank': False, 'fromError': False, 'to': 'Stanford, P. Kyle'}], 'description': 'Mass edit cells in column Author'}, {'op': 'core/column-split', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'guessCellType': True, 'removeOriginalColumn': False, 'mode': 'separator', 'separator': ',', 'regex': False, 'maxColumns': 0, 'description': 'Split column Author by separator'}, {'op': 'core/column-rename', 'oldColumnName': 'Author 1', 'newColumnName': 'Last Name', 'description': 'Rename column Author 1 to Last Name'}], [{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"}, {'op': 'core/mass-edit', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': 'value', 'edits': [{'from': [' P. Kyle Stanford'], 'fromBlank': False, 'fromError': False, 'to': 'Stanford, P. Kyle'}], 'description': 'Mass edit cells in column Author'}, {'op': 'core/column-split', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'guessCellType': True, 'removeOriginalColumn': False, 'mode': 'separator', 'separator': ',', 'regex': False, 'maxColumns': 0, 'description': 'Split column Author by separator'}, {'op': 'core/column-rename', 'oldColumnName': 'Author 2', 'newColumnName': 'First Name', 'description': 'Rename column Author 2 to First Name'}]]\n",
      "PS1:  [(['state_2', 'state_4', 'state_5', 'state_6'], ['col1_0', 'col1_1', 'col1_2', 'col4_0', 'col4_1']), (['state_2', 'state_4', 'state_5', 'state_7'], ['col1_0', 'col1_1', 'col1_2', 'col5_0', 'col5_1'])]\n",
      "DFS: ['state_2', 'state_4', 'state_5', 'state_6', 'state_7']\n",
      "PS0:  [[{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"}, {'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': 'value.toNumber()', 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': 'Text transform on cells in column Date using expression value.toNumber()'}]]\n",
      "PS1:  [(['state_3', 'state_9'], ['col2_0', 'col2_1', 'col2_2'])]\n",
      "DFS: ['state_3', 'state_9']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "all_par = []\n",
    "all_col = []\n",
    "for ps in ps1:\n",
    "    print(\"PS0: \",ps[0])\n",
    "    print(\"PS1: \",ps[1])\n",
    "    ps_dag = nx.DiGraph()\n",
    "    ps_node = nx.DiGraph()\n",
    "    for psd in ps[1]:\n",
    "        #print(psd)        \n",
    "        for i,psx in enumerate(psd[0][:-1]):\n",
    "            ps_dag.add_edge(psd[0][i],psd[0][i+1])\n",
    "        for i,psx in enumerate(psd[1][:-1]):\n",
    "            ps_node.add_edge(psd[1][i],psd[1][i+1])            \n",
    "        if len(psd[0])==1:\n",
    "            ps_dag.add_node(psd[0][0])\n",
    "    mutual_states = []\n",
    "    mutual_nodes = []\n",
    "    if len(ps_dag.edges)>0:\n",
    "        for dfs in list(nx.dfs_edges(ps_dag)):\n",
    "            if dfs[0] not in mutual_states:\n",
    "                mutual_states.append(dfs[0])\n",
    "            if dfs[1] not in mutual_states:\n",
    "                mutual_states.append(dfs[1])\n",
    "        print(\"DFS:\",mutual_states)\n",
    "        all_par.append(mutual_states)\n",
    "    else:\n",
    "        print(\"DFS:\",ps_dag.nodes)\n",
    "        all_par.append(list(ps_dag.nodes))\n",
    "    for dfs in list(nx.dfs_edges(ps_node)):\n",
    "        if dfs[0] not in mutual_nodes:\n",
    "            mutual_nodes.append(dfs[0])\n",
    "        if dfs[1] not in mutual_nodes:\n",
    "            mutual_nodes.append(dfs[1])    \n",
    "    all_col.append(mutual_nodes)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['state_1'],\n",
       "  ['state_2', 'state_4', 'state_5', 'state_6', 'state_7'],\n",
       "  ['state_3', 'state_9']],\n",
       " [['col0_0', 'col0_1'],\n",
       "  ['col1_0', 'col1_1', 'col1_2', 'col4_0', 'col4_1', 'col5_0', 'col5_1'],\n",
       "  ['col2_0', 'col2_1', 'col2_2']])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_par,all_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_values_state 8\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "get_values_state 7\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "get_values_state 5\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "get_values_state 4\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "             Author 1          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "get_values_state 3\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "get_values_state 2\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "get_values_state 6\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "get_values_state 0\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name          Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  (1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  (1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  (2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  (1992, 3, 2)    (2010-31-01, 3, 3)  \n"
     ]
    }
   ],
   "source": [
    "for x in all_par:\n",
    "    for y in x:\n",
    "        sid = int(y.split(\"state_\")[-1])\n",
    "        snapshot_pd = op1.get_snapshot_at_state(sid)\n",
    "        print(snapshot_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dcm\n",
    "import logging \n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class TransformDCM():\n",
    "    def __init__(self,trace):\n",
    "        self.trace = trace\n",
    "        self.source = []\n",
    "        self.dataset = []\n",
    "        self.state = []\n",
    "        self.array = []\n",
    "        self.column = []\n",
    "        self.row = []\n",
    "        self.cell = []\n",
    "        self.cell_values = []\n",
    "        self.column_position = []\n",
    "        self.row_position = []\n",
    "        \n",
    "        self.value_derived_from = []        \n",
    "        self.col_derived_from = []\n",
    "        self.state_derived_from = []\n",
    "        self.col_dependency = []\n",
    "        self.state_detail = []\n",
    "        \n",
    "        self.pd_index = None\n",
    "        \n",
    "        self.source_id = 0\n",
    "        self.dataset_id = 0\n",
    "        self.array_id = 0\n",
    "        self.col_id = 0\n",
    "        self.row_id = 0\n",
    "        self.cell_id = 0\n",
    "        self.value_id = 0\n",
    "        self.state_id = -1\n",
    "        self.col_pos_id = 0\n",
    "        self.row_pos_id = 0\n",
    "        \n",
    "        self.col_names_coll = set()\n",
    "        \n",
    "        \n",
    "        self.curr_df = None\n",
    "        self.curr_col = None\n",
    "        self.curr_row = None\n",
    "        self.curr_index = None\n",
    "        \n",
    "        self.curr_row_pos = {}\n",
    "        self.curr_col_pos = {}\n",
    "        self.curr_col_schema = []\n",
    "        self.curr_row_list = []\n",
    "        \n",
    "        self.curr_state = 0            \n",
    "        \n",
    "    \n",
    "    def render_curr_df(self):\n",
    "        pass\n",
    "    \n",
    "    def render_col(self):\n",
    "        pass\n",
    "    \n",
    "    def render_row(self):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def init_df(self,df):\n",
    "        self.pd_index = pd.DataFrame(np.empty(df.shape),dtype=object)    \n",
    "        self.col_names = df.columns\n",
    "        \n",
    "        for i,x in enumerate(df.to_records()):\n",
    "            jj = 0\n",
    "            #print(i)\n",
    "            for j,y in enumerate(x):\n",
    "                #print(j)\n",
    "                if j==0:\n",
    "                    continue\n",
    "                \n",
    "                self.cell.append((self.cell_id,jj,self.row_id))\n",
    "                self.cell_values.append((self.value_id,self.cell_id,self.state_id,y[0],-1))\n",
    "                #print(self.pd_index.loc[i,jj])\n",
    "                self.pd_index.loc[i,jj] = (self.cell_id,self.value_id,i,jj) \n",
    "                \n",
    "                self.value_derived_from.append((self.cell_id,self.state_id,-1))\n",
    "\n",
    "                self.cell_id+=1\n",
    "                self.value_id+=1\n",
    "                if i == 0:\n",
    "                    if jj == 0:\n",
    "                        prev_j = -1\n",
    "                    \n",
    "                    \n",
    "                    self.column.append((self.col_id,self.array_id))                    \n",
    "                    self.column_position.append((self.col_pos_id,self.col_id,self.state_id,self.col_names[jj],prev_j,-1))\n",
    "                    self.col_names_coll.add(self.col_names[jj])\n",
    "                    self.curr_col_schema.append((self.col_names[jj],jj,self.col_id,prev_j))\n",
    "                    self.curr_col_pos[self.col_id] = (self.col_pos_id,prev_j)\n",
    "                    prev_j = jj\n",
    "                    self.col_pos_id+=1                    \n",
    "                    self.col_id+=1    \n",
    "                jj+=1\n",
    "            if i == 0:\n",
    "                prev_i = -1\n",
    "                \n",
    "            self.row.append((self.row_id,self.array_id))            \n",
    "            self.row_position.append((self.row_pos_id,self.row_id,self.state_id,prev_i,-1))\n",
    "            self.curr_row_pos[self.row_id] = (self.row_pos_id,prev_i)\n",
    "            self.curr_row_list.append(self.row_pos_id)\n",
    "            prev_i = self.row_id\n",
    "            self.row_id+=1       \n",
    "            self.row_pos_id+=1            \n",
    "        \n",
    "        \"\"\"            \n",
    "        col_id = np.where(df.columns==col.name)[0][0]\n",
    "        columns.append((col_id,self.array_id))\n",
    "        #temp_col = []\n",
    "        for i,x in enumerate(col):\n",
    "            if not row_processed:\n",
    "                rows.append((i,array_id))\n",
    "            #temp_col.append((cell_id,col_id,i))\n",
    "            cells.append((cell_id,col_id,i))\n",
    "            cell_values.append((value_id,cell_id,state_id,x,-1))\n",
    "            pd_index.loc[i,col_id] = (cell_id,value_id,col_id,i)        \n",
    "            cell_id+=1\n",
    "            value_id+=1\n",
    "            #print(i,col_id)\n",
    "        row_processed = True        \n",
    "        \"\"\"\n",
    "    \n",
    "    def init_dataset(self,tt):\n",
    "        logging.debug(\"init dataset\")\n",
    "        # get filename from trace        \n",
    "        df = tt[5]\n",
    "        code = tt[6]\n",
    "        self.source.append((self.source_id,code,\"dataframe\"))\n",
    "        self.dataset.append((self.dataset_id,self.source_id))\n",
    "        self.array.append((self.array_id,self.dataset_id))\n",
    "        # state creation\n",
    "        \n",
    "        prev_state_id = self.state_id\n",
    "        self.state_id+=1        \n",
    "        self.state.append((self.state_id,prev_state_id))            \n",
    "        \n",
    "        # generate column, row, cell\n",
    "        self.init_df(df)\n",
    "        self.state_id+=1        \n",
    "\n",
    "        \n",
    "        #self.state_id+=1\n",
    "        #self.array_id+=1\n",
    "        #self.dataset_id+=1\n",
    "        #self.source_id+=1\n",
    "        \n",
    "    def init_dataset_df(self,df,state_ss={'op':\"initial\"},fname=None):\n",
    "        logging.debug(\"init dataset\")\n",
    "        self.source.append((self.source_id,fname,\"dataframe\"))\n",
    "        self.dataset.append((self.dataset_id,self.source_id))\n",
    "        self.array.append((self.array_id,self.dataset_id))\n",
    "        # state creation\n",
    "                \n",
    "        # generate column, row, cell\n",
    "        self.init_df(df)       \n",
    "\n",
    "        prev_state_id = self.state_id\n",
    "        self.state_id+=1\n",
    "        self.state.append((self.state_id,prev_state_id))\n",
    "        self.state_detail.append((prev_state_id,state_ss))\n",
    "    \n",
    "    def change_column_schema(self,prev_df,now_df):\n",
    "        #old_col = list(self.curr_col)  \n",
    "        old_col = list(prev_df.columns)\n",
    "        now_col = list(now_df.columns)\n",
    "        #logging.debug(now_df)\n",
    "        #logging.debug((\"old new col\",old_col,self.curr_col_schema,now_col))\n",
    "        new_col = set(now_col)-set(old_col)\n",
    "        ocol = set(old_col) - set(now_col)\n",
    "        \n",
    "        logging.debug((\"change_col_schema old_col\",old_col,self.curr_col_schema,now_col))\n",
    "        logging.debug((\"change_col_schema new_col\",new_col,ocol))\n",
    "        \n",
    "        old_schema = [x[0] for x in self.curr_col_schema]\n",
    "        \n",
    "        temp_new_col = []\n",
    "        \n",
    "        temp_prev = None\n",
    "        \n",
    "        logging.debug((\"change_col_schema old_schema:\",old_schema))\n",
    "                \n",
    "        for n_idx,x in enumerate(now_col):\n",
    "            logging.debug(\"change_col_schema now_col:\")\n",
    "            try:\n",
    "                idx_schema = old_schema.index(x)\n",
    "            except:\n",
    "                # check the potential column\n",
    "                for y in ocol:                    \n",
    "                    test = self.curr_df.loc[:,y].fillna(0) == now_df.loc[:,x].fillna(0)\n",
    "                    logging.debug((\"test\",test.sum(),self.curr_df.shape[0],self.curr_df,now_df))\n",
    "                    if test.sum() == self.curr_df.shape[0]:\n",
    "                        idx = old_col.index(y)\n",
    "                        prev_idx = (-1,None)\n",
    "                        logging.debug((\"idx_test\",idx))\n",
    "                        if idx > 0:\n",
    "                            prev_idx = old_col[idx-1]\n",
    "                            idx_n = now_col.index(x)\n",
    "                            now_idx = self.curr_col_schema[idx_n]\n",
    "                            prev_col_schema = (None,None,-1,None)\n",
    "                            if idx_n > 0:\n",
    "                                prev_col_schema = self.curr_col_schema[idx_n-1]\n",
    "                            logging.debug((\"change_col_schema now_idx:\",now_idx,prev_idx))\n",
    "                            self.column_position.append((self.col_pos_id,now_idx[-2],self.state_id,x,prev_col_schema[2],now_idx[1]))\n",
    "                            logging.debug((\"change_col_schema adding_col_pos1:\",(self.col_pos_id,now_idx[-2],self.state_id,x,n_idx-1,now_idx[2])))\n",
    "                            temp_new_col.append((x,self.col_pos_id,now_idx[2],now_idx[3]))\n",
    "                            #temp_new_col.append((x,self.col_pos_id,now_idx[2]))\n",
    "                            #temp_new_col.append((x,self.col_pos_id,-1))\n",
    "                            self.col_pos_id+=1  \n",
    "                            \n",
    "                            logging.debug((\"change_col_schema now_idx\",now_idx))\n",
    "                            self.col_dependency.append((self.state_id,now_idx[-2] if len(now_idx)==4 else now_idx[-1],now_idx[-2] if len(now_idx)==4 else now_idx[-1]))                                                                      \n",
    "                            break\n",
    "                continue\n",
    "                                        \n",
    "            old_schema_idx = self.curr_col_schema[idx_schema]\n",
    "            idx = idx_schema\n",
    "            #idx = old_col.index(x)\n",
    "            #prev_idx = (-1,None)\n",
    "            prev_idx = -1\n",
    "            prev_old_schema = (None,None,None,None)\n",
    "            if idx > 0:\n",
    "                prev_idx = idx - 1\n",
    "                prev_old_schema = self.curr_col_schema[prev_idx]            \n",
    "\n",
    "            prev_nidx = -1\n",
    "            prev_new_schema = (None,None,None,None)\n",
    "            if n_idx > 0:     \n",
    "                prev_nidx = n_idx - 1\n",
    "                prev_new_schema = temp_new_col[-1]\n",
    "                \n",
    "            #logging.debug((\"change_col_schema old\",n_idx,x,idx,prev_idx,self.curr_col_schema[idx_schema]))\n",
    "            #logging.debug((\"change_col_schema cur_col_schema:\",self.curr_col_schema[n_idx][0],x))\n",
    "            logging.debug((\"change_col_schema prev next:\",prev_old_schema,prev_new_schema))\n",
    "            \n",
    "            #if self.curr_col_schema[n_idx][0] != x:\n",
    "            if prev_old_schema[2] != prev_new_schema[2]:\n",
    "                #if prev_idx[1] != prev_nidx[1]: \n",
    "                #if prev_idx[0] != prev_nidx[1]:         \n",
    "                #logging.debug((\"tempnewcol:\",temp_new_col[n_idx-1], now_idx))\n",
    "                #if temp_new_col[n_idx-1][2] != now_idx[2]:\n",
    "                \"\"\"\n",
    "                if temp_new_col[n_idx-1][2] != now_idx[2]:\n",
    "                    idx_n = now_col.index(x)\n",
    "                    self.column_position.append((self.col_pos_id,now_idx[-2],self.state_id,x,temp_new_col[n_idx-1][2],now_idx[2]))\n",
    "                    logging.debug((\"adding_col_pos2:\",(self.col_pos_id,now_idx[-2],self.state_id,x,temp_new_col[n_idx-1][2],now_idx[2])))                            \n",
    "                    #temp_new_col.append((x,self.col_pos_id,now_idx[1],now_idx[2],temp_prev))\n",
    "                    temp_new_col.append((x,self.col_pos_id,now_idx[2],temp_prev))\n",
    "                    self.col_pos_id+=1\n",
    "                \"\"\"\n",
    "                self.column_position.append((self.col_pos_id,old_schema_idx[1],self.state_id,x,prev_new_schema[1],old_schema_idx[1]))\n",
    "                #logging.debug((\"adding_col_pos2:\",(self.col_pos_id,now_idx[-2],self.state_id,x,temp_new_col[n_idx-1][2],now_idx[2])))                            \n",
    "                #temp_new_col.append((x,self.col_pos_id,now_idx[1],now_idx[2],temp_prev))\n",
    "                temp_new_col.append((x,self.col_pos_id,old_schema_idx[1],prev_new_schema[1]))\n",
    "                self.col_pos_id+=1\n",
    "                #aaa\n",
    "            else:\n",
    "                 #temp_new_col.append((x,now_idx[1],now_idx[2],now_idx[3]))\n",
    "                temp_new_col.append(self.curr_col_schema[idx_schema])\n",
    "        \n",
    "        \n",
    "        logging.debug((\"change_col_schema temp_new_col:\",temp_new_col))\n",
    "        \n",
    "        self.curr_col_schema = temp_new_col\n",
    "                \n",
    "        return None\n",
    "        \n",
    "        for n_idx,x in enumerate(now_col):\n",
    "            try:\n",
    "                idx_schema = old_schema.index(x)\n",
    "            except:\n",
    "                # check the potential column\n",
    "                for y in ocol:                    \n",
    "                    test = self.curr_df.loc[:,y].fillna(0) == now_df.loc[:,x].fillna(0)\n",
    "                    logging.debug((\"test\",test.sum(),self.curr_df.shape[0],self.curr_df,now_df))\n",
    "                    if test.sum() == self.curr_df.shape[0]:\n",
    "                        idx = old_col.index(y)\n",
    "                        prev_idx = (-1,None)\n",
    "                        logging.debug((\"idx_test\",idx))\n",
    "                        if idx > 0:\n",
    "                            prev_idx = old_col[idx-1]\n",
    "                            idx_n = now_col.index(x)\n",
    "                            now_idx = self.curr_col_schema[idx_n]  \n",
    "                            logging.debug((\"now_idx:\",now_idx,prev_idx))\n",
    "                            self.column_position.append((self.col_pos_id,now_idx[-2],self.state_id,x,n_idx-1,now_idx[2]))\n",
    "                            logging.debug((\"adding_col_pos1:\",(self.col_pos_id,now_idx[-2],self.state_id,x,n_idx-1,now_idx[2])))\n",
    "                            temp_new_col.append((x,self.col_pos_id,now_idx[2],now_idx[3]))\n",
    "                            #temp_new_col.append((x,self.col_pos_id,now_idx[2]))\n",
    "                            #temp_new_col.append((x,self.col_pos_id,-1))\n",
    "                            self.col_pos_id+=1  \n",
    "                            \n",
    "                            logging.debug((\"now_idx\",now_idx))\n",
    "                            self.col_dependency.append((self.state_id,now_idx[-2] if len(now_idx)==4 else now_idx[-1],now_idx[-2] if len(now_idx)==4 else now_idx[-1]))                              \n",
    "                continue\n",
    "            \n",
    "            old_schema_idx = self.curr_col_schema[idx_schema]\n",
    "            \n",
    "            idx = old_col.index(x)\n",
    "            prev_idx = (-1,None)\n",
    "            next_idx = None\n",
    "            if idx > 0:\n",
    "                prev_idx = old_col[idx-1]\n",
    "            #if idx < len(old_col)-1:\n",
    "            #    next_idx = old_col[idx+1]\n",
    "\n",
    "            logging.debug((\"change_schema\",n_idx,x,idx,prev_idx,self.curr_col_schema[idx_schema]))\n",
    "                        \n",
    "            now_idx = self.curr_col_schema[idx_schema]    \n",
    "            \n",
    "            prev_nidx = (-1,None)\n",
    "            if n_idx > 0:                \n",
    "                prev_nidx = (n_idx-1,now_col[n_idx-1])                        \n",
    "                prev_idx = self.curr_col_schema[n_idx-1]\n",
    "            \n",
    "            #logging.debug((self.curr_col_pos[old_schema_idx[2]],now_idx))\n",
    "            \n",
    "            \n",
    "            if temp_prev == None:\n",
    "                temp_prev = -1\n",
    "            else:\n",
    "                temp_prev = now_idx[-1]\n",
    "                \n",
    "            #if self.curr_col_pos[old_schema_idx[2]][1] != now_idx[3]:\n",
    "            #print(now_idx,temp_new_col[n_idx-1])\n",
    "            logging.debug((\"prev_idx,nidx:\",prev_idx,prev_nidx,temp_new_col,n_idx))\n",
    "            if prev_idx[1] != prev_nidx[1]:         \n",
    "                #if prev_idx[0] != prev_nidx[1]:         \n",
    "                logging.debug((\"tempnewcol:\",temp_new_col[n_idx-1], now_idx))\n",
    "                #if temp_new_col[n_idx-1][2] != now_idx[2]:\n",
    "                if temp_new_col[n_idx-1][2] != now_idx[2]:\n",
    "                    idx_n = now_col.index(x)\n",
    "                    self.column_position.append((self.col_pos_id,now_idx[-2],self.state_id,x,temp_new_col[n_idx-1][2],now_idx[2]))\n",
    "                    logging.debug((\"adding_col_pos2:\",(self.col_pos_id,now_idx[-2],self.state_id,x,temp_new_col[n_idx-1][2],now_idx[2])))                            \n",
    "                    #temp_new_col.append((x,self.col_pos_id,now_idx[1],now_idx[2],temp_prev))\n",
    "                    temp_new_col.append((x,self.col_pos_id,now_idx[2],temp_prev))\n",
    "                    self.col_pos_id+=1\n",
    "            else:\n",
    "                 temp_new_col.append((x,now_idx[1],now_idx[2],now_idx[3]))\n",
    "            \n",
    "                                \n",
    "            \"\"\"\n",
    "            #if idx_n > 0:\n",
    "            prev_idx_n = -1\n",
    "            try:\n",
    "                prev_idx_n = now_col[idx_n-1]\n",
    "            except:\n",
    "                pass\n",
    "            logging.debug((\"test column\",prev_idx,prev_idx_n))\n",
    "\n",
    "            if prev_idx is not None and prev_idx[0]!=prev_idx_n:\n",
    "                self.column_position.append((self.col_pos_id,prev_idx[0],self.state_id,x,prev_idx_n,prev_idx[1]))\n",
    "                self.col_pos_id+=1        \n",
    "            #self.curr_col_schema.insert(idx,(x,self.col_id))            \n",
    "            self.col_names_coll.add(x)\n",
    "            \"\"\"\n",
    "            \n",
    "        self.curr_col_schema = temp_new_col\n",
    "            \n",
    "        pass\n",
    "    \n",
    "    def change_row_position(self,prev_df,now_df):\n",
    "        old_row = list(self.curr_row)\n",
    "        now_row = list(now_df.index)\n",
    "        #new_row = set(now_row)-set(old_row)\n",
    "        \n",
    "        temp_cur_row_pos = []\n",
    "        for x in now_row:\n",
    "            #logging.debug((x))\n",
    "            temp_cur_row_pos.append(self.curr_row_pos[x])            \n",
    "        \n",
    "        logging.debug(temp_cur_row_pos)\n",
    "        pass\n",
    "    \n",
    "    def add_column(self,prev_df,df,state_ss=None):   \n",
    "        #old_col = self.curr_col\n",
    "        old_col = prev_df.columns\n",
    "        now_col = df.columns\n",
    "        new_col = set(now_col)-set(old_col)\n",
    "        logging.debug((\"new_col:\",new_col,self.curr_col_schema))\n",
    "        \n",
    "        # sort new_col by the index\n",
    "        new_col = list(filter(lambda x:x in new_col,now_col))\n",
    "\n",
    "        in_col,out_col = dep_input_output_col(prev_df,df,state_ss[\"operation\"][\"description\"])\n",
    "        #print(\"in_col,out_col\",in_col,out_col)\n",
    "        \n",
    "        old_col_schema = self.curr_col_schema.copy()\n",
    "        \n",
    "        for j,x in enumerate(new_col):\n",
    "            last_col = self.curr_col_schema[-1][1]\n",
    "            new_col_val = df.loc[:,[x]]\n",
    "            logging.debug(new_col_val.values.tolist())\n",
    "            idx = list(now_col).index(x)\n",
    "                \n",
    "            logging.debug(idx)\n",
    "            if idx > 0:\n",
    "                prev_idx = self.curr_col_schema[idx-1]\n",
    "            \n",
    "            self.column_position.append((self.col_pos_id,self.col_id,self.state_id,x,prev_idx[2],-1))       \n",
    "            logging.debug((\"curr_col_schema\",self.curr_col_schema))\n",
    "            #self.curr_col_schema.insert(idx,(x,self.col_pos_id,self.col_id,self.curr_col_schema[-1][3] if len(self.curr_col_schema[-1])==4 else self.curr_col_schema[-1][-1]))\n",
    "            self.curr_col_schema.insert(idx,(x,self.col_pos_id,self.col_id,self.curr_col_schema[-1][2]))\n",
    "            self.curr_col_pos[self.col_id] = (self.col_pos_id,last_col)\n",
    "            self.col_names_coll.add(x)            \n",
    "            \n",
    "            # add values\n",
    "            self.column.append((self.col_id,self.array_id))\n",
    "            #self.cell_values.append()\n",
    "            temp_idx = []\n",
    "            for y,i in zip(new_col_val.values.tolist(),self.curr_row):\n",
    "            #for y,i in zip(new_col_val.values.tolist(),self.curr_row):\n",
    "                self.cell.append((self.cell_id,self.col_id,i))\n",
    "                self.cell_values.append((self.value_id,self.cell_id,self.state_id,y[0][0] if y[0]!=None else y[0],-1))\n",
    "                #print(self.pd_index.loc[i,jj])\n",
    "                #self.pd_index.loc[i,jj] = (self.cell_id,self.value_id,i,jj) \n",
    "                temp_idx.append([(self.cell_id,self.value_id,i,self.col_id)])\n",
    "                \n",
    "                # add linkage to the derived by cell\n",
    "                # lookup value id for input col_value\n",
    "                logging.debug((\"in_col:\",in_col,self.curr_col_schema))\n",
    "                for z in in_col:                    \n",
    "                    zzl = [x[-2] if len(x)==4 else x[-1] for x in list(filter(lambda x:(x[0]==z),self.curr_col_schema))]\n",
    "                    logging.debug((\"zzl:\",zzl))\n",
    "                    for zz in zzl:                        \n",
    "                        op_cid = list(filter(lambda x:(x[1]==zz)&(x[2]==i),self.cell))\n",
    "                        logging.debug((\"op_cid:\",op_cid))\n",
    "                        for zzz in op_cid:\n",
    "                            op_val = list(filter(lambda x:x[1]==zzz[0],sorted(self.cell_values,key=lambda x:x[0])))[::-1]\n",
    "                            logging.debug((\"op_val:\",op_val))\n",
    "                            for v in op_val:\n",
    "                                self.value_derived_from.append((self.value_id,self.state_id,v[0]))\n",
    "                                break\n",
    "                                            \n",
    "                #filter(lambda x:,self.cell_values)\n",
    "                \n",
    "                self.value_id+=1\n",
    "                self.cell_id+=1\n",
    "            \n",
    "            #self.pd_index[self.col_id] = pd.DataFrame(temp_idx)\n",
    "            self.pd_index.insert(loc=idx,column=self.col_id,value=pd.DataFrame(temp_idx)[0].tolist())\n",
    "            \n",
    "            #self.curr_col_pos[self.col_id] = (self.col_pos_id,prev_j)\n",
    "\n",
    "            for z in in_col:\n",
    "                zzl = [x[-2] for x in list(filter(lambda x:(x[0]==z),self.curr_col_schema))]\n",
    "                for zz in zzl:                        \n",
    "                    self.col_dependency.append((self.state_id,self.col_id,zz))                                            \n",
    "            \n",
    "            #prev_j = j\n",
    "            self.col_pos_id+=1                    \n",
    "            self.col_id+=1\n",
    "        \n",
    "        # normalize column position\n",
    "        temp_new_col = []\n",
    "        for n_idx,x in enumerate(self.curr_col_schema):\n",
    "            filtered_col = list(filter(lambda y: y[2] == x[2],old_col_schema))\n",
    "            if len(filtered_col)>0:\n",
    "                idx = [y[2] for y in old_col_schema].index(x[2])\n",
    "                prev_idx = -1\n",
    "                prev_old_schema = (None,None,None,None)\n",
    "                if idx > 0:\n",
    "                    prev_idx = idx - 1\n",
    "                    prev_old_schema = old_col_schema[prev_idx]\n",
    "                old_schema_idx = old_col_schema[idx]\n",
    "                \n",
    "                prev_nidx = -1\n",
    "                prev_new_schema = (None,None,None,None)\n",
    "                if n_idx > 0:     \n",
    "                    prev_nidx = n_idx - 1\n",
    "                    prev_new_schema = self.curr_col_schema[prev_nidx]\n",
    "\n",
    "                if prev_old_schema[2] != prev_new_schema[2]:                \n",
    "                    self.column_position.append((self.col_pos_id,old_schema_idx[1],self.state_id,x[0],prev_new_schema[1],old_schema_idx[1]))\n",
    "                    \n",
    "                    temp_new_col.append((x[0],self.col_pos_id,old_schema_idx[1],prev_new_schema[1]))\n",
    "                    self.col_pos_id+=1                \n",
    "                else:\n",
    "                    temp_new_col.append(old_col_schema[idx])\n",
    "            else:\n",
    "                temp_new_col.append(self.curr_col_schema[n_idx])\n",
    "        \n",
    "        logging.debug((\"add column\",temp_new_col))\n",
    "        \n",
    "        self.curr_col_schema = temp_new_col\n",
    "                        \n",
    "        #len(now_col)>len(prev_col)\n",
    "        pass\n",
    "    \n",
    "    def remove_column(self,prev_df,df):\n",
    "        #old_col = self.curr_col\n",
    "        old_col = prev_df.columns\n",
    "        curr_col = self.curr_col_schema\n",
    "        now_col = df.columns\n",
    "        \n",
    "        removed = set(old_col) - set(now_col)\n",
    "        logging.debug((\"remove_column: \",removed))\n",
    "        for x in removed:\n",
    "            idx = list(old_col).index(x)\n",
    "\n",
    "            #logging.debug(idx)\n",
    "            prev_idx = None\n",
    "            next_idx = None\n",
    "            if idx > 0:\n",
    "                prev_idx = self.curr_col_schema[idx-1]\n",
    "            if idx < len(old_col)-1:\n",
    "                next_idx = self.curr_col_schema[idx+1]\n",
    "            \n",
    "            self.column_position.append((self.col_pos_id,self.curr_col_schema[idx][1],self.state_id,x,-2,self.curr_col_schema[idx][1]))\n",
    "            self.curr_col_pos[idx] = (self.col_pos_id,-2)\n",
    "            old_col = self.curr_col_schema.pop(idx)\n",
    "            \n",
    "            \n",
    "            self.col_pos_id+=1          \n",
    "            if next_idx is not None:\n",
    "                self.column_position.append((self.col_pos_id,next_idx[1],self.state_id,x,prev_idx[1],next_idx[0]))                \n",
    "                self.col_pos_id+=1                                        \n",
    "        pass\n",
    "    \n",
    "    def add_row(self,df):\n",
    "        old_row = list(self.curr_row)\n",
    "        now_row = list(df.index)\n",
    "        new_row = set(now_row)-set(old_row)           \n",
    "        logging.debug((old_row,now_row,new_row))\n",
    "        \n",
    "        \n",
    "        for x in new_row:\n",
    "            new_row_val = df.loc[[x],:]\n",
    "            logging.debug((\"new row\",new_row_val.values.tolist(),self.curr_col_schema))\n",
    "        \n",
    "            for y,i in zip(new_row_val.values.tolist()[0],self.curr_col_schema):\n",
    "                #print(i)\n",
    "                self.cell.append((self.cell_id,i[1],self.row_id))\n",
    "                self.cell_values.append((self.value_id,self.cell_id,self.state_id,y[0],-1))\n",
    "                self.cell_id+=1\n",
    "                self.value_id+=1\n",
    "            \n",
    "            self.row.append((self.row_id,self.array_id))            \n",
    "            \n",
    "            if self.curr_row_pos[self.row_id-1][1]!=-2:\n",
    "                self.curr_row_pos[self.row_id] = (self.row_pos_id,self.row_id-1)\n",
    "                self.row_position.append((self.row_pos_id,self.row_id,self.state_id,self.row_id-1,-1))\n",
    "            else:\n",
    "                temp_prev_row = list(filter(lambda x:(x[1]==self.row_id-1)&(x[3]!=-2),self.row_position))\n",
    "                if len(temp_prev_row)>0:\n",
    "                    self.curr_row_pos[self.row_id] = (self.row_pos_id,temp_prev_row[-1][3])\n",
    "                    self.row_position.append((self.row_pos_id,self.row_id,temp_prev_row[-1][3],-1))\n",
    "\n",
    "                else: \n",
    "                    self.curr_row_pos[self.row_id] = (self.row_pos_id,self.row_id-1)\n",
    "            \n",
    "            self.row_id+=1    \n",
    "            self.row_pos_id+=1\n",
    "                \n",
    "            \"\"\"\n",
    "            idx = list(now_col).index(x)\n",
    "                \n",
    "            logging.debug(idx)\n",
    "            if idx > 0:\n",
    "                prev_idx = self.curr_col_schema[idx-1]\n",
    "            \n",
    "            self.column_position.append((self.col_pos_id,self.col_id,self.state_id,x,prev_idx[1],-1))\n",
    "            \n",
    "            self.curr_col_schema.insert(idx,(x,self.col_id))\n",
    "            \n",
    "            self.col_names_coll.add(x)\n",
    "            \n",
    "            \n",
    "            # add values\n",
    "            self.column.append((self.col_id,self.array_id))\n",
    "            #self.cell_values.append()\n",
    "            temp_idx = []\n",
    "            for y,i in zip(new_col_val.values.tolist(),self.curr_row):\n",
    "                self.cell.append((self.cell_id,self.col_id,i))\n",
    "                self.cell_values.append((self.value_id,self.cell_id,self.state_id,y[0],-1))\n",
    "                #print(self.pd_index.loc[i,jj])\n",
    "                #self.pd_index.loc[i,jj] = (self.cell_id,self.value_id,i,jj) \n",
    "                temp_idx.append([(self.cell_id,self.value_id,i,self.col_id)])\n",
    "                self.value_id+=1\n",
    "                self.cell_id+=1\n",
    "            \n",
    "            self.pd_index[self.col_id] = pd.DataFrame(temp_idx)\n",
    "\n",
    "            #prev_j = j\n",
    "            self.col_pos_id+=1                    \n",
    "            self.col_id+=1             \n",
    "            \"\"\"\n",
    "        \n",
    "        \n",
    "        pass\n",
    "\n",
    "    def remove_row(self,df):\n",
    "        old_row = list(self.curr_row)\n",
    "        now_row = list(df.index)\n",
    "        removed_row = set(old_row)-set(now_row)           \n",
    "        logging.debug((old_row,now_row,removed_row))\n",
    "        \n",
    "        \n",
    "        for x in removed_row:\n",
    "            temp_row_pos = self.curr_row_pos[x]\n",
    "\n",
    "            self.row_position.append((self.row_pos_id,x,self.state_id,-2,temp_row_pos[0]))\n",
    "            self.curr_row_pos[x] = (self.row_pos_id,-2)\n",
    "            self.row_pos_id+=1\n",
    "            # next pos\n",
    "\n",
    "            # filter with previous row_pos_id\n",
    "            next_row = list(filter(lambda x:x[1][1]==x,self.curr_row_pos.items()))\n",
    "            if len(next_row)>0:\n",
    "                next_row = next_row[0]\n",
    "                self.row_position.append((self.row_pos_id,next_row[0],self.state_id,temp_row_pos[1],next_row[1][0]))\n",
    "                self.curr_row_pos[next_row[0]] = (self.row_pos_id,temp_row_pos[1])\n",
    "\n",
    "                self.row_pos_id+=1        \n",
    "        pass\n",
    "    \n",
    "    def change_values(self,df,change):\n",
    "        #self.curr_index = self.pd_index[change]\n",
    "        \n",
    "        #change.columns = df.columns\n",
    "        #change.index = df.index                \n",
    "        \n",
    "        l_idx = self.pd_index[change]\n",
    "        \n",
    "        tt = np.where(np.matrix(change.to_numpy())==True)     \n",
    "        tt = list(zip(tt[0],tt[1]))\n",
    "        #logging.debug((list(zip(tt[0],tt[1]))))\n",
    "        #if tt[0].shape[0] == 1:\n",
    "        #    tt = [(tt[0][0],tt[1][0])]\n",
    "        #logging.debug((np.where(np.matrix(change.to_numpy())==True)))\n",
    "        #logging.debug((\"tt\",tt))\n",
    "        logging.debug((\"pd_index:\",self.pd_index,change.to_numpy()))\n",
    "        idx = self.pd_index.to_numpy()[change.to_numpy()].flatten()        \n",
    "        val = df[change].to_numpy().flatten()\n",
    "        logging.debug((\"idx:\",idx,val))\n",
    "        #list(idx)\n",
    "        idx_list = list(filter(lambda x:pd.isna(x)!=True,idx))\n",
    "        val_list = list(filter(lambda x:pd.isna(x)!=True,val))\n",
    "        \n",
    "        logging.debug((\"idxlist:\",idx_list,val_list))\n",
    "        \n",
    "        #?filter\n",
    "        \n",
    "        #print(idx_list,val_list)\n",
    "\n",
    "        for x in zip(idx_list,val_list,tt):\n",
    "            logging.debug((\"idxlist:\",x))\n",
    "            self.cell_values.append((self.value_id,x[0][0],self.state_id,x[1][0],x[0][1]))   \n",
    "            #logging.debug((\"x2\",x[2]))\n",
    "            ttx = list(self.pd_index.loc[x[2][0],x[2][1]])\n",
    "            ttx[1] = self.value_id\n",
    "            #logging.debug((ttx))\n",
    "            self.pd_index.loc[x[2][0],x[2][1]] = tuple(ttx)\n",
    "            #x[0] = self.value_id            \n",
    "            \n",
    "            \n",
    "            self.value_derived_from.append((self.value_id,self.state_id,x[0][1]))\n",
    "            \n",
    "            \n",
    "            \"\"\"            \n",
    "            logging.debug((\"in_col\",in_col))\n",
    "            for z in in_col:\n",
    "                zzl = [x[-1] for x in list(filter(lambda x:(x[0]==z),self.curr_col_schema))]\n",
    "                logging.debug((\"zzl\",zzl))\n",
    "                for zz in zzl:                        \n",
    "                    op_cid = list(filter(lambda x:(x[1]==zz)&(x[2]==i),self.cell))\n",
    "                    logging.debug((\"op_cid\",op_cid))\n",
    "                    for zzz in op_cid:\n",
    "                        op_val = list(filter(lambda x:x[1]==zzz[0],self.cell_values))\n",
    "                        logging.debug((\"op_val\",op_val))\n",
    "                        for v in op_val:\n",
    "                            self.value_derived_from.append((self.value_id,v[0]))\n",
    "            \"\"\"\n",
    "            \n",
    "            self.value_id+=1\n",
    "            #print(x)\n",
    "\n",
    "        #prev_state_id = state_id\n",
    "        #state_id+=1\n",
    "        #state.append((state_id,prev_state_id))\n",
    "        \n",
    "        pass\n",
    "                    \n",
    "    \n",
    "    def change_df(self,prev_df,now_df,state_ss):  \n",
    "        try:\n",
    "            in_col,out_col = dep_input_output_col(prev_df,now_df,state_ss[\"operation\"][\"description\"])\n",
    "        \n",
    "            # add linkage to the derived by cell\n",
    "            # lookup value id for input col_value\n",
    "            if len(out_col)==0:\n",
    "                logging.debug((\"in_col:\",in_col,self.curr_col_schema))\n",
    "                for z in in_col:\n",
    "                    zzl = [x[-2] if len(x)==4 else x[-1] for x in list(filter(lambda x:(x[0]==z),self.curr_col_schema))]\n",
    "                    logging.debug((\"zzl\",zzl))\n",
    "                    for zzy in zzl:\n",
    "                        self.col_dependency.append((self.state_id,zzy,zzy))                                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #prev_col = np.array(self.curr_col)\n",
    "        prev_col = prev_df.columns\n",
    "        now_col = now_df.columns\n",
    "        \n",
    "        #print(prev_col,now_col)\n",
    "        \n",
    "        \n",
    "        # condition for add and remove columns\n",
    "        if len(now_col)>len(prev_col):\n",
    "            # condition for add_columns:\n",
    "            logging.debug(\"add column\")\n",
    "            self.add_column(prev_df,now_df,state_ss)            \n",
    "        elif len(prev_col)>len(now_col):\n",
    "            # condition for remove_columns:\n",
    "            logging.debug(\"remove_column\")\n",
    "            self.remove_column(prev_df,now_df)\n",
    "            \n",
    "        # condition for change of schema:\n",
    "        if len(prev_col)==len(now_col) and np.sum(prev_col!=now_col)>0:\n",
    "            logging.debug(\"change column schema\")\n",
    "            self.change_column_schema(prev_df,now_df)\n",
    "        \n",
    "        #prev_row = np.array(self.curr_row)\n",
    "        prev_row = np.array(list(prev_df.index))\n",
    "        now_row = np.array(list(now_df.index))\n",
    "        \n",
    "        # condition for add and remove rows        \n",
    "        if len(now_row)>len(prev_row):\n",
    "            # condition for add_columns:\n",
    "            logging.debug(\"add row\")\n",
    "            self.add_row(now_df)            \n",
    "        elif len(prev_row)>len(now_row):\n",
    "            # condition for remove_columns:\n",
    "            logging.debug(\"remove row\")\n",
    "            self.remove_row(now_df)\n",
    "            \n",
    "        # condition for change of schema:\n",
    "        if len(prev_row)==len(now_row) and np.sum(prev_row!=now_row)>1:\n",
    "            logging.debug(\"change row position\")\n",
    "            self.change_row_position(prev_df,now_df)\n",
    "            \n",
    "        \n",
    "        # condition for change of values\n",
    "        try:\n",
    "            change_val = now_df.fillna(\"null\")!=prev_df.fillna(\"null\")\n",
    "            if change_val.to_numpy().sum()>0:\n",
    "                logging.debug(\"change values\")\n",
    "                self.change_values(now_df,change_val)\n",
    "            else:\n",
    "                logging.debug(\"nothing change\")\n",
    "        except BaseException as ex:\n",
    "            logging.debug(ex)\n",
    "            pass\n",
    "        \n",
    "                \n",
    "        #prev_state_id = self.state_id\n",
    "        prev_state_id = self.state_id\n",
    "        self.state_id+=1        \n",
    "        self.state_detail.append((prev_state_id,state_ss))       \n",
    "        self.state.append((self.state_id,prev_state_id))    \n",
    "        \n",
    "        \n",
    "        return True\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        col_id = np.where(prev_df.columns==col.name)[0][0]\n",
    "        columns.append((col_id,array_id))\n",
    "        #temp_col = []\n",
    "        for i,x in enumerate(col):\n",
    "            if not row_processed:\n",
    "                rows.append((i,array_id))\n",
    "            #temp_col.append((cell_id,col_id,i))\n",
    "            cells.append((cell_id,col_id,i))\n",
    "            cell_values.append((value_id,cell_id,state_id,x,-1))\n",
    "            cell_id+=1\n",
    "            value_id+=1\n",
    "            #print(i,col_id)\n",
    "            pd_index.loc[i,col_id] = (cell_id,col_id,i)            \n",
    "        row_processed = True\n",
    "        state_id+=1\n",
    "        \"\"\"\n",
    "        \n",
    "    def transform(self):\n",
    "        prev_df = None\n",
    "        now_df = None\n",
    "        for i,x in enumerate(self.trace):\n",
    "            now_df = x[5]\n",
    "            #print(now_df)\n",
    "            if i == 0:\n",
    "                #init dataset\n",
    "                self.init_dataset(x)\n",
    "            else:\n",
    "                self.change_df(prev_df,now_df)\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            self.curr_col = now_df.columns\n",
    "            #self.curr_col_schema = [for x in self.curr_col]\n",
    "            self.curr_row = list(now_df.index)        \n",
    "            self.curr_df = now_df                        \n",
    "            prev_df = now_df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_input_output_col(prev_df,now_df,desc):\n",
    "    new_col = set(now_df.columns) - set(prev_df.columns)\n",
    "    old_col = set(list(prev_df.columns))\n",
    "    sort_old_cols = sorted(old_col,key=lambda x:len(x))[::-1]\n",
    "    sort_new_cols = sorted(new_col,key=lambda x:len(x))[::-1]\n",
    "    desc = ops[\"description\"]\n",
    "\n",
    "    import re\n",
    "    out_cols = []\n",
    "    in_cols = []\n",
    "    for x in sort_new_cols:\n",
    "        sx = r'\\b{}\\b'.format(x)\n",
    "        #print(sx,desc)\n",
    "        xx = re.findall(sx,desc)\n",
    "        #print(xx)\n",
    "        for yy in xx:\n",
    "            desc = desc.replace(yy,\"\")\n",
    "        out_cols = out_cols + xx\n",
    "    for x in sort_old_cols:\n",
    "        sx = r'\\b{}\\b'.format(x)\n",
    "        #print(sx,desc)\n",
    "        xx = re.findall(sx,desc)\n",
    "        #print(xx)\n",
    "        for yy in xx:\n",
    "            desc = desc.replace(yy,\"\")\n",
    "        in_cols = in_cols + xx\n",
    "    \n",
    "    out_cols = list(set(out_cols+list(new_col)))\n",
    "        \n",
    "    return in_cols,out_cols\n",
    "    #ops[\"description\"]\n",
    "\n",
    "#dep_input_output_col(prev_df,now_df,ops[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:init dataset\n",
      "DEBUG:root:('in_col:', ['Book Title'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [0])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [1])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [2])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [1])\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)    (2, 2, 0, 2)    (3, 3, 0, 3)\n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)    (6, 6, 1, 2)    (7, 7, 1, 3)\n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 10, 2, 2)  (11, 11, 2, 3)\n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 14, 3, 2)  (15, 15, 3, 3), array([[False, False, False, False],\n",
      "       [False, False, False, False],\n",
      "       [False,  True, False, False],\n",
      "       [False, False, False, False]]))\n",
      "DEBUG:root:('idx:', array([(9, 9, 2, 1)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       ('Stanford, P. Kyle', 2, 1), nan, nan, nan, nan, nan, nan],\n",
      "      dtype=object))\n",
      "DEBUG:root:('idxlist:', [(9, 9, 2, 1)], [('Stanford, P. Kyle', 2, 1)])\n",
      "DEBUG:root:('idxlist:', ((9, 9, 2, 1), ('Stanford, P. Kyle', 2, 1), (2, 1)))\n",
      "DEBUG:root:add column\n",
      "DEBUG:root:('new_col:', {'Author 1', 'Author 2'}, [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:[[('Feyerabend', 0, 4)], [('Collins', 1, 4)], [('Stanford', 2, 4)], [(' ', 3, 4)]]\n",
      "DEBUG:root:2\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(1, 1, 0)])\n",
      "DEBUG:root:('op_val:', [(1, 1, -1, 'Feyerabend, P.', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(5, 1, 1)])\n",
      "DEBUG:root:('op_val:', [(5, 5, -1, 'Collins, H.M.', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(9, 1, 2)])\n",
      "DEBUG:root:('op_val:', [(16, 9, 3, 'Stanford, P. Kyle', 9), (9, 9, -1, ' P. Kyle Stanford', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(13, 1, 3)])\n",
      "DEBUG:root:('op_val:', [(13, 13, -1, ' ', -1)])\n",
      "DEBUG:root:[[(' P.', 0, 5)], [(' H.M.', 1, 5)], [(' P. Kyle', 2, 5)], [None]]\n",
      "DEBUG:root:3\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(1, 1, 0)])\n",
      "DEBUG:root:('op_val:', [(1, 1, -1, 'Feyerabend, P.', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(5, 1, 1)])\n",
      "DEBUG:root:('op_val:', [(5, 5, -1, 'Collins, H.M.', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(9, 1, 2)])\n",
      "DEBUG:root:('op_val:', [(16, 9, 3, 'Stanford, P. Kyle', 9), (9, 9, -1, ' P. Kyle Stanford', -1)])\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl:', [1])\n",
      "DEBUG:root:('op_cid:', [(13, 1, 3)])\n",
      "DEBUG:root:('op_val:', [(13, 13, -1, ' ', -1)])\n",
      "DEBUG:root:('add column', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw:\n",
      "get_values_state 9\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Book Title', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 8\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "Text transform on cells in column Book Title using expression value.replace(/\\s+/,' ') (['Book Title'], [])\n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 7\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "Text transform on cells in column Author using expression value.replace(/\\s+/,' ') (['Author'], [])\n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 6\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "Text transform on cells in column Date using expression value.replace(/\\s+/,' ') (['Date'], [])\n",
      "{'op': 'core/mass-edit', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': 'value', 'edits': [{'from': [' P. Kyle Stanford'], 'fromBlank': False, 'fromError': False, 'to': 'Stanford, P. Kyle'}], 'description': 'Mass edit cells in column Author'}\n",
      "get_values_state 5\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "Mass edit cells in column Author (['Author'], [])\n",
      "{'op': 'core/column-split', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'guessCellType': True, 'removeOriginalColumn': False, 'mode': 'separator', 'separator': ',', 'regex': False, 'maxColumns': 0, 'description': 'Split column Author by separator'}\n",
      "get_values_state 4\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "             Author 1          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "Split column Author by separator (['Author'], ['Author 1', 'Author 2'])\n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Author 1', 'newColumnName': 'Last Name', 'description': 'Rename column Author 1 to Last Name'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Author 1', 'Author 2', 'Date', 'Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Author 1', 4, 4, 3), ('Author 2', 5, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)], ['Book Title', 'Author', 'Last Name', 'Author 2', 'Date', 'Entrance Date'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Last Name'}, {'Author 1'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Author 1', 'Author 2', 'Date', 'Entrance Date'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "             Author 1          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  ,                       Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  )\n",
      "DEBUG:root:('idx_test', 2)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Author 1', 4, 4, 3), 'Author')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (7, 4, 5, 'Last Name', 1, 4))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Author 1', 4, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author 1', 4, 4, 3), ('Last Name', 7, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author 2', 5, 5, 3), ('Author 2', 5, 5, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 6, 2, 5), ('Date', 6, 2, 5))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Last Name', 7, 4, 3), ('Author 2', 5, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Last Name', 'Author 2', 'Date', 'Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Last Name', 7, 4, 3), ('Author 2', 5, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)], ['Book Title', 'Author', 'Last Name', 'First Name', 'Date', 'Entrance Date'])\n",
      "DEBUG:root:('change_col_schema new_col', {'First Name'}, {'Author 2'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Last Name', 'Author 2', 'Date', 'Entrance Date'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  ,                       Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  )\n",
      "DEBUG:root:('idx_test', 3)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Author 2', 5, 5, 3), 'Last Name')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (8, 5, 6, 'First Name', 2, 5))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Author 2', 5, 5, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author 2', 5, 5, 3), ('First Name', 8, 5, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 6, 2, 5), ('Date', 6, 2, 5))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Last Name', 7, 4, 3), ('First Name', 8, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Last Name', 7, 4, 3), ('First Name', 8, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [2])\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               4               5  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)  (16, 17, 0, 4)  (20, 21, 0, 5)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)  (17, 18, 1, 4)  (21, 22, 1, 5)   \n",
      "2    (8, 8, 2, 0)   (9, 16, 2, 1)  (18, 19, 2, 4)  (22, 23, 2, 5)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (19, 20, 3, 4)  (23, 24, 3, 5)   \n",
      "\n",
      "                2               3  \n",
      "0    (2, 2, 0, 2)    (3, 3, 0, 3)  \n",
      "1    (6, 6, 1, 2)    (7, 7, 1, 3)  \n",
      "2  (10, 10, 2, 2)  (11, 11, 2, 3)  \n",
      "3  (14, 14, 3, 2)  (15, 15, 3, 3)  , array([[False, False, False, False,  True, False],\n",
      "       [False, False, False, False,  True, False],\n",
      "       [False, False, False, False,  True, False],\n",
      "       [False, False, False, False,  True, False]]))\n",
      "DEBUG:root:('idx:', array([(2, 2, 0, 2), (6, 6, 1, 2), (10, 10, 2, 2), (14, 14, 3, 2)],\n",
      "      dtype=object), array([nan, nan, nan, nan, ('1975', 0, 2), nan, nan, nan, nan, nan,\n",
      "       ('1985', 1, 2), nan, nan, nan, nan, nan, ('2006', 2, 2), nan, nan,\n",
      "       nan, nan, nan, ('1992', 3, 2), nan], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(2, 2, 0, 2), (6, 6, 1, 2), (10, 10, 2, 2), (14, 14, 3, 2)], [('1975', 0, 2), ('1985', 1, 2), ('2006', 2, 2), ('1992', 3, 2)])\n",
      "DEBUG:root:('idxlist:', ((2, 2, 0, 2), ('1975', 0, 2), (0, 4)))\n",
      "DEBUG:root:('idxlist:', ((6, 6, 1, 2), ('1985', 1, 2), (1, 4)))\n",
      "DEBUG:root:('idxlist:', ((10, 10, 2, 2), ('2006', 2, 2), (2, 4)))\n",
      "DEBUG:root:('idxlist:', ((14, 14, 3, 2), ('1992', 3, 2), (3, 4)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_values_state 3\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name          Author 2           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "Rename column Author 1 to Last Name (['Author 1'], ['Last Name'])\n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Author 2', 'newColumnName': 'First Name', 'description': 'Rename column Author 2 to First Name'}\n",
      "get_values_state 2\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "Rename column Author 2 to First Name (['Author 2'], ['First Name'])\n",
      "None\n",
      "get_values_state 1\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name           Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  ( 1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  ( 1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  ( 2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  ( 1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': 'value.toNumber()', 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': 'Text transform on cells in column Date using expression value.toNumber()'}\n",
      "get_values_state 0\n",
      "                      Book Title                     Author  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)   \n",
      "\n",
      "            Last Name        First Name          Date         Entrance Date  \n",
      "0  (Feyerabend, 0, 4)       ( P., 0, 5)  (1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     (Collins, 1, 4)     ( H.M., 1, 5)  (1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2    (Stanford, 2, 4)  ( P. Kyle, 2, 5)  (2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "3           ( , 3, 4)              None  (1992, 3, 2)    (2010-31-01, 3, 3)  \n",
      "Text transform on cells in column Date using expression value.toNumber() (['Date'], [])\n",
      "{'op': 'core/row-removal', 'engineConfig': {'facets': [{'type': 'list', 'name': 'Flagged Rows', 'expression': 'row.flagged', 'columnName': '', 'invert': False, 'omitBlank': False, 'omitError': False, 'selection': [{'v': {'v': True, 'l': 'true'}}], 'selectBlank': False, 'selectError': False}], 'mode': 'row-based'}, 'description': 'Remove rows'}\n",
      "get_values_state -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:('in_col:', [], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Last Name', 7, 4, 3), ('First Name', 8, 5, 3), ('Date', 6, 2, 5), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:remove row\n",
      "DEBUG:root:([0, 1, 2, 3], [0, 1, 2], {3})\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Book Title                     Author           Last Name  \\\n",
      "0       (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (Feyerabend, 0, 4)   \n",
      "1       (Changing Order, 1, 0)      (Collins, H.M., 1, 1)     (Collins, 1, 4)   \n",
      "2  (Exceeding Our Grasp, 2, 0)  (Stanford, P. Kyle, 2, 1)    (Stanford, 2, 4)   \n",
      "\n",
      "         First Name          Date         Entrance Date  \n",
      "0       ( P., 0, 5)  (1975, 0, 2)    (1996-02-01, 0, 3)  \n",
      "1     ( H.M., 1, 5)  (1985, 1, 2)    (2003-12-31, 1, 3)  \n",
      "2  ( P. Kyle, 2, 5)  (2006, 2, 2)  (Feb, 29 2008, 2, 3)  \n",
      "Remove rows ([], [])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dcm1 = TransformDCM(None)\n",
    "print(\"raw:\")\n",
    "raw_pd = op1.get_snapshot_at_state(int(op1.get_state_to_step(len(op1.get_all_state_command())))+1)\n",
    "print(raw_pd)\n",
    "dcm1.init_dataset_df(raw_pd)\n",
    "\n",
    "prev_df = raw_pd\n",
    "\n",
    "for i,x in enumerate(op1.get_all_state_command().sort_values(\"state_id\",ascending=False).to_records()):\n",
    "    ops = json.loads(x[5])[\"operation\"]\n",
    "    print(ops)\n",
    "    now_df = op1.get_snapshot_at_state(int(op1.get_state_to_step(x.state_id)+1))\n",
    "    print(now_df)\n",
    "    dcm1.curr_col = prev_df.columns\n",
    "    dcm1.curr_row = list(prev_df.index) \n",
    "    dcm1.curr_df = prev_df \n",
    "    dcm1.change_df(prev_df,now_df,json.loads(x[5]))\n",
    "    \n",
    "    try:\n",
    "        print(ops[\"description\"],dep_input_output_col(prev_df,now_df,ops[\"description\"]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    prev_df = now_df\n",
    "\n",
    "    #op2.get_snapshot_at_state()\n",
    "    #if i>4:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Author 1', 1, -1),\n",
       "  (5, 5, 4, 'Author 2', 4, -1),\n",
       "  (6, 2, 4, 'Date', 5, 2),\n",
       "  (7, 4, 5, 'Last Name', 1, 4),\n",
       "  (8, 5, 6, 'First Name', 4, 5)],\n",
       " [('Book Title', 0, 0, -1),\n",
       "  ('Author', 1, 1, 0),\n",
       "  ('Last Name', 7, 4, 3),\n",
       "  ('First Name', 8, 5, 3),\n",
       "  ('Date', 6, 2, 5),\n",
       "  ('Entrance Date', 3, 3, 2)])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.column_position,dcm1.curr_col_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -1, -1),\n",
       " (1, -1, -1),\n",
       " (2, -1, -1),\n",
       " (3, -1, -1),\n",
       " (4, -1, -1),\n",
       " (5, -1, -1),\n",
       " (6, -1, -1),\n",
       " (7, -1, -1),\n",
       " (8, -1, -1),\n",
       " (9, -1, -1),\n",
       " (10, -1, -1),\n",
       " (11, -1, -1),\n",
       " (12, -1, -1),\n",
       " (13, -1, -1),\n",
       " (14, -1, -1),\n",
       " (15, -1, -1),\n",
       " (16, 3, 9),\n",
       " (17, 4, 1),\n",
       " (18, 4, 5),\n",
       " (19, 4, 16),\n",
       " (20, 4, 13),\n",
       " (21, 4, 1),\n",
       " (22, 4, 5),\n",
       " (23, 4, 16),\n",
       " (24, 4, 13),\n",
       " (25, 8, 2),\n",
       " (26, 8, 6),\n",
       " (27, 8, 10),\n",
       " (28, 8, 14)]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.value_derived_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:init dataset\n",
      "DEBUG:root:('in_col:', ['Book Title'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [0])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Author'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [1])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [2])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('zzl', [3])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:add column\n",
      "DEBUG:root:('new_col:', {'Entrance Date 2', 'Entrance Date 3', 'Entrance Date 1'}, [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:[[('1996', 0, 4)], [('2003', 1, 4)], [('Feb, 29 2008', 2, 4)], [('2010', 3, 4)]]\n",
      "DEBUG:root:4\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(3, 3, 0)])\n",
      "DEBUG:root:('op_val:', [(3, 3, -1, '1996-02-01', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(7, 3, 1)])\n",
      "DEBUG:root:('op_val:', [(7, 7, -1, '2003-12-31', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(11, 3, 2)])\n",
      "DEBUG:root:('op_val:', [(11, 11, -1, 'Feb, 29 2008', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(15, 3, 3)])\n",
      "DEBUG:root:('op_val:', [(15, 15, -1, '2010-31-01', -1)])\n",
      "DEBUG:root:[[('2', 0, 5)], [('12', 1, 5)], [('', 2, 5)], [('31', 3, 5)]]\n",
      "DEBUG:root:5\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(3, 3, 0)])\n",
      "DEBUG:root:('op_val:', [(3, 3, -1, '1996-02-01', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(7, 3, 1)])\n",
      "DEBUG:root:('op_val:', [(7, 7, -1, '2003-12-31', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(11, 3, 2)])\n",
      "DEBUG:root:('op_val:', [(11, 11, -1, 'Feb, 29 2008', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(15, 3, 3)])\n",
      "DEBUG:root:('op_val:', [(15, 15, -1, '2010-31-01', -1)])\n",
      "DEBUG:root:[[('1', 0, 6)], [('31', 1, 6)], [('', 2, 6)], [('1', 3, 6)]]\n",
      "DEBUG:root:6\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(3, 3, 0)])\n",
      "DEBUG:root:('op_val:', [(3, 3, -1, '1996-02-01', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(7, 3, 1)])\n",
      "DEBUG:root:('op_val:', [(7, 7, -1, '2003-12-31', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(11, 3, 2)])\n",
      "DEBUG:root:('op_val:', [(11, 11, -1, 'Feb, 29 2008', -1)])\n",
      "DEBUG:root:('in_col:', ['Entrance Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:('zzl:', [3])\n",
      "DEBUG:root:('op_cid:', [(15, 3, 3)])\n",
      "DEBUG:root:('op_val:', [(15, 15, -1, '2010-31-01', -1)])\n",
      "DEBUG:root:('add column', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw:\n",
      "get_values_state 17\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Book Title', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 16\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Author', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 15\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 14\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Entrance Date', 'expression': \"value.replace(/\\\\s+/,' ')\", 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': \"Text transform on cells in column Entrance Date using expression value.replace(/\\\\s+/,' ')\"}\n",
      "get_values_state 13\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{'op': 'core/column-split', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Entrance Date', 'guessCellType': True, 'removeOriginalColumn': False, 'mode': 'separator', 'separator': '-', 'regex': False, 'maxColumns': 0, 'description': 'Split column Entrance Date by separator'}\n",
      "get_values_state 12\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date       Entrance Date 1 Entrance Date 2 Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)  \n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Entrance Date 1', 'newColumnName': 'Year', 'description': 'Rename column Entrance Date 1 to Year'}\n",
      "get_values_state 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entrance Date 1', 'Entrance Date 2', 'Entrance Date 3'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entrance Date 1', 4, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)], ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Entrance Date 2', 'Entrance Date 3'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Year'}, {'Entrance Date 1'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entrance Date 1', 'Entrance Date 2', 'Entrance Date 3'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 2, 2, 1), ('Date', 2, 2, 1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date       Entrance Date 1 Entrance Date 2 Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)  ,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year Entrance Date 2 Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)  )\n",
      "DEBUG:root:('idx_test', 4)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Entrance Date 1', 4, 4, 3), 'Entrance Date')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (7, 4, 5, 'Year', 3, 4))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Entrance Date 1', 4, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date 1', 4, 4, 3), ('Year', 7, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date 2', 5, 5, 4), ('Entrance Date 2', 5, 5, 4))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Year', 7, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Entrance Date 2', 'Entrance Date 3'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Year', 7, 4, 3), ('Entrance Date 2', 5, 5, 4), ('Entrance Date 3', 6, 6, 5)], ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Month', 'Entrance Date 3'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Month'}, {'Entrance Date 2'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Entrance Date 2', 'Entrance Date 3'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 2, 2, 1), ('Date', 2, 2, 1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date', 3, 3, 2), ('Entrance Date', 3, 3, 2))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year Entrance Date 2 Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)  ,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  )\n",
      "DEBUG:root:('idx_test', 5)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Entrance Date 2', 5, 5, 4), 'Year')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (8, 5, 6, 'Month', 4, 5))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Entrance Date 2', 5, 5, 4))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date 2', 5, 5, 4), ('Month', 8, 5, 4))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Year', 7, 4, 3), ('Month', 8, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Month', 'Entrance Date 3'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Year', 7, 4, 3), ('Month', 8, 5, 4), ('Entrance Date 3', 6, 6, 5)], ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Month', 'Entrance Date 3'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Entry Year'}, {'Year'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Year', 'Month', 'Entrance Date 3'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 2, 2, 1), ('Date', 2, 2, 1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  ,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  )\n",
      "DEBUG:root:('idx_test', 4)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Year', 7, 4, 3), 'Entrance Date')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (9, 4, 7, 'Entry Year', 3, 4))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Year', 7, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Year', 7, 4, 3), ('Entry Year', 9, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Month', 8, 5, 4), ('Month', 8, 5, 4))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Month', 8, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year Entrance Date 2 Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)  \n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Entrance Date 2', 'newColumnName': 'Month', 'description': 'Rename column Entrance Date 2 to Month'}\n",
      "get_values_state 10\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  \n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Year', 'newColumnName': 'Entry Year', 'description': 'Rename column Year to Entry Year'}\n",
      "get_values_state 9\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  \n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Month', 'newColumnName': 'Entry Month', 'description': 'Rename column Month to Entry Month'}\n",
      "get_values_state 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Month', 'Entrance Date 3'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Month', 8, 5, 4), ('Entrance Date 3', 6, 6, 5)], ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Entry Month', 'Entrance Date 3'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Entry Month'}, {'Month'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Month', 'Entrance Date 3'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 2, 2, 1), ('Date', 2, 2, 1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date', 3, 3, 2), ('Entrance Date', 3, 3, 2))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year       Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  ,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  )\n",
      "DEBUG:root:('idx_test', 5)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Month', 8, 5, 4), 'Entry Year')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (10, 5, 8, 'Entry Month', 4, 5))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Month', 8, 5, 4))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Month', 8, 5, 4), ('Entry Month', 10, 5, 4))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entrance Date 3', 6, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:change column schema\n",
      "DEBUG:root:('change_col_schema old_col', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Entry Month', 'Entrance Date 3'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entrance Date 3', 6, 6, 5)], ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Entry Month', 'Entry Date'])\n",
      "DEBUG:root:('change_col_schema new_col', {'Entry Date'}, {'Entrance Date 3'})\n",
      "DEBUG:root:('change_col_schema old_schema:', ['Book Title', 'Author', 'Date', 'Entrance Date', 'Entry Year', 'Entry Month', 'Entrance Date 3'])\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', (None, None, None, None), (None, None, None, None))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Book Title', 0, 0, -1), ('Book Title', 0, 0, -1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Author', 1, 1, 0), ('Author', 1, 1, 0))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Date', 2, 2, 1), ('Date', 2, 2, 1))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entrance Date', 3, 3, 2), ('Entrance Date', 3, 3, 2))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('change_col_schema prev next:', ('Entry Year', 9, 4, 3), ('Entry Year', 9, 4, 3))\n",
      "DEBUG:root:change_col_schema now_col:\n",
      "DEBUG:root:('test', 4, 4,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  ,                       Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)    (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  )\n",
      "DEBUG:root:('idx_test', 6)\n",
      "DEBUG:root:('change_col_schema now_idx:', ('Entrance Date 3', 6, 6, 5), 'Entry Month')\n",
      "DEBUG:root:('change_col_schema adding_col_pos1:', (11, 6, 9, 'Entry Date', 5, 6))\n",
      "DEBUG:root:('change_col_schema now_idx', ('Entrance Date 3', 6, 6, 5))\n",
      "DEBUG:root:('change_col_schema temp_new_col:', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n",
      "DEBUG:root:('in_col:', ['Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5)])\n",
      "DEBUG:root:('zzl', [2])\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)    (2, 2, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)    (6, 6, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 10, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 14, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 18, 2, 4)  (22, 22, 2, 5)  (26, 26, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 27, 3, 6)  , array([[False, False,  True, False, False, False, False],\n",
      "       [False, False,  True, False, False, False, False],\n",
      "       [False, False,  True, False, False, False, False],\n",
      "       [False, False,  True, False, False, False, False]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:('idx:', array([(2, 2, 0, 2), (6, 6, 1, 2), (10, 10, 2, 2), (14, 14, 3, 2)],\n",
      "      dtype=object), array([nan, nan, ('1975', 0, 2), nan, nan, nan, nan, nan, nan,\n",
      "       ('1985', 1, 2), nan, nan, nan, nan, nan, nan, ('2006', 2, 2), nan,\n",
      "       nan, nan, nan, nan, nan, ('1992', 3, 2), nan, nan, nan, nan],\n",
      "      dtype=object))\n",
      "DEBUG:root:('idxlist:', [(2, 2, 0, 2), (6, 6, 1, 2), (10, 10, 2, 2), (14, 14, 3, 2)], [('1975', 0, 2), ('1985', 1, 2), ('2006', 2, 2), ('1992', 3, 2)])\n",
      "DEBUG:root:('idxlist:', ((2, 2, 0, 2), ('1975', 0, 2), (0, 2)))\n",
      "DEBUG:root:('idxlist:', ((6, 6, 1, 2), ('1985', 1, 2), (1, 2)))\n",
      "DEBUG:root:('idxlist:', ((10, 10, 2, 2), ('2006', 2, 2), (2, 2)))\n",
      "DEBUG:root:('idxlist:', ((14, 14, 3, 2), ('1992', 3, 2), (3, 2)))\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)   (2, 28, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)   (6, 29, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 30, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 31, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 18, 2, 4)  (22, 22, 2, 5)  (26, 26, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 27, 3, 6)  , array([[False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False,  True],\n",
      "       [False, False, False, False, False, False, False]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month Entrance Date 3  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)  \n",
      "{'op': 'core/column-rename', 'oldColumnName': 'Entrance Date 3', 'newColumnName': 'Entry Date', 'description': 'Rename column Entrance Date 3 to Entry Date'}\n",
      "get_values_state 7\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)    (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Date', 'expression': 'value.toNumber()', 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': 'Text transform on cells in column Date using expression value.toNumber()'}\n",
      "get_values_state 6\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)    (, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  \n",
      "None\n",
      "get_values_state 5\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:('idx:', array([(26, 26, 2, 6)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, nan, ('29', 2, 6), nan, nan, nan,\n",
      "       nan, nan, nan, nan], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(26, 26, 2, 6)], [('29', 2, 6)])\n",
      "DEBUG:root:('idxlist:', ((26, 26, 2, 6), ('29', 2, 6), (2, 6)))\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)   (2, 28, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)   (6, 29, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 30, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 31, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 18, 2, 4)  (22, 22, 2, 5)  (26, 32, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 27, 3, 6)  , array([[False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False,  True, False],\n",
      "       [False, False, False, False, False, False, False]]))\n",
      "DEBUG:root:('idx:', array([(22, 22, 2, 5)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, ('2', 2, 5), nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(22, 22, 2, 5)], [('2', 2, 5)])\n",
      "DEBUG:root:('idxlist:', ((22, 22, 2, 5), ('2', 2, 5), (2, 5)))\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)   (2, 28, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)   (6, 29, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 30, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 31, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 18, 2, 4)  (22, 33, 2, 5)  (26, 32, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 27, 3, 6)  , array([[False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False,  True, False, False],\n",
      "       [False, False, False, False, False, False, False]]))\n",
      "DEBUG:root:('idx:', array([(18, 18, 2, 4)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, ('2008', 2, 4), nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(18, 18, 2, 4)], [('2008', 2, 4)])\n",
      "DEBUG:root:('idxlist:', ((18, 18, 2, 4), ('2008', 2, 4), (2, 4)))\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)   (2, 28, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)   (6, 29, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 30, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 31, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 34, 2, 4)  (22, 33, 2, 5)  (26, 32, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 27, 3, 6)  , array([[False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False,  True]]))\n",
      "DEBUG:root:('idx:', array([(27, 27, 3, 6)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, ('31', 3, 6)], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(27, 27, 3, 6)], [('31', 3, 6)])\n",
      "DEBUG:root:('idxlist:', ((27, 27, 3, 6), ('31', 3, 6), (3, 6)))\n",
      "DEBUG:root:change values\n",
      "DEBUG:root:('pd_index:',                 0               1               2               3  \\\n",
      "0    (0, 0, 0, 0)    (1, 1, 0, 1)   (2, 28, 0, 2)    (3, 3, 0, 3)   \n",
      "1    (4, 4, 1, 0)    (5, 5, 1, 1)   (6, 29, 1, 2)    (7, 7, 1, 3)   \n",
      "2    (8, 8, 2, 0)    (9, 9, 2, 1)  (10, 30, 2, 2)  (11, 11, 2, 3)   \n",
      "3  (12, 12, 3, 0)  (13, 13, 3, 1)  (14, 31, 3, 2)  (15, 15, 3, 3)   \n",
      "\n",
      "                4               5               6  \n",
      "0  (16, 16, 0, 4)  (20, 20, 0, 5)  (24, 24, 0, 6)  \n",
      "1  (17, 17, 1, 4)  (21, 21, 1, 5)  (25, 25, 1, 6)  \n",
      "2  (18, 34, 2, 4)  (22, 33, 2, 5)  (26, 32, 2, 6)  \n",
      "3  (19, 19, 3, 4)  (23, 23, 3, 5)  (27, 35, 3, 6)  , array([[False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False],\n",
      "       [False, False, False, False, False,  True, False]]))\n",
      "DEBUG:root:('idx:', array([(23, 23, 3, 5)], dtype=object), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "       ('1', 3, 5), nan], dtype=object))\n",
      "DEBUG:root:('idxlist:', [(23, 23, 3, 5)], [('1', 3, 5)])\n",
      "DEBUG:root:('idxlist:', ((23, 23, 3, 5), ('1', 3, 5), (3, 5)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "get_values_state 4\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)   (2, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  \n",
      "None\n",
      "get_values_state 3\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)  \n",
      "None\n",
      "get_values_state 2\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)  (31, 3, 5)  (31, 3, 6)  \n",
      "None\n",
      "get_values_state 1\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)  \n",
      "{'op': 'core/text-transform', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'columnName': 'Entry Year', 'expression': 'value.toNumber()', 'onError': 'keep-original', 'repeat': False, 'repeatCount': 10, 'description': 'Text transform on cells in column Entry Year using expression value.toNumber()'}\n",
      "get_values_state 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:('in_col:', ['Entry Year'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5)])\n",
      "DEBUG:root:('zzl', [4])\n",
      "DEBUG:root:nothing change\n",
      "DEBUG:root:add column\n",
      "DEBUG:root:('new_col:', {'Archived Delay'}, [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5)])\n",
      "DEBUG:root:[[('21', 0, 7)], [('18', 1, 7)], [('2', 2, 7)], [('18', 3, 7)]]\n",
      "DEBUG:root:7\n",
      "DEBUG:root:('curr_col_schema', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5)])\n",
      "DEBUG:root:('in_col:', ['Entry Year', 'Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5), ('Archived Delay', 12, 7, 6)])\n",
      "DEBUG:root:('zzl:', [4])\n",
      "DEBUG:root:('op_cid:', [(16, 4, 0)])\n",
      "DEBUG:root:('op_val:', [(16, 16, 4, '1996', -1)])\n",
      "DEBUG:root:('zzl:', [2])\n",
      "DEBUG:root:('op_cid:', [(2, 2, 0)])\n",
      "DEBUG:root:('op_val:', [(28, 2, 10, '1975', 2), (2, 2, -1, ' 1975', -1)])\n",
      "DEBUG:root:('in_col:', ['Entry Year', 'Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5), ('Archived Delay', 12, 7, 6)])\n",
      "DEBUG:root:('zzl:', [4])\n",
      "DEBUG:root:('op_cid:', [(17, 4, 1)])\n",
      "DEBUG:root:('op_val:', [(17, 17, 4, '2003', -1)])\n",
      "DEBUG:root:('zzl:', [2])\n",
      "DEBUG:root:('op_cid:', [(6, 2, 1)])\n",
      "DEBUG:root:('op_val:', [(29, 6, 10, '1985', 6), (6, 6, -1, ' 1985', -1)])\n",
      "DEBUG:root:('in_col:', ['Entry Year', 'Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5), ('Archived Delay', 12, 7, 6)])\n",
      "DEBUG:root:('zzl:', [4])\n",
      "DEBUG:root:('op_cid:', [(18, 4, 2)])\n",
      "DEBUG:root:('op_val:', [(34, 18, 13, '2008', 18), (18, 18, 4, 'Feb, 29 2008', -1)])\n",
      "DEBUG:root:('zzl:', [2])\n",
      "DEBUG:root:('op_cid:', [(10, 2, 2)])\n",
      "DEBUG:root:('op_val:', [(30, 10, 10, '2006', 10), (10, 10, -1, ' 2006', -1)])\n",
      "DEBUG:root:('in_col:', ['Entry Year', 'Date'], [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5), ('Archived Delay', 12, 7, 6)])\n",
      "DEBUG:root:('zzl:', [4])\n",
      "DEBUG:root:('op_cid:', [(19, 4, 3)])\n",
      "DEBUG:root:('op_val:', [(19, 19, 4, '2010', -1)])\n",
      "DEBUG:root:('zzl:', [2])\n",
      "DEBUG:root:('op_cid:', [(14, 2, 3)])\n",
      "DEBUG:root:('op_val:', [(31, 14, 10, '1992', 14), (14, 14, -1, ' 1992', -1)])\n",
      "DEBUG:root:('add column', [('Book Title', 0, 0, -1), ('Author', 1, 1, 0), ('Date', 2, 2, 1), ('Entrance Date', 3, 3, 2), ('Entry Year', 9, 4, 3), ('Entry Month', 10, 5, 4), ('Entry Date', 11, 6, 5), ('Archived Delay', 12, 7, 6)])\n",
      "DEBUG:root:Can only compare identically-labeled DataFrame objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)  \n",
      "{'op': 'core/column-addition', 'engineConfig': {'facets': [], 'mode': 'row-based'}, 'baseColumnName': 'Entry Year', 'expression': 'grel:value - cells[\"Date\"].value', 'onError': 'set-to-blank', 'newColumnName': 'Archived Delay', 'columnInsertIndex': 7, 'description': 'Create column Archived Delay at index 7 based on column Entry Year using expression grel:value - cells[\"Date\"].value'}\n",
      "get_values_state -1\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)     (18, 3, 7)  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dcm2 = TransformDCM(None)\n",
    "print(\"raw:\")\n",
    "raw_pd = op2.get_snapshot_at_state(int(op2.get_state_to_step(len(op2.get_all_state_command())))+1)\n",
    "print(raw_pd)\n",
    "dcm2.init_dataset_df(raw_pd)\n",
    "\n",
    "prev_df = raw_pd\n",
    "\n",
    "for x in op2.get_all_state_command().sort_values(\"state_id\",ascending=False).to_records():\n",
    "    ops = json.loads(x[5])[\"operation\"]\n",
    "    print(ops)\n",
    "    now_df = op2.get_snapshot_at_state(int(op2.get_state_to_step(x.state_id)+1))\n",
    "    print(now_df)\n",
    "    dcm2.curr_col = prev_df.columns\n",
    "    dcm2.curr_row = list(prev_df.index) \n",
    "    dcm2.curr_df = prev_df \n",
    "    dcm2.change_df(prev_df,now_df,json.loads(x[5]))\n",
    "    prev_df = now_df\n",
    "\n",
    "\n",
    "    #op2.get_snapshot_at_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Entrance Date 1', 3, -1),\n",
       "  (5, 5, 4, 'Entrance Date 2', 4, -1),\n",
       "  (6, 6, 4, 'Entrance Date 3', 5, -1),\n",
       "  (7, 4, 5, 'Year', 3, 4),\n",
       "  (8, 5, 6, 'Month', 4, 5),\n",
       "  (9, 4, 7, 'Entry Year', 3, 7),\n",
       "  (10, 5, 8, 'Entry Month', 4, 8),\n",
       "  (11, 6, 9, 'Entry Date', 5, 6),\n",
       "  (12, 7, 17, 'Archived Delay', 6, -1)],\n",
       " [('Book Title', 0, 0, -1),\n",
       "  ('Author', 1, 1, 0),\n",
       "  ('Date', 2, 2, 1),\n",
       "  ('Entrance Date', 3, 3, 2),\n",
       "  ('Entry Year', 9, 4, 3),\n",
       "  ('Entry Month', 10, 5, 4),\n",
       "  ('Entry Date', 11, 6, 5),\n",
       "  ('Archived Delay', 12, 7, 6)])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.column_position,dcm2.curr_col_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Book Title', 0, 0, -1),\n",
       " ('Author', 1, 1, 0),\n",
       " ('Date', 2, 2, 1),\n",
       " ('Entrance Date', 3, 3, 2),\n",
       " ('Entry Year', 9, 4, 3),\n",
       " ('Entry Month', 10, 5, 4),\n",
       " ('Entry Date', 11, 6, 5),\n",
       " ('Archived Delay', 12, 7, 6)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.curr_col_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, -1, -1),\n",
       "  (1, -1, -1),\n",
       "  (2, -1, -1),\n",
       "  (3, -1, -1),\n",
       "  (4, -1, -1),\n",
       "  (5, -1, -1),\n",
       "  (6, -1, -1),\n",
       "  (7, -1, -1),\n",
       "  (8, -1, -1),\n",
       "  (9, -1, -1),\n",
       "  (10, -1, -1),\n",
       "  (11, -1, -1),\n",
       "  (12, -1, -1),\n",
       "  (13, -1, -1),\n",
       "  (14, -1, -1),\n",
       "  (15, -1, -1),\n",
       "  (16, 4, 3),\n",
       "  (17, 4, 7),\n",
       "  (18, 4, 11),\n",
       "  (19, 4, 15),\n",
       "  (20, 4, 3),\n",
       "  (21, 4, 7),\n",
       "  (22, 4, 11),\n",
       "  (23, 4, 15),\n",
       "  (24, 4, 3),\n",
       "  (25, 4, 7),\n",
       "  (26, 4, 11),\n",
       "  (27, 4, 15),\n",
       "  (28, 10, 2),\n",
       "  (29, 10, 6),\n",
       "  (30, 10, 10),\n",
       "  (31, 10, 14),\n",
       "  (32, 11, 26),\n",
       "  (33, 12, 22),\n",
       "  (34, 13, 18),\n",
       "  (35, 14, 27),\n",
       "  (36, 15, 23),\n",
       "  (37, 17, 16),\n",
       "  (37, 17, 28),\n",
       "  (38, 17, 17),\n",
       "  (38, 17, 29),\n",
       "  (39, 17, 34),\n",
       "  (39, 17, 30),\n",
       "  (40, 17, 19),\n",
       "  (40, 17, 31)],\n",
       " [(0, 0, -1, 'Against Method', -1),\n",
       "  (1, 1, -1, 'Feyerabend, P.', -1),\n",
       "  (2, 2, -1, ' 1975', -1),\n",
       "  (3, 3, -1, '1996-02-01', -1),\n",
       "  (4, 4, -1, 'Changing Order', -1),\n",
       "  (5, 5, -1, 'Collins, H.M.', -1),\n",
       "  (6, 6, -1, ' 1985', -1),\n",
       "  (7, 7, -1, '2003-12-31', -1),\n",
       "  (8, 8, -1, 'Exceeding Our Grasp', -1),\n",
       "  (9, 9, -1, ' P. Kyle Stanford', -1),\n",
       "  (10, 10, -1, ' 2006', -1),\n",
       "  (11, 11, -1, 'Feb, 29 2008', -1),\n",
       "  (12, 12, -1, 'Theory of Information', -1),\n",
       "  (13, 13, -1, ' ', -1),\n",
       "  (14, 14, -1, ' 1992', -1),\n",
       "  (15, 15, -1, '2010-31-01', -1),\n",
       "  (16, 16, 4, '1996', -1),\n",
       "  (17, 17, 4, '2003', -1),\n",
       "  (18, 18, 4, 'Feb, 29 2008', -1),\n",
       "  (19, 19, 4, '2010', -1),\n",
       "  (20, 20, 4, '2', -1),\n",
       "  (21, 21, 4, '12', -1),\n",
       "  (22, 22, 4, '', -1),\n",
       "  (23, 23, 4, '31', -1),\n",
       "  (24, 24, 4, '1', -1),\n",
       "  (25, 25, 4, '31', -1),\n",
       "  (26, 26, 4, '', -1),\n",
       "  (27, 27, 4, '1', -1),\n",
       "  (28, 2, 10, '1975', 2),\n",
       "  (29, 6, 10, '1985', 6),\n",
       "  (30, 10, 10, '2006', 10),\n",
       "  (31, 14, 10, '1992', 14),\n",
       "  (32, 26, 11, '29', 26),\n",
       "  (33, 22, 12, '2', 22),\n",
       "  (34, 18, 13, '2008', 18),\n",
       "  (35, 27, 14, '31', 27),\n",
       "  (36, 23, 15, '1', 23),\n",
       "  (37, 28, 17, '21', -1),\n",
       "  (38, 29, 17, '18', -1),\n",
       "  (39, 30, 17, '2', -1),\n",
       "  (40, 31, 17, '18', -1)])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.value_derived_from,dcm2.cell_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, {'op': 'initial'}),\n",
       " (0,\n",
       "  {'id': 1629921348453,\n",
       "   'description': \"Text transform on 0 cells in column Book Title: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Book Title',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (1,\n",
       "  {'id': 1629921434653,\n",
       "   'description': \"Text transform on 0 cells in column Author: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Author',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (2,\n",
       "  {'id': 1629922031446,\n",
       "   'description': \"Text transform on 0 cells in column Date: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Date',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (3,\n",
       "  {'id': 1629921667846,\n",
       "   'description': \"Text transform on 0 cells in column Entrance Date: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entrance Date',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Entrance Date using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (4,\n",
       "  {'id': 1629921639511,\n",
       "   'description': 'Split 4 cell(s) in column Entrance Date into several columns by separator',\n",
       "   'operation': {'op': 'core/column-split',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entrance Date',\n",
       "    'guessCellType': True,\n",
       "    'removeOriginalColumn': False,\n",
       "    'mode': 'separator',\n",
       "    'separator': '-',\n",
       "    'regex': False,\n",
       "    'maxColumns': 0,\n",
       "    'description': 'Split column Entrance Date by separator'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (5,\n",
       "  {'id': 1629921966580,\n",
       "   'description': 'Rename column Entrance Date 1 to Year',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 1',\n",
       "    'newColumnName': 'Year',\n",
       "    'description': 'Rename column Entrance Date 1 to Year'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (6,\n",
       "  {'id': 1629921643378,\n",
       "   'description': 'Rename column Entrance Date 2 to Month',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 2',\n",
       "    'newColumnName': 'Month',\n",
       "    'description': 'Rename column Entrance Date 2 to Month'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (7,\n",
       "  {'id': 1629921237421,\n",
       "   'description': 'Rename column Year to Entry Year',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Year',\n",
       "    'newColumnName': 'Entry Year',\n",
       "    'description': 'Rename column Year to Entry Year'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (8,\n",
       "  {'id': 1629921956381,\n",
       "   'description': 'Rename column Month to Entry Month',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Month',\n",
       "    'newColumnName': 'Entry Month',\n",
       "    'description': 'Rename column Month to Entry Month'},\n",
       "   'time': '2021-08-25T19:53:36Z'}),\n",
       " (9,\n",
       "  {'id': 1629921803356,\n",
       "   'description': 'Rename column Entrance Date 3 to Entry Date',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 3',\n",
       "    'newColumnName': 'Entry Date',\n",
       "    'description': 'Rename column Entrance Date 3 to Entry Date'},\n",
       "   'time': '2021-08-25T19:53:36Z'}),\n",
       " (10,\n",
       "  {'id': 1629921239394,\n",
       "   'description': 'Text transform on 4 cells in column Date: value.toNumber()',\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Date',\n",
       "    'expression': 'value.toNumber()',\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': 'Text transform on cells in column Date using expression value.toNumber()'},\n",
       "   'time': '2021-08-25T19:53:47Z'}),\n",
       " (11,\n",
       "  {'id': 1629921919709,\n",
       "   'description': 'Edit single cell on row 3, column Entry Date',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:13Z'}),\n",
       " (12,\n",
       "  {'id': 1629921743490,\n",
       "   'description': 'Edit single cell on row 3, column Entry Month',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:21Z'}),\n",
       " (13,\n",
       "  {'id': 1629922217234,\n",
       "   'description': 'Edit single cell on row 3, column Entry Year',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:27Z'}),\n",
       " (14,\n",
       "  {'id': 1629921919624,\n",
       "   'description': 'Edit single cell on row 4, column Entry Date',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:34Z'}),\n",
       " (15,\n",
       "  {'id': 1629922206801,\n",
       "   'description': 'Edit single cell on row 4, column Entry Month',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:51Z'}),\n",
       " (16,\n",
       "  {'id': 1629921632247,\n",
       "   'description': 'Text transform on 0 cells in column Entry Year: value.toNumber()',\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entry Year',\n",
       "    'expression': 'value.toNumber()',\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': 'Text transform on cells in column Entry Year using expression value.toNumber()'},\n",
       "   'time': '2021-08-25T19:57:41Z'}),\n",
       " (17,\n",
       "  {'id': 1629922420062,\n",
       "   'description': 'Create new column Archived Delay based on column Entry Year by filling 4 rows with grel:value - cells[\"Date\"].value',\n",
       "   'operation': {'op': 'core/column-addition',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'baseColumnName': 'Entry Year',\n",
       "    'expression': 'grel:value - cells[\"Date\"].value',\n",
       "    'onError': 'set-to-blank',\n",
       "    'newColumnName': 'Archived Delay',\n",
       "    'columnInsertIndex': 7,\n",
       "    'description': 'Create column Archived Delay at index 7 based on column Entry Year using expression grel:value - cells[\"Date\"].value'},\n",
       "   'time': '2021-08-25T19:57:41Z'})]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.state_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_values_state -1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Entrance Date</th>\n",
       "      <th>Entry Year</th>\n",
       "      <th>Entry Month</th>\n",
       "      <th>Entry Date</th>\n",
       "      <th>Archived Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Against Method, 0, 0)</td>\n",
       "      <td>(Feyerabend, P., 0, 1)</td>\n",
       "      <td>(1975, 0, 2)</td>\n",
       "      <td>(1996-02-01, 0, 3)</td>\n",
       "      <td>(1996, 0, 4)</td>\n",
       "      <td>(2, 0, 5)</td>\n",
       "      <td>(1, 0, 6)</td>\n",
       "      <td>(21, 0, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Changing Order, 1, 0)</td>\n",
       "      <td>(Collins, H.M., 1, 1)</td>\n",
       "      <td>(1985, 1, 2)</td>\n",
       "      <td>(2003-12-31, 1, 3)</td>\n",
       "      <td>(2003, 1, 4)</td>\n",
       "      <td>(12, 1, 5)</td>\n",
       "      <td>(31, 1, 6)</td>\n",
       "      <td>(18, 1, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Exceeding Our Grasp, 2, 0)</td>\n",
       "      <td>( P. Kyle Stanford, 2, 1)</td>\n",
       "      <td>(2006, 2, 2)</td>\n",
       "      <td>(Feb, 29 2008, 2, 3)</td>\n",
       "      <td>(2008, 2, 4)</td>\n",
       "      <td>(2, 2, 5)</td>\n",
       "      <td>(29, 2, 6)</td>\n",
       "      <td>(2, 2, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Theory of Information, 3, 0)</td>\n",
       "      <td>( , 3, 1)</td>\n",
       "      <td>(1992, 3, 2)</td>\n",
       "      <td>(2010-31-01, 3, 3)</td>\n",
       "      <td>(2010, 3, 4)</td>\n",
       "      <td>(1, 3, 5)</td>\n",
       "      <td>(31, 3, 6)</td>\n",
       "      <td>(18, 3, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Book Title                     Author          Date  \\\n",
       "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
       "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
       "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
       "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
       "\n",
       "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
       "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
       "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
       "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
       "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)     (18, 3, 7)  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2.get_snapshot_at_state(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, -1, 'Book Title', -1, -1),\n",
       " (1, 1, -1, 'Author', 0, -1),\n",
       " (2, 2, -1, 'Date', 1, -1),\n",
       " (3, 3, -1, 'Entrance Date', 2, -1),\n",
       " (4, 4, 4, 'Entrance Date 1', 3, -1),\n",
       " (5, 5, 4, 'Entrance Date 2', 4, -1),\n",
       " (6, 6, 4, 'Entrance Date 3', 5, -1),\n",
       " (7, 1, 5, 'Author', 0, 1),\n",
       " (8, 2, 5, 'Date', 1, 2),\n",
       " (9, 3, 5, 'Entrance Date', 2, 3),\n",
       " (10, 4, 5, 'Year', 3, 4),\n",
       " (11, 5, 5, 'Entrance Date 2', 4, 5),\n",
       " (12, 6, 5, 'Entrance Date 3', 5, 6),\n",
       " (13, 1, 6, 'Author', 0, 1),\n",
       " (14, 2, 6, 'Date', 1, 2),\n",
       " (15, 3, 6, 'Entrance Date', 2, 3),\n",
       " (16, 4, 6, 'Year', 3, 4),\n",
       " (17, 5, 6, 'Month', 4, 5),\n",
       " (18, 6, 6, 'Entrance Date 3', 5, 6),\n",
       " (19, 1, 7, 'Author', 0, 1),\n",
       " (20, 2, 7, 'Date', 1, 2),\n",
       " (21, 3, 7, 'Entrance Date', 2, 3),\n",
       " (22, 4, 7, 'Entry Year', 3, 4),\n",
       " (23, 5, 7, 'Month', 4, 5),\n",
       " (24, 6, 7, 'Entrance Date 3', 5, 6),\n",
       " (25, 1, 8, 'Author', 0, 1),\n",
       " (26, 2, 8, 'Date', 1, 2),\n",
       " (27, 3, 8, 'Entrance Date', 2, 3),\n",
       " (28, 4, 8, 'Entry Year', 3, 4),\n",
       " (29, 5, 8, 'Entry Month', 4, 5),\n",
       " (30, 6, 8, 'Entrance Date 3', 5, 6),\n",
       " (31, 1, 9, 'Author', 0, 1),\n",
       " (32, 2, 9, 'Date', 1, 2),\n",
       " (33, 3, 9, 'Entrance Date', 2, 3),\n",
       " (34, 4, 9, 'Entry Year', 3, 4),\n",
       " (35, 5, 9, 'Entry Month', 4, 5),\n",
       " (36, 6, 9, 'Entry Date', 5, 6),\n",
       " (37, 7, 17, 'Archived Delay', 36, -1)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.column_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1, 2)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x:x[0]==9,dcm1.cell))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(now_df.columns) - set(prev_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Against Method', -1),\n",
       "  (1, 1, -1, 'Feyerabend, P.', -1),\n",
       "  (2, 2, -1, ' 1975', -1),\n",
       "  (3, 3, -1, '1996-02-01', -1),\n",
       "  (4, 4, -1, 'Changing Order', -1),\n",
       "  (5, 5, -1, 'Collins, H.M.', -1),\n",
       "  (6, 6, -1, ' 1985', -1),\n",
       "  (7, 7, -1, '2003-12-31', -1),\n",
       "  (8, 8, -1, 'Exceeding Our Grasp', -1),\n",
       "  (9, 9, -1, ' P. Kyle Stanford', -1),\n",
       "  (10, 10, -1, ' 2006', -1),\n",
       "  (11, 11, -1, 'Feb, 29 2008', -1),\n",
       "  (12, 12, -1, 'Theory of Information', -1),\n",
       "  (13, 13, -1, ' ', -1),\n",
       "  (14, 14, -1, ' 1992', -1),\n",
       "  (15, 15, -1, '2010-31-01', -1),\n",
       "  (16, 9, 3, 'Stanford, P. Kyle', 9),\n",
       "  (17, 16, 4, 'Feyerabend', -1),\n",
       "  (18, 17, 4, 'Collins', -1),\n",
       "  (19, 18, 4, 'Stanford', -1),\n",
       "  (20, 19, 4, ' ', -1),\n",
       "  (21, 20, 4, ' P.', -1),\n",
       "  (22, 21, 4, ' H.M.', -1),\n",
       "  (23, 22, 4, ' P. Kyle', -1),\n",
       "  (24, 23, 4, None, -1),\n",
       "  (25, 2, 8, '1975', 2),\n",
       "  (26, 6, 8, '1985', 6),\n",
       "  (27, 10, 8, '2006', 10),\n",
       "  (28, 14, 8, '1992', 14)],\n",
       " [(0, 0, -1, 'Against Method', -1),\n",
       "  (1, 1, -1, 'Feyerabend, P.', -1),\n",
       "  (2, 2, -1, ' 1975', -1),\n",
       "  (3, 3, -1, '1996-02-01', -1),\n",
       "  (4, 4, -1, 'Changing Order', -1),\n",
       "  (5, 5, -1, 'Collins, H.M.', -1),\n",
       "  (6, 6, -1, ' 1985', -1),\n",
       "  (7, 7, -1, '2003-12-31', -1),\n",
       "  (8, 8, -1, 'Exceeding Our Grasp', -1),\n",
       "  (9, 9, -1, ' P. Kyle Stanford', -1),\n",
       "  (10, 10, -1, ' 2006', -1),\n",
       "  (11, 11, -1, 'Feb, 29 2008', -1),\n",
       "  (12, 12, -1, 'Theory of Information', -1),\n",
       "  (13, 13, -1, ' ', -1),\n",
       "  (14, 14, -1, ' 1992', -1),\n",
       "  (15, 15, -1, '2010-31-01', -1),\n",
       "  (16, 16, 4, '1996', -1),\n",
       "  (17, 17, 4, '2003', -1),\n",
       "  (18, 18, 4, 'Feb, 29 2008', -1),\n",
       "  (19, 19, 4, '2010', -1),\n",
       "  (20, 20, 4, '2', -1),\n",
       "  (21, 21, 4, '12', -1),\n",
       "  (22, 22, 4, '', -1),\n",
       "  (23, 23, 4, '31', -1),\n",
       "  (24, 24, 4, '1', -1),\n",
       "  (25, 25, 4, '31', -1),\n",
       "  (26, 26, 4, '', -1),\n",
       "  (27, 27, 4, '1', -1),\n",
       "  (28, 2, 10, '1975', 2),\n",
       "  (29, 6, 10, '1985', 6),\n",
       "  (30, 10, 10, '2006', 10),\n",
       "  (31, 14, 10, '1992', 14),\n",
       "  (32, 26, 11, '29', 26),\n",
       "  (33, 22, 12, '2', 22),\n",
       "  (34, 18, 13, '2008', 18),\n",
       "  (35, 27, 14, '31', 27),\n",
       "  (36, 23, 15, '1', 23),\n",
       "  (37, 28, 17, '21', -1),\n",
       "  (38, 29, 17, '18', -1),\n",
       "  (39, 30, 17, '2', -1),\n",
       "  (40, 31, 17, '18', -1)])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.cell_values,dcm2.cell_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, 0),\n",
       "  (1, 1, 1),\n",
       "  (2, 2, 2),\n",
       "  (3, 1, 1),\n",
       "  (4, 4, 1),\n",
       "  (4, 5, 1),\n",
       "  (5, 4, 4),\n",
       "  (6, 5, 5),\n",
       "  (8, 2, 2)],\n",
       " [(0, 0, 0),\n",
       "  (1, 1, 1),\n",
       "  (2, 2, 2),\n",
       "  (3, 3, 3),\n",
       "  (4, 4, 3),\n",
       "  (4, 5, 3),\n",
       "  (4, 6, 3),\n",
       "  (5, 4, 4),\n",
       "  (6, 5, 5),\n",
       "  (7, 4, 4),\n",
       "  (8, 5, 5),\n",
       "  (9, 6, 6),\n",
       "  (10, 2, 2),\n",
       "  (16, 4, 4),\n",
       "  (17, 7, 4),\n",
       "  (17, 7, 2)])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.col_dependency,dcm2.col_dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, {'op': 'initial'}),\n",
       " (0,\n",
       "  {'id': 1629921348453,\n",
       "   'description': \"Text transform on 0 cells in column Book Title: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Book Title',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (1,\n",
       "  {'id': 1629921434653,\n",
       "   'description': \"Text transform on 0 cells in column Author: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Author',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (2,\n",
       "  {'id': 1629922031446,\n",
       "   'description': \"Text transform on 0 cells in column Date: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Date',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (3,\n",
       "  {'id': 1629921667846,\n",
       "   'description': \"Text transform on 0 cells in column Entrance Date: value.replace(/\\\\s+/,' ')\",\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entrance Date',\n",
       "    'expression': \"value.replace(/\\\\s+/,' ')\",\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': \"Text transform on cells in column Entrance Date using expression value.replace(/\\\\s+/,' ')\"},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (4,\n",
       "  {'id': 1629921639511,\n",
       "   'description': 'Split 4 cell(s) in column Entrance Date into several columns by separator',\n",
       "   'operation': {'op': 'core/column-split',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entrance Date',\n",
       "    'guessCellType': True,\n",
       "    'removeOriginalColumn': False,\n",
       "    'mode': 'separator',\n",
       "    'separator': '-',\n",
       "    'regex': False,\n",
       "    'maxColumns': 0,\n",
       "    'description': 'Split column Entrance Date by separator'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (5,\n",
       "  {'id': 1629921966580,\n",
       "   'description': 'Rename column Entrance Date 1 to Year',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 1',\n",
       "    'newColumnName': 'Year',\n",
       "    'description': 'Rename column Entrance Date 1 to Year'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (6,\n",
       "  {'id': 1629921643378,\n",
       "   'description': 'Rename column Entrance Date 2 to Month',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 2',\n",
       "    'newColumnName': 'Month',\n",
       "    'description': 'Rename column Entrance Date 2 to Month'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (7,\n",
       "  {'id': 1629921237421,\n",
       "   'description': 'Rename column Year to Entry Year',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Year',\n",
       "    'newColumnName': 'Entry Year',\n",
       "    'description': 'Rename column Year to Entry Year'},\n",
       "   'time': '2021-08-25T19:53:35Z'}),\n",
       " (8,\n",
       "  {'id': 1629921956381,\n",
       "   'description': 'Rename column Month to Entry Month',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Month',\n",
       "    'newColumnName': 'Entry Month',\n",
       "    'description': 'Rename column Month to Entry Month'},\n",
       "   'time': '2021-08-25T19:53:36Z'}),\n",
       " (9,\n",
       "  {'id': 1629921803356,\n",
       "   'description': 'Rename column Entrance Date 3 to Entry Date',\n",
       "   'operation': {'op': 'core/column-rename',\n",
       "    'oldColumnName': 'Entrance Date 3',\n",
       "    'newColumnName': 'Entry Date',\n",
       "    'description': 'Rename column Entrance Date 3 to Entry Date'},\n",
       "   'time': '2021-08-25T19:53:36Z'}),\n",
       " (10,\n",
       "  {'id': 1629921239394,\n",
       "   'description': 'Text transform on 4 cells in column Date: value.toNumber()',\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Date',\n",
       "    'expression': 'value.toNumber()',\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': 'Text transform on cells in column Date using expression value.toNumber()'},\n",
       "   'time': '2021-08-25T19:53:47Z'}),\n",
       " (11,\n",
       "  {'id': 1629921919709,\n",
       "   'description': 'Edit single cell on row 3, column Entry Date',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:13Z'}),\n",
       " (12,\n",
       "  {'id': 1629921743490,\n",
       "   'description': 'Edit single cell on row 3, column Entry Month',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:21Z'}),\n",
       " (13,\n",
       "  {'id': 1629922217234,\n",
       "   'description': 'Edit single cell on row 3, column Entry Year',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:27Z'}),\n",
       " (14,\n",
       "  {'id': 1629921919624,\n",
       "   'description': 'Edit single cell on row 4, column Entry Date',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:34Z'}),\n",
       " (15,\n",
       "  {'id': 1629922206801,\n",
       "   'description': 'Edit single cell on row 4, column Entry Month',\n",
       "   'operation': None,\n",
       "   'time': '2021-08-25T19:55:51Z'}),\n",
       " (16,\n",
       "  {'id': 1629921632247,\n",
       "   'description': 'Text transform on 0 cells in column Entry Year: value.toNumber()',\n",
       "   'operation': {'op': 'core/text-transform',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'columnName': 'Entry Year',\n",
       "    'expression': 'value.toNumber()',\n",
       "    'onError': 'keep-original',\n",
       "    'repeat': False,\n",
       "    'repeatCount': 10,\n",
       "    'description': 'Text transform on cells in column Entry Year using expression value.toNumber()'},\n",
       "   'time': '2021-08-25T19:57:41Z'}),\n",
       " (17,\n",
       "  {'id': 1629922420062,\n",
       "   'description': 'Create new column Archived Delay based on column Entry Year by filling 4 rows with grel:value - cells[\"Date\"].value',\n",
       "   'operation': {'op': 'core/column-addition',\n",
       "    'engineConfig': {'facets': [], 'mode': 'row-based'},\n",
       "    'baseColumnName': 'Entry Year',\n",
       "    'expression': 'grel:value - cells[\"Date\"].value',\n",
       "    'onError': 'set-to-blank',\n",
       "    'newColumnName': 'Archived Delay',\n",
       "    'columnInsertIndex': 7,\n",
       "    'description': 'Create column Archived Delay at index 7 based on column Entry Year using expression grel:value - cells[\"Date\"].value'},\n",
       "   'time': '2021-08-25T19:57:41Z'})]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2.state_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, -1, -1),\n",
       "  (1, -1, -1),\n",
       "  (2, -1, -1),\n",
       "  (3, -1, -1),\n",
       "  (4, -1, -1),\n",
       "  (5, -1, -1),\n",
       "  (6, -1, -1),\n",
       "  (7, -1, -1),\n",
       "  (8, -1, -1),\n",
       "  (9, -1, -1),\n",
       "  (10, -1, -1),\n",
       "  (11, -1, -1),\n",
       "  (12, -1, -1),\n",
       "  (13, -1, -1),\n",
       "  (14, -1, -1),\n",
       "  (15, -1, -1),\n",
       "  (16, 3, 9),\n",
       "  (17, 4, 1),\n",
       "  (18, 4, 5),\n",
       "  (19, 4, 16),\n",
       "  (20, 4, 13),\n",
       "  (21, 4, 1),\n",
       "  (22, 4, 5),\n",
       "  (23, 4, 16),\n",
       "  (24, 4, 13),\n",
       "  (25, 8, 2),\n",
       "  (26, 8, 6),\n",
       "  (27, 8, 10),\n",
       "  (28, 8, 14)],\n",
       " [(0, -1, -1),\n",
       "  (1, -1, -1),\n",
       "  (2, -1, -1),\n",
       "  (3, -1, -1),\n",
       "  (4, -1, -1),\n",
       "  (5, -1, -1),\n",
       "  (6, -1, -1),\n",
       "  (7, -1, -1),\n",
       "  (8, -1, -1),\n",
       "  (9, -1, -1),\n",
       "  (10, -1, -1),\n",
       "  (11, -1, -1),\n",
       "  (12, -1, -1),\n",
       "  (13, -1, -1),\n",
       "  (14, -1, -1),\n",
       "  (15, -1, -1),\n",
       "  (16, 4, 3),\n",
       "  (17, 4, 7),\n",
       "  (18, 4, 11),\n",
       "  (19, 4, 15),\n",
       "  (20, 4, 3),\n",
       "  (21, 4, 7),\n",
       "  (22, 4, 11),\n",
       "  (23, 4, 15),\n",
       "  (24, 4, 3),\n",
       "  (25, 4, 7),\n",
       "  (26, 4, 11),\n",
       "  (27, 4, 15),\n",
       "  (28, 10, 2),\n",
       "  (29, 10, 6),\n",
       "  (30, 10, 10),\n",
       "  (31, 10, 14),\n",
       "  (32, 11, 26),\n",
       "  (33, 12, 22),\n",
       "  (34, 13, 18),\n",
       "  (35, 14, 27),\n",
       "  (36, 15, 23),\n",
       "  (37, 17, 16),\n",
       "  (37, 17, 28),\n",
       "  (38, 17, 17),\n",
       "  (38, 17, 29),\n",
       "  (39, 17, 34),\n",
       "  (39, 17, 30),\n",
       "  (40, 17, 19),\n",
       "  (40, 17, 31)])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.value_derived_from,dcm2.value_derived_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm1_val_pd = pd.DataFrame(dcm1.cell_values)\n",
    "dcm2_val_pd = pd.DataFrame(dcm2.cell_values)\n",
    "dcm1_cell_pd = pd.DataFrame(dcm1.cell)\n",
    "dcm2_cell_pd = pd.DataFrame(dcm2.cell)\n",
    "dcm1_col_pd = pd.DataFrame(dcm1.column)\n",
    "dcm2_col_pd = pd.DataFrame(dcm2.column)\n",
    "dcm1_row_pd = pd.DataFrame(dcm1.row)\n",
    "dcm2_row_pd = pd.DataFrame(dcm2.row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2\n",
       "0    0  0  0\n",
       "1    1  1  0\n",
       "2    2  2  0\n",
       "3    3  3  0\n",
       "4    4  0  1\n",
       "5    5  1  1\n",
       "6    6  2  1\n",
       "7    7  3  1\n",
       "8    8  0  2\n",
       "9    9  1  2\n",
       "10  10  2  2\n",
       "11  11  3  2\n",
       "12  12  0  3\n",
       "13  13  1  3\n",
       "14  14  2  3\n",
       "15  15  3  3\n",
       "16  16  4  0\n",
       "17  17  4  1\n",
       "18  18  4  2\n",
       "19  19  4  3\n",
       "20  20  5  0\n",
       "21  21  5  1\n",
       "22  22  5  2\n",
       "23  23  5  3"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1_cell_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Against Method</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Feyerabend, P.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1975</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1996-02-01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Changing Order</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>Collins, H.M.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>1985</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>Exceeding Our Grasp</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>P. Kyle Stanford</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>2006</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>Feb, 29 2008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>Theory of Information</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>1992</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-31-01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1996</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2003</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Feb, 29 2008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1985</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1992</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2                      3   4\n",
       "0    0   0  -1         Against Method  -1\n",
       "1    1   1  -1         Feyerabend, P.  -1\n",
       "2    2   2  -1                   1975  -1\n",
       "3    3   3  -1             1996-02-01  -1\n",
       "4    4   4  -1         Changing Order  -1\n",
       "5    5   5  -1          Collins, H.M.  -1\n",
       "6    6   6  -1                   1985  -1\n",
       "7    7   7  -1             2003-12-31  -1\n",
       "8    8   8  -1    Exceeding Our Grasp  -1\n",
       "9    9   9  -1       P. Kyle Stanford  -1\n",
       "10  10  10  -1                   2006  -1\n",
       "11  11  11  -1           Feb, 29 2008  -1\n",
       "12  12  12  -1  Theory of Information  -1\n",
       "13  13  13  -1                         -1\n",
       "14  14  14  -1                   1992  -1\n",
       "15  15  15  -1             2010-31-01  -1\n",
       "16  16  16   4                   1996  -1\n",
       "17  17  17   4                   2003  -1\n",
       "18  18  18   4           Feb, 29 2008  -1\n",
       "19  19  19   4                   2010  -1\n",
       "20  20  20   4                      2  -1\n",
       "21  21  21   4                     12  -1\n",
       "22  22  22   4                         -1\n",
       "23  23  23   4                     31  -1\n",
       "24  24  24   4                      1  -1\n",
       "25  25  25   4                     31  -1\n",
       "26  26  26   4                         -1\n",
       "27  27  27   4                      1  -1\n",
       "28  28   2  10                   1975   2\n",
       "29  29   6  10                   1985   6\n",
       "30  30  10  10                   2006  10\n",
       "31  31  14  10                   1992  14\n",
       "32  32  26  11                     29  26\n",
       "33  33  22  12                      2  22\n",
       "34  34  18  13                   2008  18\n",
       "35  35  27  14                     31  27\n",
       "36  36  23  15                      1  23\n",
       "37  37  28  17                     21  -1\n",
       "38  38  29  17                     18  -1\n",
       "39  39  30  17                      2  -1\n",
       "40  40  31  17                     18  -1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm2_val_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (1, 0), (2, 0), (3, 0)], [(0, 0), (1, 0), (2, 0), (3, 0)])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align row\n",
    "dcm1.row,dcm2.row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Author 1', 1, -1),\n",
       "  (5, 5, 4, 'Author 2', 4, -1),\n",
       "  (6, 1, 5, 'Author', 0, 1),\n",
       "  (7, 4, 5, 'Last Name', 1, 4),\n",
       "  (8, 5, 5, 'Author 2', 4, 5),\n",
       "  (9, 2, 5, 'Date', 5, 2),\n",
       "  (10, 3, 5, 'Entrance Date', 2, 3),\n",
       "  (11, 1, 6, 'Author', 0, 1),\n",
       "  (12, 4, 6, 'Last Name', 1, 4),\n",
       "  (13, 5, 6, 'First Name', 2, 5),\n",
       "  (14, 2, 6, 'Date', 5, 2),\n",
       "  (15, 3, 6, 'Entrance Date', 2, 3)],\n",
       " [(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Entrance Date 1', 3, -1),\n",
       "  (5, 5, 4, 'Entrance Date 2', 4, -1),\n",
       "  (6, 6, 4, 'Entrance Date 3', 5, -1),\n",
       "  (7, 1, 5, 'Author', 0, 1),\n",
       "  (8, 2, 5, 'Date', 1, 2),\n",
       "  (9, 3, 5, 'Entrance Date', 2, 3),\n",
       "  (10, 4, 5, 'Year', 3, 4),\n",
       "  (11, 5, 5, 'Entrance Date 2', 4, 5),\n",
       "  (12, 6, 5, 'Entrance Date 3', 5, 6),\n",
       "  (13, 1, 6, 'Author', 0, 1),\n",
       "  (14, 2, 6, 'Date', 1, 2),\n",
       "  (15, 3, 6, 'Entrance Date', 2, 3),\n",
       "  (16, 4, 6, 'Year', 3, 4),\n",
       "  (17, 5, 6, 'Month', 4, 5),\n",
       "  (18, 6, 6, 'Entrance Date 3', 5, 6),\n",
       "  (19, 1, 7, 'Author', 0, 1),\n",
       "  (20, 2, 7, 'Date', 1, 2),\n",
       "  (21, 3, 7, 'Entrance Date', 2, 3),\n",
       "  (22, 4, 7, 'Entry Year', 3, 4),\n",
       "  (23, 5, 7, 'Month', 4, 5),\n",
       "  (24, 6, 7, 'Entrance Date 3', 5, 6),\n",
       "  (25, 1, 8, 'Author', 0, 1),\n",
       "  (26, 2, 8, 'Date', 1, 2),\n",
       "  (27, 3, 8, 'Entrance Date', 2, 3),\n",
       "  (28, 4, 8, 'Entry Year', 3, 4),\n",
       "  (29, 5, 8, 'Entry Month', 4, 5),\n",
       "  (30, 6, 8, 'Entrance Date 3', 5, 6),\n",
       "  (31, 1, 9, 'Author', 0, 1),\n",
       "  (32, 2, 9, 'Date', 1, 2),\n",
       "  (33, 3, 9, 'Entrance Date', 2, 3),\n",
       "  (34, 4, 9, 'Entry Year', 3, 4),\n",
       "  (35, 5, 9, 'Entry Month', 4, 5),\n",
       "  (36, 6, 9, 'Entry Date', 5, 6),\n",
       "  (37, 7, 17, 'Archived Delay', 36, -1)])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align schema\n",
    "dcm1.column_position,dcm2.column_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0)],\n",
       " [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0)])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align column\n",
    "dcm1.column,dcm2.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Against Method', -1),\n",
       "  (1, 1, -1, 'Feyerabend, P.', -1),\n",
       "  (2, 2, -1, ' 1975', -1),\n",
       "  (3, 3, -1, '1996-02-01', -1),\n",
       "  (4, 4, -1, 'Changing Order', -1),\n",
       "  (5, 5, -1, 'Collins, H.M.', -1),\n",
       "  (6, 6, -1, ' 1985', -1),\n",
       "  (7, 7, -1, '2003-12-31', -1),\n",
       "  (8, 8, -1, 'Exceeding Our Grasp', -1),\n",
       "  (9, 9, -1, ' P. Kyle Stanford', -1),\n",
       "  (10, 10, -1, ' 2006', -1),\n",
       "  (11, 11, -1, 'Feb, 29 2008', -1),\n",
       "  (12, 12, -1, 'Theory of Information', -1),\n",
       "  (13, 13, -1, ' ', -1),\n",
       "  (14, 14, -1, ' 1992', -1),\n",
       "  (15, 15, -1, '2010-31-01', -1),\n",
       "  (16, 9, 3, 'Stanford, P. Kyle', 9),\n",
       "  (17, 16, 4, 'Feyerabend', -1),\n",
       "  (18, 17, 4, 'Collins', -1),\n",
       "  (19, 18, 4, 'Stanford', -1),\n",
       "  (20, 19, 4, ' ', -1),\n",
       "  (21, 20, 4, ' P.', -1),\n",
       "  (22, 21, 4, ' H.M.', -1),\n",
       "  (23, 22, 4, ' P. Kyle', -1),\n",
       "  (24, 23, 4, None, -1),\n",
       "  (25, 2, 8, '1975', 2),\n",
       "  (26, 6, 8, '1985', 6),\n",
       "  (27, 10, 8, '2006', 10),\n",
       "  (28, 14, 8, '1992', 14)],\n",
       " [(0, 0, -1, 'Against Method', -1),\n",
       "  (1, 1, -1, 'Feyerabend, P.', -1),\n",
       "  (2, 2, -1, ' 1975', -1),\n",
       "  (3, 3, -1, '1996-02-01', -1),\n",
       "  (4, 4, -1, 'Changing Order', -1),\n",
       "  (5, 5, -1, 'Collins, H.M.', -1),\n",
       "  (6, 6, -1, ' 1985', -1),\n",
       "  (7, 7, -1, '2003-12-31', -1),\n",
       "  (8, 8, -1, 'Exceeding Our Grasp', -1),\n",
       "  (9, 9, -1, ' P. Kyle Stanford', -1),\n",
       "  (10, 10, -1, ' 2006', -1),\n",
       "  (11, 11, -1, 'Feb, 29 2008', -1),\n",
       "  (12, 12, -1, 'Theory of Information', -1),\n",
       "  (13, 13, -1, ' ', -1),\n",
       "  (14, 14, -1, ' 1992', -1),\n",
       "  (15, 15, -1, '2010-31-01', -1),\n",
       "  (16, 16, 4, '1996', -1),\n",
       "  (17, 17, 4, '2003', -1),\n",
       "  (18, 18, 4, 'Feb, 29 2008', -1),\n",
       "  (19, 19, 4, '2010', -1),\n",
       "  (20, 20, 4, '2', -1),\n",
       "  (21, 21, 4, '12', -1),\n",
       "  (22, 22, 4, '', -1),\n",
       "  (23, 23, 4, '31', -1),\n",
       "  (24, 24, 4, '1', -1),\n",
       "  (25, 25, 4, '31', -1),\n",
       "  (26, 26, 4, '', -1),\n",
       "  (27, 27, 4, '1', -1),\n",
       "  (28, 2, 10, '1975', 2),\n",
       "  (29, 6, 10, '1985', 6),\n",
       "  (30, 10, 10, '2006', 10),\n",
       "  (31, 14, 10, '1992', 14),\n",
       "  (32, 26, 11, '29', 26),\n",
       "  (33, 22, 12, '2', 22),\n",
       "  (34, 18, 13, '2008', 18),\n",
       "  (35, 27, 14, '31', 27),\n",
       "  (36, 23, 15, '1', 23),\n",
       "  (37, 28, 17, '21', -1),\n",
       "  (38, 29, 17, '18', -1),\n",
       "  (39, 30, 17, '2', -1),\n",
       "  (40, 31, 17, '18', -1)],\n",
       " [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0)])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# align values\n",
    "dcm1.cell_values,dcm2.cell_values,dcm2.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_union_pd = dcm1_val_pd[dcm1_val_pd[4]==-1].merge(dcm2_val_pd[dcm2_val_pd[4]==-1],left_on=1,right_on=1,how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_union_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77120/1549340077.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcol_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrow_id\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcell_union_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_union_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcell_union_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#cell_values.append((x[\"0_x\"],x[\"1\"],x[\"2_x\"],x[\"3_x\"],x[\"4_x\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#cell_values_map[\"a-{}\".format(int(x[\"0_x\"]))] = x[\"0_x\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_union_pd' is not defined"
     ]
    }
   ],
   "source": [
    "# similar\n",
    "cell_values = []\n",
    "cell_values_map = {}\n",
    "cell = []\n",
    "cell_map = {}\n",
    "col = []\n",
    "col_map = {}\n",
    "row = []\n",
    "row_map = {}\n",
    "cell_values_id = 0\n",
    "cell_id = 0\n",
    "col_id = 0\n",
    "row_id =0\n",
    "for x in cell_union_pd[cell_union_pd[\"3_x\"]==cell_union_pd[\"3_y\"]].to_records():\n",
    "    #cell_values.append((x[\"0_x\"],x[\"1\"],x[\"2_x\"],x[\"3_x\"],x[\"4_x\"]))\n",
    "    #cell_values_map[\"a-{}\".format(int(x[\"0_x\"]))] = x[\"0_x\"]\n",
    "    #cell_values_map[\"b-{}\".format(int(x[\"0_y\"]))] = x[\"0_x\"]\n",
    "\n",
    "    cell_idt = dcm1_cell_pd[dcm1_cell_pd[0]==x[\"1\"]].values[0]\n",
    "\n",
    "    try:\n",
    "        col_map[\"a-{}\".format(cell_idt[1])] \n",
    "    except:\n",
    "        #col_map[\"a-{}\".format(cell_id[2])] = cell_id[2]\n",
    "        #col_map[\"b-{}\".format(cell_id[2])] = cell_id[2]\n",
    "        col_map[\"a-{}\".format(cell_idt[1])] = col_id\n",
    "        col_map[\"b-{}\".format(cell_idt[1])] = col_id\n",
    "        col_idt = dcm1_col_pd[dcm1_col_pd[0]==cell_idt[1]].values[0]\n",
    "        col.append((col_id,col_idt[1]))\n",
    "        col_id+=1\n",
    "        \n",
    "    try:\n",
    "        row_map[\"a-{}\".format(cell_idt[2])]\n",
    "    except:\n",
    "        #row_map[\"a-{}\".format(cell_id[1])] = cell_id[1]\n",
    "        #row_map[\"b-{}\".format(cell_id[1])] = cell_id[1]\n",
    "        row_map[\"a-{}\".format(cell_idt[2])] = row_id\n",
    "        row_map[\"b-{}\".format(cell_idt[2])] = row_id\n",
    "        row_idt = dcm1_row_pd[dcm1_row_pd[0]==cell_idt[2]].values[0]\n",
    "        row.append((row_id,row_idt[1]))\n",
    "        row_id+=1\n",
    "\n",
    "    try:\n",
    "        cell_map[\"a-{}\".format(int(x[\"1\"]))] \n",
    "    except:\n",
    "        #cell_map[\"a-{}\".format(int(x[\"1\"]))] = x[\"1\"]\n",
    "        #cell_map[\"b-{}\".format(int(x[\"1\"]))] = x[\"1\"]\n",
    "        cell_map[\"a-{}\".format(int(x[\"1\"]))] = cell_id\n",
    "        cell_map[\"b-{}\".format(int(x[\"1\"]))] = cell_id\n",
    "        #cell.append((cell_id,row_id,col_id))\n",
    "        cell.append((cell_id,col_map[\"a-{}\".format(cell_idt[1])],row_map[\"a-{}\".format(cell_idt[2])]))\n",
    "        cell_id+=1\n",
    "        \n",
    "    cell_values.append((cell_values_id,cell_map[\"a-{}\".format(int(x[\"1\"]))] ,x[\"2_x\"],x[\"3_x\"],x[\"4_x\"]))\n",
    "    cell_values_map[\"a-{}\".format(int(x[\"0_x\"]))] = cell_values_id\n",
    "    cell_values_map[\"b-{}\".format(int(x[\"0_y\"]))] = cell_values_id\n",
    "    cell_values_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in cell_union_pd[cell_union_pd[\"3_x\"]!=cell_union_pd[\"3_y\"]].to_records():\n",
    "    #cell_values.append((x[\"0_x\"],x[\"1\"],x[\"2_x\"],x[\"3_x\"],x[\"4_x\"]))\n",
    "    #cell_values_map[\"a-{}\".format(int(x[\"0_x\"]))] = x[\"0_x\"]\n",
    "    #cell_values_map[\"b-{}\".format(int(x[\"0_y\"]))] = x[\"0_x\"]\n",
    "\n",
    "    if not np.isnan(x[\"0_x\"]):\n",
    "        cell_idt = dcm1_cell_pd[dcm1_cell_pd[0]==x[\"1\"]].values[0]\n",
    "        try:\n",
    "            col_map[\"a-{}\".format(cell_idt[1])] \n",
    "        except:\n",
    "            #col_map[\"a-{}\".format(cell_id[2])] = cell_id[2]\n",
    "            #col_map[\"b-{}\".format(cell_id[2])] = cell_id[2]\n",
    "            col_map[\"a-{}\".format(cell_idt[1])] = col_id\n",
    "            col_idt = dcm1_col_pd[dcm1_col_pd[0]==cell_idt[1]].values[0]\n",
    "            col.append((col_id,col_idt[1]))\n",
    "            col_id+=1\n",
    "\n",
    "        try:\n",
    "            row_map[\"a-{}\".format(cell_idt[2])]\n",
    "        except:\n",
    "            row_map[\"a-{}\".format(cell_idt[2])] = row_id\n",
    "            row_idt = dcm1_row_pd[dcm1_row_pd[0]==cell_idt[2]].values[0]\n",
    "            row.append((row_id,row_idt[2]))\n",
    "            row_id+=1\n",
    "\n",
    "        try:\n",
    "            cell_map[\"a-{}\".format(int(x[\"1\"]))] \n",
    "        except:\n",
    "            cell_map[\"a-{}\".format(int(x[\"1\"]))] = cell_id\n",
    "            cell.append((cell_id,col_map[\"a-{}\".format(cell_idt[1])],row_map[\"a-{}\".format(cell_idt[2])]))\n",
    "            cell_id+=1\n",
    "\n",
    "        cell_values.append((cell_values_id,cell_map[\"a-{}\".format(int(x[\"1\"]))] ,x[\"2_x\"],x[\"3_x\"],x[\"4_x\"]))\n",
    "        cell_values_map[\"a-{}\".format(int(x[\"0_x\"]))] = cell_values_id\n",
    "        cell_values_id+=1\n",
    "        \n",
    "    if not np.isnan(x[\"0_y\"]):\n",
    "        cell_idt = dcm2_cell_pd[dcm2_cell_pd[0]==x[\"1\"]].values[0]\n",
    "        try:\n",
    "            col_map[\"b-{}\".format(cell_idt[1])] \n",
    "        except:\n",
    "            col_map[\"b-{}\".format(cell_idt[1])] = col_id\n",
    "            col_idt = dcm2_col_pd[dcm2_col_pd[0]==cell_idt[1]].values[0]\n",
    "            col.append((col_id,col_idt[1]))\n",
    "            col_id+=1\n",
    "\n",
    "        try:\n",
    "            row_map[\"b-{}\".format(cell_idt[2])]\n",
    "        except:\n",
    "            row_map[\"b-{}\".format(cell_idt[2])] = row_id\n",
    "            row_idt = dcm2_row_pd[dcm2_row_pd[0]==cell_idt[2]].values[0]\n",
    "            row.append((row_id,row_idt[1]))\n",
    "\n",
    "        try:\n",
    "            cell_map[\"b-{}\".format(int(x[\"1\"]))] \n",
    "        except:\n",
    "            cell_map[\"b-{}\".format(int(x[\"1\"]))] = cell_id\n",
    "            cell.append((cell_id,col_map[\"b-{}\".format(cell_idt[1])],row_map[\"b-{}\".format(cell_idt[2])]))\n",
    "            cell_id+=1\n",
    "\n",
    "        cell_values.append((cell_values_id,cell_map[\"b-{}\".format(int(x[\"1\"]))] ,x[\"2_y\"],x[\"3_y\"],x[\"4_y\"]))\n",
    "        cell_values_map[\"b-{}\".format(int(x[\"0_y\"]))] = cell_values_id\n",
    "        cell_values_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Author 1', 1, -1),\n",
       "  (5, 5, 4, 'Author 2', 4, -1),\n",
       "  (6, 1, 5, 'Author', 0, 1),\n",
       "  (7, 4, 5, 'Last Name', 1, 4),\n",
       "  (8, 5, 5, 'Author 2', 4, 5),\n",
       "  (9, 2, 5, 'Date', 5, 2),\n",
       "  (10, 3, 5, 'Entrance Date', 2, 3),\n",
       "  (11, 1, 6, 'Author', 0, 1),\n",
       "  (12, 4, 6, 'Last Name', 1, 4),\n",
       "  (13, 5, 6, 'First Name', 2, 5),\n",
       "  (14, 2, 6, 'Date', 5, 2),\n",
       "  (15, 3, 6, 'Entrance Date', 2, 3)],\n",
       " [(0, 0, -1, 'Book Title', -1, -1),\n",
       "  (1, 1, -1, 'Author', 0, -1),\n",
       "  (2, 2, -1, 'Date', 1, -1),\n",
       "  (3, 3, -1, 'Entrance Date', 2, -1),\n",
       "  (4, 4, 4, 'Entrance Date 1', 3, -1),\n",
       "  (5, 5, 4, 'Entrance Date 2', 4, -1),\n",
       "  (6, 6, 4, 'Entrance Date 3', 5, -1),\n",
       "  (7, 1, 5, 'Author', 0, 1),\n",
       "  (8, 2, 5, 'Date', 1, 2),\n",
       "  (9, 3, 5, 'Entrance Date', 2, 3),\n",
       "  (10, 4, 5, 'Year', 3, 4),\n",
       "  (11, 5, 5, 'Entrance Date 2', 4, 5),\n",
       "  (12, 6, 5, 'Entrance Date 3', 5, 6),\n",
       "  (13, 1, 6, 'Author', 0, 1),\n",
       "  (14, 2, 6, 'Date', 1, 2),\n",
       "  (15, 3, 6, 'Entrance Date', 2, 3),\n",
       "  (16, 4, 6, 'Year', 3, 4),\n",
       "  (17, 5, 6, 'Month', 4, 5),\n",
       "  (18, 6, 6, 'Entrance Date 3', 5, 6),\n",
       "  (19, 1, 7, 'Author', 0, 1),\n",
       "  (20, 2, 7, 'Date', 1, 2),\n",
       "  (21, 3, 7, 'Entrance Date', 2, 3),\n",
       "  (22, 4, 7, 'Entry Year', 3, 4),\n",
       "  (23, 5, 7, 'Month', 4, 5),\n",
       "  (24, 6, 7, 'Entrance Date 3', 5, 6),\n",
       "  (25, 1, 8, 'Author', 0, 1),\n",
       "  (26, 2, 8, 'Date', 1, 2),\n",
       "  (27, 3, 8, 'Entrance Date', 2, 3),\n",
       "  (28, 4, 8, 'Entry Year', 3, 4),\n",
       "  (29, 5, 8, 'Entry Month', 4, 5),\n",
       "  (30, 6, 8, 'Entrance Date 3', 5, 6),\n",
       "  (31, 1, 9, 'Author', 0, 1),\n",
       "  (32, 2, 9, 'Date', 1, 2),\n",
       "  (33, 3, 9, 'Entrance Date', 2, 3),\n",
       "  (34, 4, 9, 'Entry Year', 3, 4),\n",
       "  (35, 5, 9, 'Entry Month', 4, 5),\n",
       "  (36, 6, 9, 'Entry Date', 5, 6),\n",
       "  (37, 7, 17, 'Archived Delay', 36, -1)])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.column_position,dcm2.column_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0),\n",
       "  (1, 0),\n",
       "  (2, 0),\n",
       "  (3, 0),\n",
       "  (4, 0),\n",
       "  (5, 0),\n",
       "  (6, 0),\n",
       "  (7, 0),\n",
       "  (8, 0),\n",
       "  (9, 0)],\n",
       " [(0, 0), (1, 0), (2, 0), (3, 0)],\n",
       " [(0, 0, 0),\n",
       "  (1, 1, 0),\n",
       "  (2, 2, 0),\n",
       "  (3, 3, 0),\n",
       "  (4, 0, 1),\n",
       "  (5, 1, 1),\n",
       "  (6, 2, 1),\n",
       "  (7, 3, 1),\n",
       "  (8, 0, 2),\n",
       "  (9, 1, 2),\n",
       "  (10, 2, 2),\n",
       "  (11, 3, 2),\n",
       "  (12, 0, 3),\n",
       "  (13, 1, 3),\n",
       "  (14, 2, 3),\n",
       "  (15, 3, 3),\n",
       "  (16, 4, 0),\n",
       "  (17, 5, 0),\n",
       "  (18, 4, 1),\n",
       "  (19, 5, 1),\n",
       "  (20, 4, 2),\n",
       "  (21, 5, 2),\n",
       "  (22, 4, 3),\n",
       "  (23, 5, 3),\n",
       "  (24, 6, 0),\n",
       "  (25, 7, 0),\n",
       "  (26, 6, 1),\n",
       "  (27, 7, 1),\n",
       "  (28, 6, 2),\n",
       "  (29, 7, 2),\n",
       "  (30, 6, 3),\n",
       "  (31, 7, 3),\n",
       "  (32, 8, 0),\n",
       "  (33, 8, 1),\n",
       "  (34, 8, 2),\n",
       "  (35, 8, 3),\n",
       "  (36, 9, 0),\n",
       "  (37, 9, 1),\n",
       "  (38, 9, 2),\n",
       "  (39, 9, 3)],\n",
       " [(0, 0, -1.0, 'Against Method', -1.0),\n",
       "  (1, 1, -1.0, 'Feyerabend, P.', -1.0),\n",
       "  (2, 2, -1.0, ' 1975', -1.0),\n",
       "  (3, 3, -1.0, '1996-02-01', -1.0),\n",
       "  (4, 4, -1.0, 'Changing Order', -1.0),\n",
       "  (5, 5, -1.0, 'Collins, H.M.', -1.0),\n",
       "  (6, 6, -1.0, ' 1985', -1.0),\n",
       "  (7, 7, -1.0, '2003-12-31', -1.0),\n",
       "  (8, 8, -1.0, 'Exceeding Our Grasp', -1.0),\n",
       "  (9, 9, -1.0, ' P. Kyle Stanford', -1.0),\n",
       "  (10, 10, -1.0, ' 2006', -1.0),\n",
       "  (11, 11, -1.0, 'Feb, 29 2008', -1.0),\n",
       "  (12, 12, -1.0, 'Theory of Information', -1.0),\n",
       "  (13, 13, -1.0, ' ', -1.0),\n",
       "  (14, 14, -1.0, ' 1992', -1.0),\n",
       "  (15, 15, -1.0, '2010-31-01', -1.0),\n",
       "  (16, 16, 4.0, 'Feyerabend', -1.0),\n",
       "  (17, 17, 4, '1996', -1),\n",
       "  (18, 18, 4.0, 'Collins', -1.0),\n",
       "  (19, 19, 4, '2003', -1),\n",
       "  (20, 20, 4.0, 'Stanford', -1.0),\n",
       "  (21, 21, 4, 'Feb, 29 2008', -1),\n",
       "  (22, 22, 4.0, ' ', -1.0),\n",
       "  (23, 23, 4, '2010', -1),\n",
       "  (24, 24, 4.0, ' P.', -1.0),\n",
       "  (25, 25, 4, '2', -1),\n",
       "  (26, 26, 4.0, ' H.M.', -1.0),\n",
       "  (27, 27, 4, '12', -1),\n",
       "  (28, 28, 4.0, ' P. Kyle', -1.0),\n",
       "  (29, 29, 4, '', -1),\n",
       "  (30, 30, 4.0, None, -1.0),\n",
       "  (31, 31, 4, '31', -1),\n",
       "  (32, 32, 4, '1', -1),\n",
       "  (33, 33, 4, '31', -1),\n",
       "  (34, 34, 4, '', -1),\n",
       "  (35, 35, 4, '1', -1),\n",
       "  (36, 36, 17, '21', -1),\n",
       "  (37, 37, 17, '18', -1),\n",
       "  (38, 38, 17, '2', -1),\n",
       "  (39, 39, 17, '18', -1)])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col,row,cell,cell_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77120/140708428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcol_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col_map' is not defined"
     ]
    }
   ],
   "source": [
    "col_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a-0': 0,\n",
       "  'b-0': 0,\n",
       "  'a-1': 1,\n",
       "  'b-1': 1,\n",
       "  'a-2': 2,\n",
       "  'b-2': 2,\n",
       "  'a-3': 3,\n",
       "  'b-3': 3},\n",
       " {'a-0': 0,\n",
       "  'b-0': 0,\n",
       "  'a-1': 1,\n",
       "  'b-1': 1,\n",
       "  'a-2': 2,\n",
       "  'b-2': 2,\n",
       "  'a-3': 3,\n",
       "  'b-3': 3,\n",
       "  'a-4': 4,\n",
       "  'b-4': 4,\n",
       "  'a-5': 5,\n",
       "  'b-5': 5,\n",
       "  'a-6': 6,\n",
       "  'b-6': 6,\n",
       "  'a-7': 7,\n",
       "  'b-7': 7,\n",
       "  'a-8': 8,\n",
       "  'b-8': 8,\n",
       "  'a-9': 9,\n",
       "  'b-9': 9,\n",
       "  'a-10': 10,\n",
       "  'b-10': 10,\n",
       "  'a-11': 11,\n",
       "  'b-11': 11,\n",
       "  'a-12': 12,\n",
       "  'b-12': 12,\n",
       "  'a-13': 13,\n",
       "  'b-13': 13,\n",
       "  'a-14': 14,\n",
       "  'b-14': 14,\n",
       "  'a-15': 15,\n",
       "  'b-15': 15,\n",
       "  'a-16': 16,\n",
       "  'b-16': 17,\n",
       "  'a-17': 18,\n",
       "  'b-17': 19,\n",
       "  'a-18': 20,\n",
       "  'b-18': 21,\n",
       "  'a-19': 22,\n",
       "  'b-19': 23,\n",
       "  'a-20': 24,\n",
       "  'b-20': 25,\n",
       "  'a-21': 26,\n",
       "  'b-21': 27,\n",
       "  'a-22': 28,\n",
       "  'b-22': 29,\n",
       "  'a-23': 30,\n",
       "  'b-23': 31,\n",
       "  'b-24': 32,\n",
       "  'b-25': 33,\n",
       "  'b-26': 34,\n",
       "  'b-27': 35,\n",
       "  'b-28': 36,\n",
       "  'b-29': 37,\n",
       "  'b-30': 38,\n",
       "  'b-31': 39})"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_map,cell_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Feyerabend</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1996</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Collins</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2003</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Feb, 29 2008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>P.</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>H.M.</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>P. Kyle</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0_x   1  2_x         3_x  4_x  0_y  2_y           3_y  4_y\n",
       "16  17.0  16  4.0  Feyerabend -1.0   16    4          1996   -1\n",
       "17  18.0  17  4.0     Collins -1.0   17    4          2003   -1\n",
       "18  19.0  18  4.0    Stanford -1.0   18    4  Feb, 29 2008   -1\n",
       "19  20.0  19  4.0             -1.0   19    4          2010   -1\n",
       "20  21.0  20  4.0          P. -1.0   20    4             2   -1\n",
       "21  22.0  21  4.0        H.M. -1.0   21    4            12   -1\n",
       "22  23.0  22  4.0     P. Kyle -1.0   22    4                 -1\n",
       "23  24.0  23  4.0        None -1.0   23    4            31   -1\n",
       "24   NaN  24  NaN         NaN  NaN   24    4             1   -1\n",
       "25   NaN  25  NaN         NaN  NaN   25    4            31   -1\n",
       "26   NaN  26  NaN         NaN  NaN   26    4                 -1\n",
       "27   NaN  27  NaN         NaN  NaN   27    4             1   -1\n",
       "28   NaN  28  NaN         NaN  NaN   37   17            21   -1\n",
       "29   NaN  29  NaN         NaN  NaN   38   17            18   -1\n",
       "30   NaN  30  NaN         NaN  NaN   39   17             2   -1\n",
       "31   NaN  31  NaN         NaN  NaN   40   17            18   -1"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new/different cell\n",
    "cell_union_pd[cell_union_pd[\"3_x\"]!=cell_union_pd[\"3_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "?dcm1_val_pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'op': 'core/row-removal',\n",
       " 'engineConfig': {'facets': [{'type': 'list',\n",
       "    'name': 'Flagged Rows',\n",
       "    'expression': 'row.flagged',\n",
       "    'columnName': '',\n",
       "    'invert': False,\n",
       "    'omitBlank': False,\n",
       "    'omitError': False,\n",
       "    'selection': [{'v': {'v': True, 'l': 'true'}}],\n",
       "    'selectBlank': False,\n",
       "    'selectError': False}],\n",
       "  'mode': 'row-based'},\n",
       " 'description': 'Remove rows'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(x[5])[\"operation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, -1, ('Against Method', 0, 0), -1),\n",
       " (1, 1, -1, ('Feyerabend, P.', 0, 1), -1),\n",
       " (2, 2, -1, (' 1975', 0, 2), -1),\n",
       " (3, 3, -1, ('1996-02-01', 0, 3), -1),\n",
       " (4, 4, -1, ('Changing Order', 1, 0), -1),\n",
       " (5, 5, -1, ('Collins, H.M.', 1, 1), -1),\n",
       " (6, 6, -1, (' 1985', 1, 2), -1),\n",
       " (7, 7, -1, ('2003-12-31', 1, 3), -1),\n",
       " (8, 8, -1, ('Exceeding Our Grasp', 2, 0), -1),\n",
       " (9, 9, -1, (' P. Kyle Stanford', 2, 1), -1),\n",
       " (10, 10, -1, (' 2006', 2, 2), -1),\n",
       " (11, 11, -1, ('Feb, 29 2008', 2, 3), -1),\n",
       " (12, 12, -1, ('Theory of Information', 3, 0), -1),\n",
       " (13, 13, -1, (' ', 3, 1), -1),\n",
       " (14, 14, -1, (' 1992', 3, 2), -1),\n",
       " (15, 15, -1, ('2010-31-01', 3, 3), -1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm1.cell_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw:\n",
      "get_values_state 17\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{\"id\": 1629921348453, \"description\": \"Text transform on 0 cells in column Book Title: value.replace(/\\\\s+/,' ')\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Book Title\", \"expression\": \"value.replace(/\\\\s+/,' ')\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Book Title using expression value.replace(/\\\\s+/,' ')\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 16\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{\"id\": 1629921434653, \"description\": \"Text transform on 0 cells in column Author: value.replace(/\\\\s+/,' ')\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Author\", \"expression\": \"value.replace(/\\\\s+/,' ')\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Author using expression value.replace(/\\\\s+/,' ')\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 15\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{\"id\": 1629922031446, \"description\": \"Text transform on 0 cells in column Date: value.replace(/\\\\s+/,' ')\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Date\", \"expression\": \"value.replace(/\\\\s+/,' ')\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Date using expression value.replace(/\\\\s+/,' ')\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 14\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{\"id\": 1629921667846, \"description\": \"Text transform on 0 cells in column Entrance Date: value.replace(/\\\\s+/,' ')\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Entrance Date\", \"expression\": \"value.replace(/\\\\s+/,' ')\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Entrance Date using expression value.replace(/\\\\s+/,' ')\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 13\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date  \n",
      "0    (1996-02-01, 0, 3)  \n",
      "1    (2003-12-31, 1, 3)  \n",
      "2  (Feb, 29 2008, 2, 3)  \n",
      "3    (2010-31-01, 3, 3)  \n",
      "{\"id\": 1629921639511, \"description\": \"Split 4 cell(s) in column Entrance Date into several columns by separator\", \"operation\": {\"op\": \"core/column-split\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Entrance Date\", \"guessCellType\": true, \"removeOriginalColumn\": false, \"mode\": \"separator\", \"separator\": \"-\", \"regex\": false, \"maxColumns\": 0, \"description\": \"Split column Entrance Date by separator\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 12\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date       Entrance Date 1 Entrance Date 2 Entrance Date 3  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921966580, \"description\": \"Rename column Entrance Date 1 to Year\", \"operation\": {\"op\": \"core/column-rename\", \"oldColumnName\": \"Entrance Date 1\", \"newColumnName\": \"Year\", \"description\": \"Rename column Entrance Date 1 to Year\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 11\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year Entrance Date 2 Entrance Date 3  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)       (2, 0, 5)       (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)      (12, 1, 5)      (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)        (, 2, 5)        (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)      (31, 3, 5)       (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921643378, \"description\": \"Rename column Entrance Date 2 to Month\", \"operation\": {\"op\": \"core/column-rename\", \"oldColumnName\": \"Entrance Date 2\", \"newColumnName\": \"Month\", \"description\": \"Rename column Entrance Date 2 to Month\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 10\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date                  Year       Month Entrance Date 3  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921237421, \"description\": \"Rename column Year to Entry Year\", \"operation\": {\"op\": \"core/column-rename\", \"oldColumnName\": \"Year\", \"newColumnName\": \"Entry Year\", \"description\": \"Rename column Year to Entry Year\"}, \"time\": \"2021-08-25T19:53:35Z\"}\n",
      "get_values_state 9\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year       Month Entrance Date 3  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921956381, \"description\": \"Rename column Month to Entry Month\", \"operation\": {\"op\": \"core/column-rename\", \"oldColumnName\": \"Month\", \"newColumnName\": \"Entry Month\", \"description\": \"Rename column Month to Entry Month\"}, \"time\": \"2021-08-25T19:53:36Z\"}\n",
      "get_values_state 8\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month Entrance Date 3  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)       (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)      (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)        (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)       (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921803356, \"description\": \"Rename column Entrance Date 3 to Entry Date\", \"operation\": {\"op\": \"core/column-rename\", \"oldColumnName\": \"Entrance Date 3\", \"newColumnName\": \"Entry Date\", \"description\": \"Rename column Entrance Date 3 to Entry Date\"}, \"time\": \"2021-08-25T19:53:36Z\"}\n",
      "get_values_state 7\n",
      "                      Book Title                     Author           Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  ( 1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  ( 1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  ( 2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  ( 1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)    (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921239394, \"description\": \"Text transform on 4 cells in column Date: value.toNumber()\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Date\", \"expression\": \"value.toNumber()\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Date using expression value.toNumber()\"}, \"time\": \"2021-08-25T19:53:47Z\"}\n",
      "get_values_state 6\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)    (, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921919709, \"description\": \"Edit single cell on row 3, column Entry Date\", \"operation\": null, \"time\": \"2021-08-25T19:55:13Z\"}\n",
      "get_values_state 5\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)    (, 2, 5)  (29, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629921743490, \"description\": \"Edit single cell on row 3, column Entry Month\", \"operation\": null, \"time\": \"2021-08-25T19:55:21Z\"}\n",
      "get_values_state 4\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date            Entry Year Entry Month  Entry Date  \\\n",
      "0    (1996-02-01, 0, 3)          (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)   \n",
      "1    (2003-12-31, 1, 3)          (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)   \n",
      "2  (Feb, 29 2008, 2, 3)  (Feb, 29 2008, 2, 4)   (2, 2, 5)  (29, 2, 6)   \n",
      "3    (2010-31-01, 3, 3)          (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)   \n",
      "\n",
      "  Archived Delay  \n",
      "0     (21, 0, 7)  \n",
      "1     (18, 1, 7)  \n",
      "2      (2, 2, 7)  \n",
      "3     (18, 3, 7)  \n",
      "{\"id\": 1629922217234, \"description\": \"Edit single cell on row 3, column Entry Year\", \"operation\": null, \"time\": \"2021-08-25T19:55:27Z\"}\n",
      "get_values_state 3\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)  (31, 3, 5)   (1, 3, 6)     (18, 3, 7)  \n",
      "{\"id\": 1629921919624, \"description\": \"Edit single cell on row 4, column Entry Date\", \"operation\": null, \"time\": \"2021-08-25T19:55:34Z\"}\n",
      "get_values_state 2\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)  (31, 3, 5)  (31, 3, 6)     (18, 3, 7)  \n",
      "{\"id\": 1629922206801, \"description\": \"Edit single cell on row 4, column Entry Month\", \"operation\": null, \"time\": \"2021-08-25T19:55:51Z\"}\n",
      "get_values_state 1\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)     (18, 3, 7)  \n",
      "{\"id\": 1629921632247, \"description\": \"Text transform on 0 cells in column Entry Year: value.toNumber()\", \"operation\": {\"op\": \"core/text-transform\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"columnName\": \"Entry Year\", \"expression\": \"value.toNumber()\", \"onError\": \"keep-original\", \"repeat\": false, \"repeatCount\": 10, \"description\": \"Text transform on cells in column Entry Year using expression value.toNumber()\"}, \"time\": \"2021-08-25T19:57:41Z\"}\n",
      "get_values_state 0\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)     (18, 3, 7)  \n",
      "{\"id\": 1629922420062, \"description\": \"Create new column Archived Delay based on column Entry Year by filling 4 rows with grel:value - cells[\\\"Date\\\"].value\", \"operation\": {\"op\": \"core/column-addition\", \"engineConfig\": {\"facets\": [], \"mode\": \"row-based\"}, \"baseColumnName\": \"Entry Year\", \"expression\": \"grel:value - cells[\\\"Date\\\"].value\", \"onError\": \"set-to-blank\", \"newColumnName\": \"Archived Delay\", \"columnInsertIndex\": 7, \"description\": \"Create column Archived Delay at index 7 based on column Entry Year using expression grel:value - cells[\\\"Date\\\"].value\"}, \"time\": \"2021-08-25T19:57:41Z\"}\n",
      "get_values_state -1\n",
      "                      Book Title                     Author          Date  \\\n",
      "0         (Against Method, 0, 0)     (Feyerabend, P., 0, 1)  (1975, 0, 2)   \n",
      "1         (Changing Order, 1, 0)      (Collins, H.M., 1, 1)  (1985, 1, 2)   \n",
      "2    (Exceeding Our Grasp, 2, 0)  ( P. Kyle Stanford, 2, 1)  (2006, 2, 2)   \n",
      "3  (Theory of Information, 3, 0)                  ( , 3, 1)  (1992, 3, 2)   \n",
      "\n",
      "          Entrance Date    Entry Year Entry Month  Entry Date Archived Delay  \n",
      "0    (1996-02-01, 0, 3)  (1996, 0, 4)   (2, 0, 5)   (1, 0, 6)     (21, 0, 7)  \n",
      "1    (2003-12-31, 1, 3)  (2003, 1, 4)  (12, 1, 5)  (31, 1, 6)     (18, 1, 7)  \n",
      "2  (Feb, 29 2008, 2, 3)  (2008, 2, 4)   (2, 2, 5)  (29, 2, 6)      (2, 2, 7)  \n",
      "3    (2010-31-01, 3, 3)  (2010, 3, 4)   (1, 3, 5)  (31, 3, 6)     (18, 3, 7)  \n"
     ]
    }
   ],
   "source": [
    "print(\"raw:\")\n",
    "print(op2.get_snapshot_at_state(int(op2.get_state_to_step(len(op2.get_all_state_command())))+1))\n",
    "for x in op2.get_all_state_command().sort_values(\"state_id\",ascending=False).to_records():\n",
    "    print(x[5])\n",
    "    print(op2.get_snapshot_at_state(int(op2.get_state_to_step(x.state_id)+1)))\n",
    "    #op2.get_snapshot_at_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1.get_all_state_command().sort_values(\"state_id\",ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_gv.dot\",\"w\") as file:\n",
    "    file.write(gv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = nx.nx_pydot.read_dot(\"test_gv.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test_gv.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1.get_col_at_state_order(state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2.get_col_at_state_order(state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "db_files = []\n",
    "for x in os.listdir():\n",
    "    if x.endswith(\".db\"):\n",
    "        db_files.append(x)\n",
    "\n",
    "global orpe,num_state\n",
    "\n",
    "@interact\n",
    "def interactive_form(file=db_files):\n",
    "    global orpe,num_state\n",
    "    #orpe = ProvenanceExplorer(file)\n",
    "    #orpe = ProvenanceExplorer(\"workflow-demo-3.openrefine.db\")\n",
    "    orpe = ProvenanceExplorer(\"airbnb_demo.db\")\n",
    "    num_state = orpe.get_number_of_state().num_state.values[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_parallel = orpe.gv_template(orpe.parallel_workflow())\n",
    "collapsed,freq_pattern = orpe.collapsed_iterative(orpe.parallel_workflow(),temp_parallel[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.gv_template(freq_pattern,orpe.parallel_workflow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_column_at_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_linear_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_all_state_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "linear_recipe = orpe.get_linear_recipe()\n",
    "\n",
    "params = set()\n",
    "process = {}\n",
    "\n",
    "max_state = orpe.get_number_of_state()\n",
    "\n",
    "for x in linear_recipe.to_records():\n",
    "    xx = json.loads(x.detail)\n",
    "\n",
    "    real_state = max_state.values[0][0]-x.state_id    \n",
    "    prev_state = max_state.values[0][0]-x.prev_state_id\n",
    "\n",
    "    if real_state == 0:\n",
    "        input_name = \"tableoriginal\"\n",
    "    else:\n",
    "        input_name = \"table{}\".format(real_state) \n",
    "\n",
    "    process[\"state{}\".format(prev_state)] = {}\n",
    "    process[\"state{}\".format(prev_state)][\"input\"] = input_name\n",
    "    process[\"state{}\".format(prev_state)][\"output\"] = \"table{}\".format(prev_state)\n",
    "    process[\"state{}\".format(prev_state)][\"desc\"] = xx[\"description\"]\n",
    "    try:\n",
    "        process[\"state{}\".format(prev_state)][\"op\"] = xx[\"operation\"][\"op\"]\n",
    "        process[\"state{}\".format(prev_state)][\"operation\"] = xx[\"operation\"]\n",
    "    except:\n",
    "        pass\n",
    "    #print(xx)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_def = \"\"\"\n",
    "digraph \"[stackcollapse]\" {\n",
    "node [style=filled fillcolor=\"#f8f8f8\"]\n",
    "\"\"\"\n",
    "\n",
    "edge_def = \"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "process_nodes = []\n",
    "data_nodes_in = set()\n",
    "data_nodes_out = set()\n",
    "\n",
    "for key,val in process.items():\n",
    "    temp_name = \"{state}\\\\n\".format(state=key)\n",
    "    temp_desc = \"\"\n",
    "    try:\n",
    "        temp_desc += val[\"op\"] +\"\\\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    temp_desc += val[\"desc\"]\n",
    "    nodes_def+=\"\"\"\n",
    "        {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=box tooltip=\"{tt}\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "    \"\"\".format(x=key,label=temp_name+temp_desc.replace('\"',\"'\"),id=key,tt=\"\")\n",
    "    \n",
    "    temp_process_yw = \"\"\"\n",
    "    #@begin {key} #@desc {desc} \n",
    "    \"\"\".format(key=key,desc=temp_desc.replace('\"',\"'\"))\n",
    "    \n",
    "    if val[\"input\"] not in isinput:\n",
    "        nodes_def+=\"\"\"\n",
    "            {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "        \"\"\".format(x=val[\"input\"],label=val[\"input\"].replace('\"',\"'\"),id=key,tt=\"\")\n",
    "        isinput.add(val[\"input\"])\n",
    "        \n",
    "\n",
    "    if val[\"output\"] not in isinput:\n",
    "        nodes_def+=\"\"\"\n",
    "            {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "        \"\"\".format(x=val[\"output\"],label=val[\"output\"].replace('\"',\"'\"),id=key,tt=\"\")\n",
    "        isinput.add(val[\"output\"])\n",
    "        \n",
    "        \n",
    "    edge_def+=\"\"\"\n",
    "        {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "    \"\"\".format(input=val[\"input\"],output=key,data=\"\")\n",
    "    \n",
    "    data_nodes_in.add(\"{key}\".format(key=val[\"input\"]).replace(\" \",\"_\"))\n",
    "    temp_process_yw += \"\"\"\n",
    "    #@in \"\"\"+ \"\"\"{key}\n",
    "        \"\"\".format(key=val[\"input\"]).replace(\" \",\"_\")   \n",
    "    \n",
    "    \n",
    "    edge_def+=\"\"\"\n",
    "        {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "    \"\"\".format(input=key,output=val[\"output\"],data=\"\")\n",
    "    \n",
    "    data_nodes_out.add(\"{key}\".format(key=val[\"output\"]).replace(\" \",\"_\"))\n",
    "    temp_process_yw += \"\"\"\n",
    "    #@out \"\"\"+\"\"\"{key}\n",
    "    \"\"\".format(key=val[\"output\"]).replace(\" \",\"_\")            \n",
    "    \n",
    "    temp_process_yw += \"\"\"\n",
    "    #@end {key}     \n",
    "    \"\"\".format(key=key)\n",
    "    process_nodes.append(temp_process_yw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_yw = \"\"\"#@begin test_or\n",
    "\"\"\"\n",
    "for x in data_nodes_in-data_nodes_out:\n",
    "    compiled_yw+=\"#@in {}\\n\".format(x)\n",
    "for x in data_nodes_out-data_nodes_in:\n",
    "    compiled_yw+=\"#@out {}\\n\".format(x)    \n",
    "for x in process_nodes:\n",
    "    compiled_yw+=x+\"\\n\"\n",
    "compiled_yw += \"\"\"#@end test_or\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compiled_yw.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_yw(compiled_yw,output=\"temporary.png\"):\n",
    "    with open(\"temporary.yw\",\"w\") as file:\n",
    "        file.write(compiled_yw)\n",
    "    !java -jar yesworkflow-0.2.2.0-SNAPSHOT-jar-with-dependencies.jar  graph temporary.yw -c extract.comment=\"#\" | dot -Tpng -o $output\n",
    "    from IPython.display import Image\n",
    "    return Image(filename=output) \n",
    "def save_pdf_yw(compiled_yw,output=\"temporary.pdf\"):\n",
    "    with open(\"temporary.yw\",\"w\") as file:\n",
    "        file.write(compiled_yw)\n",
    "    !java -jar yesworkflow-0.2.2.0-SNAPSHOT-jar-with-dependencies.jar  graph temporary.yw -c extract.comment=\"#\" | dot -Tpdf -o $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pdf_yw(compiled_yw)\n",
    "#display_yw(compiled_yw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pdf_yw(compiled_yw,\"linear_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nodes_def+edge_def+\"\\n}\")\n",
    "from graphviz import Source\n",
    "\n",
    "temp = nodes_def+edge_def+\"\\n}\"\n",
    "s = Source(temp)\n",
    "#s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dependency = orpe.get_all_column_dependency()\n",
    "state_order = orpe.get_state_order()\n",
    "state_col_dep = col_dependency.merge(state_order)\n",
    "state_col_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_linear_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_recipe = orpe.get_linear_recipe()\n",
    "\n",
    "process = {}\n",
    "col_counter = {}\n",
    "\n",
    "for x in linear_recipe.sort_values(\"state_id\",ascending=False).to_records():\n",
    "    sid = x.state_id    \n",
    "    print(sid)\n",
    "\n",
    "\n",
    "    xx = json.loads(x.detail)\n",
    "\n",
    "    real_state = max_state.values[0][0]-x.state_id    \n",
    "    prev_state = max_state.values[0][0]-x.prev_state_id\n",
    "\n",
    "    if real_state == 0:\n",
    "        input_name = \"tableoriginal\"\n",
    "    else:\n",
    "        input_name = \"table{}\".format(real_state) \n",
    "\n",
    "    process[\"state_{}\".format(prev_state)] = {}\n",
    "    try:\n",
    "        state_pd = state_col_dep.groupby(\"state_id\").get_group(sid)\n",
    "        process[\"state_{}\".format(prev_state)][\"input\"] = []\n",
    "        process[\"state_{}\".format(prev_state)][\"output\"] = []\n",
    "\n",
    "        icol = set()\n",
    "        ocol = set()\n",
    "        for y in state_pd.to_records():\n",
    "            colname = \"col{}\".format(y.input_column)\n",
    "            if colname not in icol:\n",
    "                try:\n",
    "                    col_counter[colname] #+= 1\n",
    "                except:\n",
    "                    col_counter[colname] = 0                                                \n",
    "                process[\"state_{}\".format(prev_state)][\"input\"].append(\"{colname}_{counter}\".format(colname=colname,counter=col_counter[colname]))\n",
    "                icol.add(colname)\n",
    "            \n",
    "            if y.output_column==-2:\n",
    "                colname = \"col_removed\"\n",
    "            else:\n",
    "                colname = \"col{}\".format(y.output_column)\n",
    "            if colname not in ocol:\n",
    "                try:\n",
    "                    col_counter[colname] += 1\n",
    "                except:\n",
    "                    col_counter[colname] = 0     \n",
    "                process[\"state_{}\".format(prev_state)][\"output\"].append(\"{colname}_{counter}\".format(colname=colname,counter=col_counter[colname]))\n",
    "                ocol.add(colname)\n",
    "        #print(state_pd)\n",
    "    except:\n",
    "        #print(x.command)\n",
    "        pass\n",
    "\n",
    "    process[\"state_{}\".format(prev_state)][\"desc\"] = xx[\"description\"]\n",
    "    \n",
    "    try:\n",
    "        process[\"state_{}\".format(prev_state)][\"op\"] = xx[\"operation\"][\"op\"]\n",
    "        try:\n",
    "            process[\"state_{}\".format(prev_state)][\"annotation\"] = x.process_annotation\n",
    "        except:\n",
    "            process[\"state_{}\".format(prev_state)][\"annotation\"] =  xx[\"operation\"][\"op\"]\n",
    "        process[\"state_{}\".format(prev_state)][\"operation\"] = xx[\"operation\"]\n",
    "    except:\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_recipe = orpe.get_linear_recipe()\n",
    "\n",
    "process = {}\n",
    "col_counter = {}\n",
    "max_state = orpe.get_number_of_state()\n",
    "\n",
    "for x in linear_recipe.sort_values(\"state_id\",ascending=False).to_records():\n",
    "    sid = x.state_id    \n",
    "    print(sid)\n",
    "\n",
    "\n",
    "    xx = json.loads(x.detail)\n",
    "\n",
    "    real_state = max_state.values[0][0]-x.state_id    \n",
    "    prev_state = max_state.values[0][0]-x.prev_state_id\n",
    "    print(x.prev_state_id)\n",
    "\n",
    "    if real_state == 0:\n",
    "        input_name = \"tableoriginal\"\n",
    "    else:\n",
    "        input_name = \"table{}\".format(real_state) \n",
    "\n",
    "    process[\"state_{}\".format(prev_state)] = {}\n",
    "    try:\n",
    "        state_pd = state_col_dep.groupby(\"state_id\").get_group(sid)\n",
    "        process[\"state_{}\".format(prev_state)][\"input\"] = []\n",
    "        process[\"state_{}\".format(prev_state)][\"output\"] = []\n",
    "\n",
    "        icol = set()\n",
    "        ocol = set()\n",
    "        for y in state_pd.to_records():\n",
    "            colname = \"col{}\".format(y.input_column)\n",
    "            if colname not in icol:\n",
    "                try:\n",
    "                    col_counter[colname] #+= 1\n",
    "                except:\n",
    "                    col_counter[colname] = 0                                                \n",
    "                process[\"state_{}\".format(prev_state)][\"input\"].append(\"{colname}_{counter}\".format(colname=colname,counter=col_counter[colname]))\n",
    "                icol.add(colname)\n",
    "            \n",
    "            if y.output_column==-2:\n",
    "                colname = \"col_removed\"\n",
    "            else:\n",
    "                colname = \"col{}\".format(y.output_column)\n",
    "            if colname not in ocol:\n",
    "                try:\n",
    "                    col_counter[colname] += 1\n",
    "                except:\n",
    "                    col_counter[colname] = 0     \n",
    "                process[\"state_{}\".format(prev_state)][\"output\"].append(\"{colname}_{counter}\".format(colname=colname,counter=col_counter[colname]))\n",
    "                ocol.add(colname)\n",
    "        #print(state_pd)\n",
    "    except:\n",
    "        pass\n",
    "        #print(x.command)\n",
    "\n",
    "    process[\"state_{}\".format(prev_state)][\"desc\"] = xx[\"description\"]\n",
    "    try:\n",
    "        process[\"state_{}\".format(prev_state)][\"annotation\"] = x.process_annotation\n",
    "    except:\n",
    "        process[\"state_{}\".format(prev_state)][\"annotation\"] =  \"\"\n",
    "    try:\n",
    "        process[\"state_{}\".format(prev_state)][\"op\"] = xx[\"operation\"][\"op\"]\n",
    "        if process[\"state_{}\".format(prev_state)][\"annotation\"] == \"\":\n",
    "            process[\"state_{}\".format(prev_state)][\"annotation\"] = xx[\"operation\"][\"op\"]\n",
    "        process[\"state_{}\".format(prev_state)][\"operation\"] = xx[\"operation\"]\n",
    "    except:\n",
    "        pass           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_number_of_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_def = \"\"\"\n",
    "digraph \"[stackcollapse]\" {\n",
    "node [style=filled fillcolor=\"#f8f8f8\"]\n",
    "\"\"\"\n",
    "\n",
    "edge_def = \"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "parallel_graph = nx.DiGraph()\n",
    "\n",
    "\n",
    "for key,val in process.items():\n",
    "    temp_desc = \"{state}\\\\n\".format(state=key)\n",
    "    try:\n",
    "        temp_desc += val[\"op\"] +\"\\\\n\" + val[\"annotation\"] +\"\\\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    temp_desc += val[\"desc\"]\n",
    "    nodes_def+=\"\"\"\n",
    "        {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=box tooltip=\"{tt}\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "    \"\"\".format(x=key,label=temp_desc.replace('\"',\"'\"),id=key,tt=\"\")\n",
    "    colkey = key.split(\"_\")[-1]\n",
    "    parallel_graph.add_node(key,label=temp_desc,type=\"state\",t_id=colkey)\n",
    "    try:\n",
    "        val[\"input\"]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    col_state = orpe.get_column_at_state(key.split(\"_\")[-1])\n",
    "    #print(col_state)\n",
    "    \n",
    "    for valinput in val[\"input\"]:\n",
    "        if valinput not in isinput:\n",
    "            try:\n",
    "                colkey = valinput.split(\"_\")[0].split(\"col\")[-1]\n",
    "                #print(colkey)\n",
    "                colname = col_state[col_state.col_id==int(colkey)].col_name.values[0]\n",
    "                #print(colname)\n",
    "            except:\n",
    "                #print(colkey)\n",
    "                colname = \"\"\n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valinput,label=valinput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valinput)\n",
    "            \n",
    "            parallel_graph.add_node(valinput,label=valinput,type=\"col\",t_id=colkey)\n",
    "\n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=valinput,output=key,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(valinput,key)\n",
    "    for valoutput in val[\"output\"]:\n",
    "        if valoutput not in isinput:\n",
    "            try:\n",
    "                colkey = valoutput.split(\"_\")[0].split(\"col\")[-1]\n",
    "                #print(colkey)\n",
    "                colname = col_state[col_state.col_id==int(colkey)].col_name.values[0]\n",
    "                #print(colname)\n",
    "            except:\n",
    "                #print(colkey)\n",
    "                colname = \"\"\n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valoutput,label=valoutput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valoutput)\n",
    "\n",
    "            parallel_graph.add_node(valoutput,label=valoutput,type=\"col\",t_id=colkey)\n",
    "\n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=key,output=valoutput,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(key,valoutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_column_at_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test = reuse_recipe(0)\n",
    "_, test2 = reuse_recipe(1)\n",
    "test.extend(test2)\n",
    "_, test2 = reuse_recipe(7)\n",
    "test.extend(test2)\n",
    "_, test2 = reuse_recipe(8)\n",
    "test.extend(test2)\n",
    "\n",
    "simple_process = {}\n",
    "for x in test:\n",
    "    st = orpe.get_state_to_step(x)+1\n",
    "    try:\n",
    "        simple_process[\"state_{}\".format(st)] = freq_pattern_process[\"state_{}\".format(st)]\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(simple_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel yesworkflow format\n",
    "\n",
    "nodes_def = \"\"\"\n",
    "digraph \"[stackcollapse]\" {\n",
    "node [style=filled fillcolor=\"#f8f8f8\"]\n",
    "\"\"\"\n",
    "\n",
    "edge_def = \"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "process_nodes = []\n",
    "data_nodes_in = set()\n",
    "data_nodes_out = set()\n",
    "\n",
    "parallel_graph = nx.DiGraph()\n",
    "\n",
    "for key,val in process.items():\n",
    "#for key,val in collapsed_process.items():\n",
    "#for key,val in freq_pattern.items():\n",
    "#for key,val in simple_process.items():\n",
    "    temp_name = \"{state}\\\\n\".format(state=key)\n",
    "    temp_desc = \"\"\n",
    "    try:\n",
    "        temp_desc += val[\"op\"] +\"\\\\n\" + val[\"annotation\"] +\"\\\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    temp_desc += val[\"desc\"]\n",
    "    nodes_def+=\"\"\"\n",
    "        {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=box tooltip=\"{tt}\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "    \"\"\".format(x=key,label=temp_name+temp_desc.replace('\"',\"'\"),id=key,tt=\"\")\n",
    "    colkey = key.split(\"_\")[-1]\n",
    "    parallel_graph.add_node(key,label=temp_desc,type=\"state\",t_id=colkey)\n",
    "    try:\n",
    "        val[\"input\"]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    temp_process_yw = \"\"\"\n",
    "    #@begin {key} #@desc {desc} \n",
    "    \"\"\".format(key=key,desc=temp_desc.replace('\"',\"'\"))\n",
    "    #format(key=key,desc=key)\n",
    "    \n",
    "    \n",
    "    col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1]))\n",
    "    \n",
    "    prev_col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1])-1)\n",
    "    \n",
    "    if int(key.split(\"_\")[-1])==25:\n",
    "        print(\"cstate\",key,col_state)\n",
    "        print(\"pstate\",key,prev_col_state)\n",
    "\n",
    "    \n",
    "    for valinput in val[\"input\"]:\n",
    "        try:\n",
    "            colkey = valinput.split(\"_\")[0].split(\"col\")[-1]\n",
    "            #print(colkey)\n",
    "            colname = prev_col_state[prev_col_state.col_id==int(colkey)].col_name.values[0]\n",
    "            #print(\"colname-x\",colname)\n",
    "        except:\n",
    "            #print(colkey)\n",
    "            colname = \"\"        \n",
    "        if valinput not in isinput:            \n",
    "            #prev_col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1])+1)            \n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valinput,label=valinput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valinput)\n",
    "            \n",
    "            parallel_graph.add_node(valinput,label=valinput,type=\"col\",t_id=colkey)\n",
    "        \n",
    "        #print(col_state)\n",
    "\n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=valinput,output=key,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(valinput,key)\n",
    "        data_nodes_in.add(\"{key}-{colname}\".format(key=valinput,colname=colname).replace(\" \",\"_\"))\n",
    "        temp_process_yw += \"\"\"\n",
    "        #@in \"\"\"+ \"\"\"{key}-{colname}\n",
    "            \"\"\".format(key=valinput,colname=colname).replace(\" \",\"_\")\n",
    "    for valoutput in val[\"output\"]:\n",
    "        try:\n",
    "            colkey = valoutput.split(\"_\")[0].split(\"col\")[-1]\n",
    "            #print(colkey)\n",
    "            colname = col_state[col_state.col_id==int(colkey)].col_name.values[0]\n",
    "            #print(colname)\n",
    "        except:\n",
    "            #print(colkey)\n",
    "            colname = \"\"       \n",
    "            \n",
    "        if valoutput not in isinput:\n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valoutput,label=valoutput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valoutput)\n",
    "\n",
    "            parallel_graph.add_node(valoutput,label=valoutput,type=\"col\",t_id=colkey)\n",
    "\n",
    "        #print(col_state)\n",
    "        \n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=key,output=valoutput,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(key,valoutput)\n",
    "        data_nodes_out.add(\"{key}-{colname}\".format(key=valoutput,colname=colname).replace(\" \",\"_\"))\n",
    "        temp_process_yw += \"\"\"\n",
    "        #@out \"\"\"+\"\"\"{key}-{colname}\n",
    "        \"\"\".format(key=valoutput,colname=colname).replace(\" \",\"_\")\n",
    "\n",
    "    temp_process_yw += \"\"\"\n",
    "    #@end {key}     \n",
    "    \"\"\".format(key=key)\n",
    "    process_nodes.append(temp_process_yw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow template gv format\n",
    "\n",
    "header = \"\"\"\n",
    "/* Start of top-level graph */\n",
    "digraph Workflow {\n",
    "rankdir=TB\n",
    "\n",
    "/* Start of double cluster for drawing box around nodes in workflow */\n",
    "subgraph cluster_workflow_box_outer { label=\"\"; penwidth=0\n",
    "subgraph cluster_workflow_box_inner { label=\"\"; penwidth=0\n",
    "\"\"\"\n",
    "\n",
    "single_process = \"\"\"\n",
    "/* Style for nodes representing atomic programs in workflow */\n",
    "node[shape=box style=filled fillcolor=\"#CCFFCC\" peripheries=1 fontname=Helvetica]\n",
    "\n",
    "/* Nodes representing atomic programs in workflow */\n",
    "\"\"\"\n",
    "#state_4 [shape=record rankdir=LR label=\"{<f0> step 4 (to_date) | grel\\:value.replace(/\\\\/i,'') | 16492 cells changed}\"];\n",
    "\n",
    "\n",
    "group_process_nodes = \"\"\"\n",
    "node[shape=box style=filled fillcolor=\"#CCCCFF\" peripheries=1 fontname=Helvetica]\n",
    "\"\"\"\n",
    "#state_5 [shape=record rankdir=LR label=\"{<f0> state_5 |<f1> core/mass-edit\\nclustering\\ngroup clustering 4 processes}\"];\n",
    "\n",
    "freq_pattern_nodes = \"\"\"\n",
    "node[shape=box style=filled fillcolor=\"#CCFFFF\" peripheries=1 fontname=Helvetica]\n",
    "\"\"\"\n",
    "#state_5 [shape=record rankdir=LR label=\"{<f0> state_5 |<f1> core/mass-edit\\nclustering\\ngroup clustering 4 processes}\"];\n",
    "\n",
    "column_nodes = \"\"\"\n",
    "/* Style for nodes representing non-parameter data channels in workflow */\n",
    "node[shape=box style=\"rounded,filled\" fillcolor=\"#FFFFCC\" peripheries=1 fontname=Helvetica]\n",
    "\n",
    "/* Nodes for non-parameter data channels in workflow */\n",
    "\"\"\"\n",
    "#\"col12_0-date\" [shape=record rankdir=LR label=\"{<f0> date_0 }\"]\n",
    "\n",
    "parameters_nodes = \"\"\"\n",
    "/* Style for nodes representing parameter channels in workflow */\n",
    "node[shape=box style=\"rounded,filled\" fillcolor=\"#FCFCFC\" peripheries=1 fontname=Helvetica]\n",
    "\n",
    "/* Nodes representing parameter channels in workflow */\n",
    "\"\"\"\n",
    "\n",
    "edges = \"\"\"\n",
    "/* Edges representing connections between programs and channels */\n",
    "\"\"\"\n",
    "#\"col12_0-date\" -> state_4\n",
    "\n",
    "\n",
    "footer = \"\"\"\n",
    "/* End of double cluster for drawing box around nodes in workflow */\n",
    "}}\n",
    "\n",
    "/* End of top-level graph */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "process_nodes = []\n",
    "data_nodes_in = set()\n",
    "data_nodes_out = set()\n",
    "\n",
    "parallel_graph = nx.DiGraph()\n",
    "\n",
    "for key,val in process.items():\n",
    "#for key,val in collapsed_process.items():\n",
    "#for key,val in freq_pattern_process.items():\n",
    "#for key,val in simple_process.items():\n",
    "    try:\n",
    "        # remove single process\n",
    "        val[\"input\"]\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    try:\n",
    "        group_process = val[\"group_process\"]\n",
    "        step_name = \"Step {}\".format(key.split(\"_\")[-1])\n",
    "    except:\n",
    "        group_process = []\n",
    "        step_name = \"Step {}\".format(key.split(\"_\")[-1])\n",
    "\n",
    "    try:\n",
    "        freq_pattern = val[\"freq_pattern\"]\n",
    "        step_name = \"Step {}\".format(key.split(\"_\")[-1])\n",
    "    except:\n",
    "        freq_pattern = []\n",
    "        step_name = \"Step {}\".format(key.split(\"_\")[-1])\n",
    "\n",
    "    try:\n",
    "        json_recipe = val[\"operation\"]\n",
    "    except:\n",
    "        json_recipe = {}\n",
    "        json_recipe[\"op\"] = \"single-operation\"\n",
    "        val[\"op\"] = \"single-operation\"\n",
    "\n",
    "    detail = \"\"\n",
    "\n",
    "    #if (len(group_process)==0) & (len(freq_pattern)==0) & () \n",
    "\n",
    "    #if len(freq_pattern_process)>0:\n",
    "        \n",
    "    if len(group_process)==0:\n",
    "        if len(freq_pattern)>0:\n",
    "            for y in freq_pattern[1]:\n",
    "                pname = y[0][2]\n",
    "                internal_group = [y[0]] + y[2]\n",
    "                detail += \"| {}{} \".format(\"group-\" if len(internal_group)>1 else \"\",pname)\n",
    "                # if freq_pattern is cluster\n",
    "                if len(internal_group)>0:                    \n",
    "                    detail+=\" ({}, {})\".format(internal_group[0][0],len(internal_group))\n",
    "\n",
    "                    for x in internal_group:\n",
    "                        temp_val = process[x[0]]\n",
    "                        try:\n",
    "                            json_recipe = temp_val[\"operation\"]\n",
    "                        except:\n",
    "                            json_recipe = {}\n",
    "                            json_recipe[\"op\"] = \"single-operation\"\n",
    "                            temp_val[\"op\"] = \"single-operation\"\n",
    "                                                \n",
    "                        \"\"\"\n",
    "                        if temp_val[\"op\"]==\"core/mass-edit\":\n",
    "                            cells_variance = sum([len(x[\"from\"]) for x in json_recipe[\"edits\"]])\n",
    "                            cells_affected = int(temp_val[\"desc\"].split(\"edit\")[-1].split(\"cells\")[0])\n",
    "                            detail+=\"| {} =\\> {}, {} cells\".format(cells_variance,len(json_recipe[\"edits\"]),cells_affected)\n",
    "                        else:\n",
    "                            try:\n",
    "                                cells_affected = int(temp_val[\"desc\"].split(\"Text transform on\")[-1].split(\"cells\")[0])        \n",
    "                                detail += \"| {}, {} changed\".format(json_recipe[\"expression\"].replace('\"','\\\\\"'),cells_affected)\n",
    "                            except:\n",
    "                                pass\n",
    "                            #break\n",
    "                        \"\"\"\n",
    "                else:                    \n",
    "                    temp_val = process[y[0][0]]\n",
    "                    try:\n",
    "                        json_recipe = temp_val[\"operation\"]\n",
    "                    except:\n",
    "                        json_recipe = {}\n",
    "                        json_recipe[\"op\"] = \"single-operation\"   \n",
    "                        temp_val[\"op\"] = \"single-operation\"\n",
    "                              \n",
    "                    if temp_val[\"op\"]==\"core/mass-edit\":\n",
    "                        cells_variance = sum([len(x[\"from\"]) for x in json_recipe[\"edits\"]])\n",
    "                        cells_affected = int(temp_val[\"desc\"].split(\"edit\")[-1].split(\"cells\")[0])\n",
    "                        detail+=\"| {} =\\> {}, {} cells\".format(cells_variance,len(json_recipe[\"edits\"]),cells_affected)\n",
    "                    else:\n",
    "                        try:\n",
    "                            cells_affected = int(temp_val[\"desc\"].split(\"Text transform on\")[-1].split(\"cells\")[0])        \n",
    "                            detail += \"| {}, {} changed\".format(json_recipe[\"expression\"].replace('\"','\\\\\"'),cells_affected)\n",
    "                        except:\n",
    "                            pass\n",
    "                            \n",
    "        else:\n",
    "            if val[\"op\"]!=\"core/mass-edit\":\n",
    "                try:\n",
    "                    detail += \"| {} \".format(json_recipe[\"expression\"].replace('\"','\\\\\"'))\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                \"\"\"\n",
    "                for x in json_recipe[\"edits\"]:\n",
    "                    detail+=\",\".join(x[\"from\"])[:25]+\" ({})\".format(len(x[\"from\"]))+\" => \"+x[\"to\"][:25]+\"\\n\"\n",
    "                \"\"\"\n",
    "                cells_variance = sum([len(x[\"from\"]) for x in json_recipe[\"edits\"]])\n",
    "                \n",
    "                detail+=\"| {} =\\> {} clusters\".format(cells_variance,len(json_recipe[\"edits\"]))\n",
    "    else:\n",
    "        for x in group_process:\n",
    "            temp_val = process[x[0]]\n",
    "            try:\n",
    "                json_recipe = temp_val[\"operation\"]\n",
    "            except:\n",
    "                json_recipe = {}\n",
    "                json_recipe[\"op\"] = \"single-operation\"\n",
    "                val[\"op\"] = \"single-operation\"\n",
    "            if temp_val[\"op\"]==\"core/mass-edit\":\n",
    "                cells_variance = sum([len(x[\"from\"]) for x in json_recipe[\"edits\"]])\n",
    "                cells_affected = int(temp_val[\"desc\"].split(\"edit\")[-1].split(\"cells\")[0])\n",
    "                detail+=\"| {} =\\> {}, {} cells\".format(cells_variance,len(json_recipe[\"edits\"]),cells_affected)\n",
    "            else:\n",
    "                try:\n",
    "                    cells_affected = int(temp_val[\"desc\"].split(\"Text transform on\")[-1].split(\"cells\")[0])        \n",
    "                    detail += \"| {}, {} changed\".format(json_recipe[\"expression\"].replace('\"','\\\\\"'),cells_affected)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    description = \"\"\n",
    "    if (len(group_process)==0) & (len(freq_pattern)==0):\n",
    "        if val[\"op\"]==\"core/mass-edit\":\n",
    "            cells_affected = int(val[\"desc\"].split(\"edit\")[-1].split(\"cells\")[0])\n",
    "            description+=\"| {} cells affected\".format(cells_affected)\n",
    "        elif val[\"op\"]==\"core/text-transform\":\n",
    "            cells_affected = int(val[\"desc\"].split(\"Text transform on\")[-1].split(\"cells\")[0])        \n",
    "            description+=\"| {} cells changed\".format(cells_affected)\n",
    "\n",
    "    if len(freq_pattern)>0:\n",
    "        freq_pattern_nodes+='''\n",
    "        {state_id} [shape=record rankdir=LR label=\"{{<f0> {step_name} ({function_name}) {detail} {description}}}\"];\n",
    "        '''.format(state_id=key,step_name=step_name,function_name=freq_pattern[0],detail=detail,description=description)    \n",
    "    elif len(group_process)>0:\n",
    "        group_process_nodes+='''\n",
    "        {state_id} [shape=record rankdir=LR label=\"{{<f0> {step_name} ({is_group}{function_name}) {detail} {description}}}\"];\n",
    "        '''.format(state_id=key,step_name=step_name,is_group=\"group-\" if len(group_process)>0 else \"\",function_name=val[\"annotation\"],detail=detail,description=description)\n",
    "    else:  \n",
    "        single_process+='''\n",
    "        {state_id} [shape=record rankdir=LR label=\"{{<f0> {step_name} ({is_group}{function_name}) {detail} {description}}}\"];\n",
    "        '''.format(state_id=key,step_name=step_name,is_group=\"group-\" if len(group_process)>0 else \"\",function_name=val[\"annotation\"],detail=detail,description=description)\n",
    "        #print(single_process)\n",
    "\n",
    "    \n",
    "\n",
    "    temp_name = \"{state}\\\\n\".format(state=key)\n",
    "    temp_desc = \"\"\n",
    "    try:\n",
    "        temp_desc += val[\"op\"] +\"\\\\n\" + val[\"annotation\"] +\"\\\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    temp_desc += val[\"desc\"]\n",
    "    nodes_def+=\"\"\"\n",
    "        {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=box tooltip=\"{tt}\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "    \"\"\".format(x=key,label=temp_name+temp_desc.replace('\"',\"'\"),id=key,tt=\"\")\n",
    "        \n",
    "    colkey = key.split(\"_\")[-1]\n",
    "    parallel_graph.add_node(key,label=temp_desc,type=\"state\",t_id=colkey)\n",
    "    try:\n",
    "        val[\"input\"]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    temp_process_yw = \"\"\"\n",
    "    #@begin {key} #@desc {desc} \n",
    "    \"\"\".format(key=key,desc=temp_desc.replace('\"',\"'\"))\n",
    "    #format(key=key,desc=key)\n",
    "    \n",
    "    \n",
    "    col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1]))\n",
    "    \n",
    "    prev_col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1])-1)\n",
    "    \n",
    "    #if int(key.split(\"_\")[-1])==25:\n",
    "    #    print(\"cstate\",key,col_state)\n",
    "    #    print(\"pstate\",key,prev_col_state)\n",
    "\n",
    "    \n",
    "    for valinput in val[\"input\"]:\n",
    "        try:\n",
    "            colkey = valinput.split(\"_\")[0].split(\"col\")[-1]\n",
    "            #print(colkey)\n",
    "            colname = prev_col_state[prev_col_state.col_id==int(colkey)].col_name.values[0]\n",
    "            #print(\"colname-x\",colname)\n",
    "        except:\n",
    "            print(colkey)\n",
    "            colname = colkey \n",
    "        if valinput not in isinput:            \n",
    "            #prev_col_state = orpe.get_column_at_state(int(key.split(\"_\")[-1])+1)            \n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valinput,label=valinput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valinput)\n",
    "            \n",
    "            parallel_graph.add_node(valinput,label=valinput,type=\"col\",t_id=colkey)\n",
    "        \n",
    "        #print(col_state)\n",
    "\n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=valinput,output=key,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(valinput,key)\n",
    "        data_nodes_in.add(\"{key}-{colname}\".format(key=valinput,colname=colname).replace(\" \",\"_\"))\n",
    "        temp_process_yw += \"\"\"\n",
    "        #@in \"\"\"+ \"\"\"{key}-{colname}\n",
    "            \"\"\".format(key=valinput,colname=colname).replace(\" \",\"_\")\n",
    "        \n",
    "        col_label = \"{}_{}\".format(colname,valinput.split(\"_\")[-1]) \n",
    "        column_nodes+=\"\"\"\n",
    "        \"{node_name}\" [shape=record rankdir=LR label=\"{{<f0> {label} }}\"]\n",
    "        \"\"\".format(node_name=valinput,label=col_label)\n",
    "\n",
    "        edges+=\"\"\"\n",
    "        \"{}\" -> {}\n",
    "        \"\"\".format(valinput,key)\n",
    "\n",
    "    for valoutput in val[\"output\"]:\n",
    "        try:\n",
    "            colkey = valoutput.split(\"_\")[0].split(\"col\")[-1]\n",
    "            #print(colkey)\n",
    "            colname = col_state[col_state.col_id==int(colkey)].col_name.values[0]\n",
    "            #print(colname)\n",
    "        except:\n",
    "            #print(colkey)\n",
    "            colname = \"_\".join(valoutput.split(\"_\")[:-1])\n",
    "            \n",
    "        if valoutput not in isinput:\n",
    "            nodes_def+=\"\"\"\n",
    "                {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "            \"\"\".format(x=valoutput,label=valoutput.replace('\"',\"'\")+\"\\\\n\"+colname,id=key,tt=\"\")\n",
    "            isinput.add(valoutput)\n",
    "\n",
    "            parallel_graph.add_node(valoutput,label=valoutput,type=\"col\",t_id=colkey)\n",
    "\n",
    "        #print(col_state)\n",
    "        \n",
    "        edge_def+=\"\"\"\n",
    "            {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "        \"\"\".format(input=key,output=valoutput,data=\"\")\n",
    "\n",
    "        parallel_graph.add_edge(key,valoutput)\n",
    "        data_nodes_out.add(\"{key}-{colname}\".format(key=valoutput,colname=colname).replace(\" \",\"_\"))\n",
    "        temp_process_yw += \"\"\"\n",
    "        #@out \"\"\"+\"\"\"{key}-{colname}\n",
    "        \"\"\".format(key=valoutput,colname=colname).replace(\" \",\"_\")\n",
    "\n",
    "        col_label = \"{}_{}\".format(colname,valoutput.split(\"_\")[-1]) \n",
    "        column_nodes+=\"\"\"\n",
    "        \"{node_name}\" [shape=record rankdir=LR label=\"{{<f0> {label} }}\"]\n",
    "        \"\"\".format(node_name=valoutput,label=col_label)\n",
    "\n",
    "        edges+=\"\"\"\n",
    "        \"{}\" -> {}\n",
    "        \"\"\".format(key,valoutput)\n",
    "\n",
    "    temp_process_yw += \"\"\"\n",
    "    #@end {key}     in\n",
    "    \"\"\".format(key=key)\n",
    "    process_nodes.append(temp_process_yw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in json_recipe[\"edits\"]:\n",
    "#    print(\",\".join(x[\"from\"])[:25]+\" ({})\".format(len(x[\"from\"]))+\" to \"+x[\"to\"][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf(gv_string,filename=\"temp\"):\n",
    "    input = filename+\".gv\"\n",
    "    with open(input,\"w\") as file:\n",
    "        file.write(gv_string)\n",
    "    output = filename+\".pdf\"    \n",
    "    !dot -Tpdf -o $output $input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_string = header+single_process+column_nodes+parameters_nodes+group_process_nodes+freq_pattern_nodes+edges+footer\n",
    "generate_pdf(gv_string)\n",
    "display_yw(gv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_nodes,data_nodes_in-data_nodes_out,data_nodes_out-data_nodes_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_yw = \"\"\"#@begin test_or\n",
    "\"\"\"\n",
    "for x in data_nodes_in-data_nodes_out:\n",
    "    compiled_yw+=\"#@in {}\\n\".format(x)\n",
    "for x in data_nodes_out-data_nodes_in:\n",
    "    compiled_yw+=\"#@out {}\\n\".format(x)    \n",
    "for x in process_nodes:\n",
    "    compiled_yw+=x+\"\\n\"\n",
    "compiled_yw += \"\"\"#@end test_or\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compiled_yw.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_yw(compiled_yw,output=\"temporary.png\"):\n",
    "    with open(\"temporary.yw\",\"w\") as file:\n",
    "        file.write(compiled_yw)\n",
    "    !java -jar yesworkflow-0.2.2.0-SNAPSHOT-jar-with-dependencies.jar  graph temporary.yw -c extract.comment=\"#\" | dot -Tpng -o $output\n",
    "    from IPython.display import Image\n",
    "    return Image(filename=output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf_yw(compiled_yw,output=\"temporary.pdf\"):\n",
    "    with open(\"temporary.yw\",\"w\") as file:\n",
    "        file.write(compiled_yw)\n",
    "    !java -jar yesworkflow-0.2.2.0-SNAPSHOT-jar-with-dependencies.jar  graph temporary.yw -c extract.comment=\"#\" | dot -Tpdf -o $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!java -jar yesworkflow-0.2.2.0-SNAPSHOT-jar-with-dependencies.jar  graph temporary.yw -c extract.comment=\"#\" > collapsed_2.gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpdf -o collapsed_2.pdf \"collapsed_2 copy.gv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pdf_yw(compiled_yw)\n",
    "display_yw(compiled_yw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern = collapsed_process.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_58\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_5\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_13\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_12\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_11\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_10\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_10\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_36\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "freq_pattern[\"state_69\"][\"annotation\"] = \"freq_pattern_analysis\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_58\"][\"output\"] = freq_pattern[\"state_65\"][\"output\"]\n",
    "freq_pattern[\"state_58\"][\"desc\"] = \"sub_process_1\"\n",
    "freq_pattern[\"state_58\"][\"op\"] = \"clustering, remove_char\"\n",
    "del(freq_pattern[\"state_65\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_5\"][\"output\"] = freq_pattern[\"state_67\"][\"output\"]\n",
    "freq_pattern[\"state_5\"][\"desc\"] = \"sub_process_1\"\n",
    "freq_pattern[\"state_5\"][\"op\"] = \"clustering, remove_char\"\n",
    "del(freq_pattern[\"state_67\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_13\"][\"output\"] = freq_pattern[\"state_47\"][\"output\"]\n",
    "freq_pattern[\"state_13\"][\"desc\"] = \"sub_process_2\"\n",
    "freq_pattern[\"state_13\"][\"op\"] = \"upper_case, clustering\"\n",
    "del(freq_pattern[\"state_47\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_12\"][\"output\"] = freq_pattern[\"state_30\"][\"output\"]\n",
    "freq_pattern[\"state_12\"][\"desc\"] = \"sub_process_2\"\n",
    "freq_pattern[\"state_12\"][\"op\"] = \"upper_case, clustering\"\n",
    "del(freq_pattern[\"state_30\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_11\"][\"output\"] = freq_pattern[\"state_23\"][\"output\"]\n",
    "freq_pattern[\"state_11\"][\"desc\"] = \"sub_process_2\"\n",
    "freq_pattern[\"state_11\"][\"op\"] = \"upper_case, clustering\"\n",
    "del(freq_pattern[\"state_23\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_10\"][\"output\"] = freq_pattern[\"state_15\"][\"output\"]\n",
    "freq_pattern[\"state_10\"][\"desc\"] = \"sub_process_2\"\n",
    "freq_pattern[\"state_10\"][\"op\"] = \"upper_case, clustering\"\n",
    "del(freq_pattern[\"state_15\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_36\"][\"output\"] = freq_pattern[\"state_41\"][\"output\"]\n",
    "freq_pattern[\"state_36\"][\"desc\"] = \"sub_process_3\"\n",
    "freq_pattern[\"state_36\"][\"op\"] = \"remove_char, clustering, remove_char, clustering\"\n",
    "del(freq_pattern[\"state_39\"])\n",
    "del(freq_pattern[\"state_40\"])\n",
    "del(freq_pattern[\"state_41\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern[\"state_69\"][\"output\"] = freq_pattern[\"state_86\"][\"output\"]\n",
    "freq_pattern[\"state_69\"][\"desc\"] = \"sub_process_3\"\n",
    "freq_pattern[\"state_69\"][\"op\"] = \"remove_char, clustering, remove_char, clustering\"\n",
    "del(freq_pattern[\"state_81\"])\n",
    "del(freq_pattern[\"state_85\"])\n",
    "del(freq_pattern[\"state_86\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nodes_def+edge_def+\"\\n}\")\n",
    "from graphviz import Source\n",
    "\n",
    "temp = nodes_def+edge_def+\"\\n}\"\n",
    "s = Source(temp)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib import pyplot as plt \n",
    "#plt.figure(figsize=(10,10))\n",
    "#nx.draw_kamada_kawai(parallel_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_state[col_state.col_id==int(colkey)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def parallel_state(parallel_graph,col_name):\n",
    "    state_op_dict = dict(orpe.get_all_state_command().apply(lambda x:(x.state_id,json.loads(x.detail)[\"operation\"]),axis=1).to_list())    \n",
    "    state_graph = nx.DiGraph()\n",
    "    all_path = nx.dfs_successors(parallel_graph,col_name)\n",
    "    print(all_path)\n",
    "    for key,val in all_path.items():\n",
    "        if key.startswith(\"state\"):\n",
    "            try:\n",
    "                print(key)\n",
    "                for vv in all_path[key]:\n",
    "                    for jj in all_path[vv]:\n",
    "                        print(\"out\",jj)            \n",
    "                        state_graph.add_edge(key,jj)\n",
    "            except:\n",
    "                pass\n",
    "    print(state_graph.edges)\n",
    "    sink_nodes = [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree == 0]\n",
    "    source_nodes = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree == 0]\n",
    "    recipes = []\n",
    "    paths = []\n",
    "    for x in [(source, sink) for sink in sink_nodes for source in source_nodes]:\n",
    "        for path in nx.all_simple_paths(state_graph, source=x[0], target=x[1]):\n",
    "            print(x)\n",
    "            temp_path_recipe = list(filter(lambda x:x!=None,[json.loads(state_cmd[state_cmd.state_id==orpe.get_state_to_step(int(yy.split(\"_\")[-1])-1)].detail.values[0])[\"operation\"] for yy in path]))\n",
    "            recipes.append(temp_path_recipe)\n",
    "            paths.append(path)\n",
    "    return recipes,paths\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel process / recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_state(parallel_graph,col_name):\n",
    "    sink_nodes = [node for node, outdegree in dict(parallel_graph.out_degree(parallel_graph.nodes())).items() if outdegree == 0]\n",
    "    source_nodes = [col_name]\n",
    "    recipes = []\n",
    "    data = []\n",
    "    paths = []\n",
    "    for x in [(source, sink) for sink in sink_nodes for source in source_nodes]:\n",
    "        a_simple_path = list(nx.all_simple_paths(parallel_graph, source=x[0], target=x[1]))\n",
    "        a_state_path = [list(filter(lambda x:x.startswith(\"state\"), x)) for x in a_simple_path]\n",
    "        #print(a_simple_path)\n",
    "        a_data = [list(filter(lambda x:x.startswith(\"col\"), x)) for x in a_simple_path]\n",
    "        for i,path in enumerate(a_state_path):\n",
    "            print(x)\n",
    "            temp_path_recipe = list(filter(lambda x:x!=None,[json.loads(state_cmd[state_cmd.state_id==orpe.get_state_to_step(int(yy.split(\"_\")[-1])-1)].detail.values[0])[\"operation\"] for yy in path]))\n",
    "            recipes.append(temp_path_recipe)\n",
    "            paths.append((path,a_data[i]))\n",
    "    return recipes,paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_nodes(parallel_graph):\n",
    "    sink_nodes = [node for node, outdegree in dict(parallel_graph.out_degree(parallel_graph.nodes())).items() if outdegree == 0]\n",
    "    source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "    #res_cluster = {}\n",
    "    res_cluster = {x:[] for x in source_nodes}\n",
    "    #print(res_cluster)\n",
    "    #try:\n",
    "    #        res_cluster[x[0]] = []\n",
    "    #except:\n",
    "    #    pass\n",
    "    for x in [(source, sink) for sink in sink_nodes for source in source_nodes]:\n",
    "        #print(x)\n",
    "        all_simple_path = list(nx.all_simple_paths(parallel_graph, source=x[0], target=x[1]))\n",
    "        all_state_path = [list(filter(lambda x:x.startswith(\"state\"), x)) for x in all_simple_path]\n",
    "        all_data = [list(filter(lambda x:x.startswith(\"col\"), x)) for x in all_simple_path]\n",
    "\n",
    "\n",
    "        #a_state_path = [list(filter(lambda x:x.startswith(\"state\"), x)) for x in a_simple_path]\n",
    "        #a_data = [list(filter(lambda x:x.startswith(\"col\"), x)) for x in a_simple_path]\n",
    "        \n",
    "        for ii,a_simple_path in enumerate(all_simple_path):\n",
    "            #print(set(a_simple_path))\n",
    "            if len(a_simple_path) > 0:\n",
    "                #if len()\n",
    "                is_intersect = False\n",
    "                for y in res_cluster.copy():\n",
    "                    if len(res_cluster[y])>0:\n",
    "                        for j in res_cluster[y].copy(): \n",
    "                            #print(j)                   \n",
    "                            if len(set(a_simple_path).intersection(j[0]))>0:\n",
    "                                res_cluster[y].append((a_simple_path,all_state_path[ii],all_data[ii]))\n",
    "                                is_intersect = True\n",
    "                            #else:\n",
    "                            #    res_cluster[x[0]].append(a_simple_path)     \n",
    "                if not is_intersect:\n",
    "                    res_cluster[x[0]].append((a_simple_path,all_state_path[ii],all_data[ii]))     \n",
    "    return res_cluster                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cluster_nodes = cluster_nodes(parallel_graph)\n",
    "a_cluster_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceTicker:\n",
    "    ticker = -1\n",
    "    def __init__(self,path,possible_set,id):\n",
    "        self.path = path\n",
    "        #print(self.path)\n",
    "        self.len_path = len(path)\n",
    "        self.possible_set = possible_set\n",
    "        self.id = id\n",
    "\n",
    "    def is_end_ticker(self):\n",
    "        #print(self.len_path, self.ticker)\n",
    "        if self.len_path-1 == self.ticker:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def next_pos_ticker(self):\n",
    "        try:\n",
    "            self.possible_set[self.path[self.ticker+1]].remove(self.id)\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return self.path[self.ticker+1]\n",
    "\n",
    "    def move_up_ticker(self):\n",
    "        is_pass = False\n",
    "        #print(self.is_end_ticker())\n",
    "        if (not self.is_end_ticker()):\n",
    "            if not self.next_pos_ticker():\n",
    "                return None\n",
    "\n",
    "        try:\n",
    "            is_pass = len(self.possible_set[self.path[self.ticker+1]]) == 0            \n",
    "        except:\n",
    "            #if no lock\n",
    "            is_pass = True            \n",
    "\n",
    "        #print(is_pass,self.is_end_ticker)\n",
    "\n",
    "        if (not self.is_end_ticker()) and is_pass:\n",
    "            self.ticker+=1\n",
    "            return self.path[self.ticker]\n",
    "\n",
    "\n",
    "for key,val in a_cluster_nodes.items():\n",
    "    #print(key,val)\n",
    "    all_parallel_test = val\n",
    "    #print(all_parallel_test)\n",
    "\n",
    "    possible_set = {}\n",
    "    for i,x in enumerate(all_parallel_test[:-1]):\n",
    "        for j,y in enumerate(all_parallel_test[i+1:]):\n",
    "            #print(x,y)\n",
    "            temp_intersect = set(x[1]).intersection(y[1])\n",
    "            #print(i,j+i+1,temp_intersect)\n",
    "            for xx in temp_intersect:\n",
    "                try:\n",
    "                    possible_set[xx]\n",
    "                except:\n",
    "                    possible_set[xx] = set()\n",
    "                possible_set[xx].add(i)\n",
    "                possible_set[xx].add(j+i+1)\n",
    "\n",
    "    #print(possible_set)\n",
    "\n",
    "    ticker = [TraceTicker(x[1],possible_set,id) for id,x in  enumerate(all_parallel_test)]\n",
    "    # check end condition\n",
    "    end_condition = np.sum([x.is_end_ticker() for x in ticker])\n",
    "\n",
    "\n",
    "    trace_ticker = set()\n",
    "\n",
    "    combined_recipe = []\n",
    "\n",
    "    while not end_condition:\n",
    "        for id,x in enumerate(ticker):\n",
    "            xx = x.move_up_ticker()\n",
    "            if xx != None:\n",
    "                if xx not in trace_ticker:\n",
    "                    trace_ticker.add(xx)\n",
    "                    #print(id,xx)\n",
    "                    combined_recipe.append(xx)\n",
    "        end_condition = np.sum([x.is_end_ticker() for x in ticker]) == len(ticker)\n",
    "    \n",
    "    print(key,combined_recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_recipe = {}\n",
    "for key,value in a_cluster_nodes.items(): \n",
    "    cluster_recipe[key] = value\n",
    "cluster_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cmd = orpe.get_all_state_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes = [node for node, outdegree in dict(parallel_graph.out_degree(parallel_graph.nodes())).items() if outdegree == 0]\n",
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "\n",
    "all_parallel_test = []\n",
    "for x in source_nodes: \n",
    "    all_parallel_test.extend(parallel_state(parallel_graph,x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parallel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parallel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "state_graph = nx.DiGraph()\n",
    "for x in all_parallel_test:\n",
    "    #print(x[0])\n",
    "    if len(x[0])>1:\n",
    "        for i,y in enumerate(x[0][:-1]):\n",
    "            state_graph.add_edge(y,x[0][i+1])\n",
    "    else:\n",
    "        #print(y)\n",
    "        state_graph.add_node(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_sink_nodes = [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree == 0]\n",
    "start_source_nodes = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree == 0]\n",
    "end_split =  [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree > 1]\n",
    "start_split =   list(set([x[1] for x in state_graph.out_edges(end_split)]))\n",
    "start_merge = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree > 1]\n",
    "end_merge =   list(set([x[0] for x in state_graph.in_edges(start_merge)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes = [node for node, outdegree in dict(parallel_graph.out_degree(parallel_graph.nodes())).items() if outdegree == 0]\n",
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "\n",
    "all_parallel_test = []\n",
    "for x in source_nodes: \n",
    "    all_parallel_test.extend(parallel_state(parallel_graph,x)[1])\n",
    "\n",
    "import networkx as nx\n",
    "state_graph = nx.DiGraph()\n",
    "for x in all_parallel_test:\n",
    "    #print(x[0])\n",
    "    if len(x[0])>1:\n",
    "        for i,y in enumerate(x[0][:-1]):\n",
    "            state_graph.add_edge(y,x[0][i+1])\n",
    "    else:\n",
    "        #print(y)\n",
    "        state_graph.add_node(x[0][0])\n",
    "\n",
    "end_sink_nodes = [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree == 0]\n",
    "start_source_nodes = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree == 0]\n",
    "end_split =  [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree > 1]\n",
    "start_split =   list(set([x[1] for x in state_graph.out_edges(end_split)]))\n",
    "start_merge = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree > 1]\n",
    "end_merge =   list(set([x[0] for x in state_graph.in_edges(start_merge)]))\n",
    "\n",
    "\n",
    "start_points = start_source_nodes+start_split+start_merge\n",
    "end_points = end_sink_nodes+end_split+end_merge\n",
    "\n",
    "cluster = {}\n",
    "for x in start_points:\n",
    "    for y in end_points:\n",
    "        try:\n",
    "            #print(x)\n",
    "            ps = nx.shortest_path(state_graph,x,y)\n",
    "            try:\n",
    "                if len(ps) < len(cluster[ps[-1]]):\n",
    "                    cluster[ps[-1]] = ps\n",
    "            except:\n",
    "                cluster[ps[-1]] = ps\n",
    "            #print(ps)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_points = start_source_nodes+start_split+start_merge\n",
    "end_points = end_sink_nodes+end_split+end_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_points,end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.shortest_path(state_graph,\"state_12\",\"state_77\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "for x in start_points:\n",
    "    for y in end_points:\n",
    "        try:\n",
    "            #print(x)\n",
    "            ps = nx.shortest_path(state_graph,x,y)\n",
    "            try:\n",
    "                if len(ps) < len(cluster[ps[-1]]):\n",
    "                    cluster[ps[-1]] = ps\n",
    "            except:\n",
    "                cluster[ps[-1]] = ps\n",
    "            #print(ps)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster[\"state_14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in state_graph.edges(end_split[0]):\n",
    "#    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection of columns at state derived from all_parallel_test (return index of the parallel test)\n",
    "\n",
    "possible_set = {}\n",
    "for i,x in enumerate(all_parallel_test[:-1]):\n",
    "    for j,y in enumerate(all_parallel_test[i+1:]):\n",
    "        temp_intersect = set(x[0]).intersection(y[0])\n",
    "        #print(i,j+i+1,temp_intersect)\n",
    "        for xx in temp_intersect:\n",
    "            try:\n",
    "                possible_set[xx]\n",
    "            except:\n",
    "                possible_set[xx] = set()\n",
    "            possible_set[xx].add(i)\n",
    "            possible_set[xx].add(j+i+1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_set = set()\n",
    "for x in possible_set.values():\n",
    "    for y in x:\n",
    "        ind_set.add(y)\n",
    "ind_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_list = list(filter(lambda x:x is not None,[x[0] if i not in ind_set else None for i,x in enumerate(all_parallel_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_set = {}\n",
    "for i,x in enumerate(all_parallel_test[:-1]):\n",
    "    for j,y in enumerate(all_parallel_test[i+1:]):\n",
    "        temp_intersect = set(x[0]).intersection(y[0])\n",
    "        print(i,j+i+1,temp_intersect)\n",
    "        for xx in temp_intersect:\n",
    "            try:\n",
    "                possible_set[xx]\n",
    "            except:\n",
    "                possible_set[xx] = set()\n",
    "            possible_set[xx].add(i)\n",
    "            possible_set[xx].add(j+i+1)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set = set()\n",
    "intertwined_set = []\n",
    "for x,xx in possible_set.items():\n",
    "    temp_combined = []\n",
    "    if tuple(xx) not in temp_set:\n",
    "        #temp_combined = [(x,xx,[all_parallel_test[xi] for xi in xx])] \n",
    "        temp_combined = [(x,xx)] \n",
    "        temp_set.add(tuple(xx))   \n",
    "        for y,yy in possible_set.items():\n",
    "            if x!=y:\n",
    "                if tuple(yy) not in temp_set:\n",
    "                    if len(set(xx).intersection(yy))>0:\n",
    "                        #temp_combined.append((y,yy,[all_parallel_test[xi] for xi in yy]))\n",
    "                        temp_combined.append((y,yy))\n",
    "                        temp_set.add(tuple(yy))\n",
    "    if len(temp_combined)>0:\n",
    "        intertwined_set.append(temp_combined)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_check(next_set,temp,result=[]):\n",
    "    #print(temp,next_set)\n",
    "    if len(temp)==0:\n",
    "        return\n",
    "    for i,x in enumerate(next_set):\n",
    "        temp_set = set.intersection(*map(set,[temp,x]))\n",
    "        print(\"intersection\",temp_set)\n",
    "        if len(temp_set)>0:            \n",
    "            result.append(temp_set)\n",
    "        if i<len(next_set)-1 and len(temp_set)>0:\n",
    "            intersection_check(next_set[1:],temp_set,result)\n",
    "\n",
    "ind_intertw = []\n",
    "for x in intertwined_set:    \n",
    "    yy = [y[1] for y in x]\n",
    "    temp_set = set()\n",
    "    for y in yy:\n",
    "        for z in y:\n",
    "            temp_set.add(z)\n",
    "    yy = [all_parallel_test[y][0] for y in temp_set]\n",
    "    \n",
    "    result = []\n",
    "    for y in range(len(yy)-1):\n",
    "        intersection_check(yy[y+1:],yy[y],result)\n",
    "    #print(result)\n",
    "    for y in yy:\n",
    "        yc = y.copy()\n",
    "        for r in result:\n",
    "            for rr in r:\n",
    "                try:\n",
    "                    yc.remove(rr)\n",
    "                except:\n",
    "                    continue    \n",
    "        #print(\"yc\",yc)\n",
    "        if len(yc)>0:\n",
    "            ind_intertw.append(yc)\n",
    "\n",
    "    for r in result:\n",
    "        for y in yy:\n",
    "            is_int = len(r-set(y))==0\n",
    "            if is_int:\n",
    "                temp_int = []\n",
    "                for yi in y:\n",
    "                    if yi in r:\n",
    "                        temp_int.append(yi)\n",
    "                ind_intertw.append(temp_int)\n",
    "                break\n",
    "\n",
    "    #print(yy)\n",
    "    #print(set.intersection(*map(set,yy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parallel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_intertw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_combined = ind_intertw + ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_combined = list(cluster.values())\n",
    "ind_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_parallel = []\n",
    "for x in ind_combined:\n",
    "    #it_process = [(y,process[y][\"op\"],process[y][\"annotation\"],process[y][\"input\"],process[y][\"output\"]) for y in x]\n",
    "    it_process = []\n",
    "    for y in x:\n",
    "        try:\n",
    "            it_process.append((y,process[y][\"op\"],process[y][\"annotation\"],process[y][\"input\"],process[y][\"output\"]))\n",
    "        except:\n",
    "            it_process.append((y,\"single-op\",\"single-op\",process[y][\"input\"],process[y][\"output\"]))\n",
    "    #print(it_process)\n",
    "    temp = it_process[0][2]\n",
    "    temp_y = it_process[0]\n",
    "    #print(\"tt\",it_process)\n",
    "    let_temp = []\n",
    "    details = []\n",
    "    #print(len(it_process))\n",
    "    if len(it_process)==1:\n",
    "        let_temp = [(temp_y,None,details)]\n",
    "    else:\n",
    "        #print(temp_y[0])\n",
    "        test_break = False\n",
    "        is_collapsed = False        \n",
    "        if temp_y[0]==\"state_14\":\n",
    "            print(it_process)\n",
    "            test_break = True\n",
    "        for y in it_process[1:]:\n",
    "            #if test_break:\n",
    "            #    print(y,temp,let_temp)\n",
    "            if temp!=y[2]:            \n",
    "                let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "                temp = y[2]\n",
    "                temp_y = y\n",
    "                details = []\n",
    "                is_collapsed = False        \n",
    "            else:\n",
    "                details.append(y)\n",
    "                is_collapsed = True\n",
    "        if is_collapsed:\n",
    "            let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "        if len(details)==0 and not is_collapsed:\n",
    "            let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "        #print(let_temp)        \n",
    "    detail_parallel.append(let_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes = [node for node, outdegree in dict(parallel_graph.out_degree(parallel_graph.nodes())).items() if outdegree == 0]\n",
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "\n",
    "all_parallel_test = []\n",
    "for x in source_nodes: \n",
    "    all_parallel_test.extend(parallel_state(parallel_graph,x)[1])\n",
    "\n",
    "import networkx as nx\n",
    "state_graph = nx.DiGraph()\n",
    "for x in all_parallel_test:\n",
    "    #print(x[0])\n",
    "    if len(x[0])>1:\n",
    "        for i,y in enumerate(x[0][:-1]):\n",
    "            state_graph.add_edge(y,x[0][i+1])\n",
    "    else:\n",
    "        #print(y)\n",
    "        state_graph.add_node(x[0][0])\n",
    "\n",
    "end_sink_nodes = [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree == 0]\n",
    "start_source_nodes = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree == 0]\n",
    "end_split =  [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree > 1]\n",
    "start_split =   list(set([x[1] for x in state_graph.out_edges(end_split)]))\n",
    "start_merge = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree > 1]\n",
    "end_merge =   list(set([x[0] for x in state_graph.in_edges(start_merge)]))\n",
    "\n",
    "\n",
    "start_points = start_source_nodes+start_split+start_merge\n",
    "end_points = end_sink_nodes+end_split+end_merge\n",
    "\n",
    "cluster = {}\n",
    "for x in start_points:\n",
    "    for y in end_points:\n",
    "        try:\n",
    "            #print(x)\n",
    "            ps = nx.shortest_path(state_graph,x,y)\n",
    "            try:\n",
    "                if len(ps) < len(cluster[ps[-1]]):\n",
    "                    cluster[ps[-1]] = ps\n",
    "            except:\n",
    "                cluster[ps[-1]] = ps\n",
    "            #print(ps)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "ind_combined = list(cluster.values())\n",
    "\n",
    "detail_parallel = []\n",
    "for x in ind_combined:\n",
    "    #it_process = [(y,process[y][\"op\"],process[y][\"annotation\"],process[y][\"input\"],process[y][\"output\"]) for y in x]\n",
    "    it_process = []\n",
    "    for y in x:\n",
    "        try:\n",
    "            it_process.append((y,process[y][\"op\"],process[y][\"annotation\"],process[y][\"input\"],process[y][\"output\"]))\n",
    "        except:\n",
    "            it_process.append((y,\"single-op\",\"single-op\",process[y][\"input\"],process[y][\"output\"]))\n",
    "    #print(it_process)\n",
    "    temp = it_process[0][2]\n",
    "    temp_y = it_process[0]\n",
    "    #print(\"tt\",it_process)\n",
    "    let_temp = []\n",
    "    details = []\n",
    "    #print(len(it_process))\n",
    "    if len(it_process)==1:\n",
    "        let_temp = [(temp_y,None,details)]\n",
    "    else:\n",
    "        #print(temp_y[0])\n",
    "        test_break = False\n",
    "        is_collapsed = False        \n",
    "        if temp_y[0]==\"state_14\":\n",
    "            print(it_process)\n",
    "            test_break = True\n",
    "        for y in it_process[1:]:\n",
    "            #if test_break:\n",
    "            #    print(y,temp,let_temp)\n",
    "            if temp!=y[2]:            \n",
    "                let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "                temp = y[2]\n",
    "                temp_y = y\n",
    "                details = []\n",
    "                is_collapsed = False        \n",
    "            else:\n",
    "                details.append(y)\n",
    "                is_collapsed = True\n",
    "        if is_collapsed:\n",
    "            let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "        if len(details)==0 and not is_collapsed:\n",
    "            let_temp.append((temp_y,details[-1][4] if len(details)>0 else None,details))\n",
    "        #print(let_temp)        \n",
    "    detail_parallel.append(let_temp)\n",
    "\n",
    "collapsed_process = {}\n",
    "skip_orphan_nodes = False\n",
    "for x in detail_parallel:\n",
    "    if (len(x)==1) and (len(x[0][2])!=2) and skip_orphan_nodes :\n",
    "        continue    \n",
    "    for y in x:           \n",
    "        print(y[0][0])\n",
    "        group_process = y[2]\n",
    "        group_detail = []\n",
    "        try:\n",
    "            temp_process = collapsed_process[y[0][0]]\n",
    "        except:\n",
    "            temp_process = process[y[0][0]].copy()\n",
    "        if len(group_process)>0:\n",
    "            temp_process[\"output\"] = group_process[-1][4]\n",
    "            #temp_process[\"desc\"] = \"group {} {} processes\".format(temp_process[\"annotation\"],len(group_process)+1)\n",
    "            temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            #print(group_process[-1][4])            \n",
    "        collapsed_process[y[0][0]] = temp_process\n",
    "        \n",
    "import itertools\n",
    "\n",
    "\n",
    "def lookup(iterable, length):\n",
    "    tees = itertools.tee(iterable, length)\n",
    "    for i, t in enumerate(tees):\n",
    "        for _ in range(i):\n",
    "            next(t, None)\n",
    "    return zip(*tees)\n",
    "\n",
    "def has_sequence(array, sequence):\n",
    "    sequence = tuple(sequence)\n",
    "    group_index = []\n",
    "    j = 0\n",
    "    for i,group in enumerate(lookup(array, len(sequence))):\n",
    "        #if j>0:\n",
    "        #    j-=1\n",
    "        #    continue\n",
    "        if group == sequence:\n",
    "            #print(i,array,group)\n",
    "            #array=array[i+len(group):]\n",
    "            #group_index.append((i,array,group))\n",
    "            #j=len(group)\n",
    "            return [i,array,group]\n",
    "        \n",
    "    #return any(group == sequence for group in lookup(array, len(sequence)))\n",
    "    return None\n",
    "\n",
    "\n",
    "all_new_proc = []\n",
    "all_det_proc = []\n",
    "for x in detail_parallel:\n",
    "    proces_det = [y[0][2] for y in x]\n",
    "    j=0\n",
    "    new_proc = []\n",
    "    det_proc = []\n",
    "    for i,y in enumerate(sub_workflow):\n",
    "        sequence = has_sequence(proces_det[j:],y)\n",
    "        if sequence!=None:\n",
    "            sequence[0] = sequence[0]+j\n",
    "            sequence[1] = proces_det\n",
    "            print(sequence)\n",
    "            new_proc = new_proc + proces_det[j:sequence[0]] + [\"sub_process_{}\".format(i)]\n",
    "            det_proc = det_proc + x[j:sequence[0]] + [ ((\"sub_process_{}\".format(i),x[j+sequence[0]:(j+sequence[0]+len(sequence[2]))]),) ]\n",
    "            j+=sequence[0]+len(sequence[2])\n",
    "    if j == 0:\n",
    "        new_proc = proces_det\n",
    "        det_proc = x\n",
    "    else:\n",
    "        new_proc = new_proc + proces_det[j:]\n",
    "        det_proc = det_proc + x[j:]\n",
    "    all_new_proc.append(new_proc)\n",
    "    all_det_proc.append(det_proc)\n",
    "\n",
    "\n",
    "freq_pattern_process = {}\n",
    "for x in all_det_proc:\n",
    "    # skip orphan process\n",
    "    if (len(x)==1) and (len(x[0][0])!=2) and skip_orphan_nodes :\n",
    "        continue\n",
    "    for y in x:           \n",
    "        state = y[0][0]\n",
    "        #print(state)\n",
    "        # check freq_pattern_output\n",
    "        #if len(y[0])\n",
    "        #print(state)\n",
    "        #if state==\"sub_process_1\":\n",
    "        #    break\n",
    "        if len(y[0]) == 2:\n",
    "            first_process = y[0][1][0]\n",
    "            #print(first_process)\n",
    "            temp_process = process[first_process[0][0]].copy()\n",
    "            last_process = y[0][1][-1]\n",
    "            group_process = last_process[2]\n",
    "            #group_process = last_process[0]\n",
    "            if len(group_process)>0:\n",
    "                temp_process[\"output\"] = group_process[-1][4]                \n",
    "            else:\n",
    "                temp_process[\"output\"] = last_process[0][4]\n",
    "\n",
    "            #if len(group_process)>0:\n",
    "            #        temp_process[\"output\"] = group_process[-1][4]\n",
    "            \n",
    "            if state==\"sub_process_1\":\n",
    "                print(group_process)\n",
    "\n",
    "            \"\"\"\n",
    "            inside_group = []\n",
    "            for z in y[0][1]:\n",
    "                inside_state = z[0][0]\n",
    "                group_process = z[2]\n",
    "                temp_process = process[inside_state].copy()\n",
    "                if len(group_process)>0:\n",
    "                    temp_process[\"group_process\"] = [z[0]] + group_process\n",
    "                inside_group.append(temp_process)\n",
    "            \n",
    "            temp_process[\"inside_group\"] = inside_group\n",
    "            \"\"\"\n",
    "            \n",
    "            temp_process[\"freq_pattern\"] = y[0]\n",
    "            freq_pattern_process[first_process[0][0]] = temp_process\n",
    "        else:\n",
    "            #if state==\"sub_process_1\":\n",
    "            #    print(temp_process)\n",
    "\n",
    "            group_process = y[2]\n",
    "            temp_process = process[state].copy()\n",
    "            if len(group_process)>0:\n",
    "                temp_process[\"output\"] = group_process[-1][4]\n",
    "                temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            freq_pattern_process[state] = temp_process\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        group_process = y[2]\n",
    "        group_detail = []\n",
    "        try:\n",
    "            temp_process = collapsed_process[y[0][0]]\n",
    "        except:\n",
    "            temp_process = process[y[0][0]].copy()\n",
    "        if len(group_process)>0:\n",
    "            temp_process[\"output\"] = group_process[-1][4]\n",
    "            #temp_process[\"desc\"] = \"group {} {} processes\".format(temp_process[\"annotation\"],len(group_process)+1)\n",
    "            temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            #print(group_process[-1][4])            \n",
    "        collapsed_process[y[0][0]] = temp_process\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_process = {}\n",
    "skip_orphan_nodes = False\n",
    "for x in detail_parallel:\n",
    "    if (len(x)==1) and (len(x[0][2])!=2) and skip_orphan_nodes :\n",
    "        continue    \n",
    "    for y in x:           \n",
    "        print(y[0][0])\n",
    "        group_process = y[2]\n",
    "        group_detail = []\n",
    "        try:\n",
    "            temp_process = collapsed_process[y[0][0]]\n",
    "        except:\n",
    "            temp_process = process[y[0][0]].copy()\n",
    "        if len(group_process)>0:\n",
    "            temp_process[\"output\"] = group_process[-1][4]\n",
    "            #temp_process[\"desc\"] = \"group {} {} processes\".format(temp_process[\"annotation\"],len(group_process)+1)\n",
    "            temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            #print(group_process[-1][4])            \n",
    "        collapsed_process[y[0][0]] = temp_process\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_details = {}\n",
    "for x in detail_parallel:\n",
    "    for y in x:\n",
    "        try:\n",
    "            count_details[y[0][2]]\n",
    "        except:\n",
    "            count_details[y[0][2]] = 0\n",
    "        count_details[y[0][2]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "is_recur = True\n",
    "all_n_count = {}\n",
    "while is_recur:\n",
    "    n_count = {}\n",
    "    for x in detail_parallel:\n",
    "        yy = [y[0][2] for y in x]\n",
    "        for y in ngrams(yy,n):\n",
    "            try:\n",
    "                n_count[y]\n",
    "            except:\n",
    "                n_count[y] = 0\n",
    "            n_count[y]+=1\n",
    "    if sum(n_count.values()) == len(n_count.values()):\n",
    "        is_recur=False        \n",
    "    else:\n",
    "        all_n_count[n] = n_count\n",
    "        #print(sum(n_count.values()),len(n_count.values()))\n",
    "        n+=1\n",
    "        #is_recur=False\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_keys = max(all_n_count.keys())\n",
    "filtered_freq = []\n",
    "temp_all_n_count = all_n_count.copy()\n",
    "for x in range(max_keys,0,-1):\n",
    "    temp = filter(lambda x:x[1]>1,list(temp_all_n_count[x].items()))\n",
    "    for y in temp:\n",
    "        for ii in range(x-1,0,-1):\n",
    "            for j in list(ngrams(y[0],x-ii)):\n",
    "                temp_all_n_count[x-ii][j]-=y[1]\n",
    "    print(list(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_items = []\n",
    "for y in [list(x.items()) for x in temp_all_n_count.values()]:\n",
    "    for x in y:\n",
    "        flattened_items.append(x)\n",
    "list(filter(lambda x:x[1]>1,flattened_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ops = []\n",
    "for i,x in enumerate(temp_all_n_count.values()):\n",
    "    if i == 0:\n",
    "        combined_ops.extend(list(filter(lambda x: x[1]> 0, list(x.items()))))\n",
    "    else:\n",
    "        combined_ops.extend(list(filter(lambda x: x[1]> 1, list(x.items()))))\n",
    "combined_ops    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(combined_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_workflow = [x[0] for x in list(filter(lambda x: len(x[0])>1,combined_ops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "is_recur = True\n",
    "all_n_count = {}\n",
    "while is_recur:\n",
    "    n_count = {}\n",
    "    for x in detail_parallel:\n",
    "        yy = [y[0][2] for y in x]\n",
    "        for y in ngrams(yy,n):\n",
    "            try:\n",
    "                n_count[y]\n",
    "            except:\n",
    "                n_count[y] = 0\n",
    "            n_count[y]+=1\n",
    "    if sum(n_count.values()) == len(n_count.values()):\n",
    "        is_recur=False        \n",
    "    else:\n",
    "        all_n_count[n] = n_count\n",
    "        #print(sum(n_count.values()),len(n_count.values()))\n",
    "        n+=1\n",
    "        #is_recur=False\n",
    "\n",
    "max_keys = max(all_n_count.keys())\n",
    "filtered_freq = []\n",
    "temp_all_n_count = all_n_count.copy()\n",
    "for x in range(max_keys,0,-1):\n",
    "    temp = filter(lambda x:x[1]>1,list(temp_all_n_count[x].items()))\n",
    "    for y in temp:\n",
    "        for ii in range(x-1,0,-1):\n",
    "            for j in list(ngrams(y[0],x-ii)):\n",
    "                temp_all_n_count[x-ii][j]-=y[1]\n",
    "    print(list(temp))\n",
    "\n",
    "\n",
    "flattened_items = []\n",
    "for y in [list(x.items()) for x in temp_all_n_count.values()]:\n",
    "    for x in y:\n",
    "        flattened_items.append(x)\n",
    "list(filter(lambda x:x[1]>1,flattened_items))\n",
    "\n",
    "combined_ops = []\n",
    "for i,x in enumerate(temp_all_n_count.values()):\n",
    "    if i == 0:\n",
    "        combined_ops.extend(list(filter(lambda x: x[1]> 0, list(x.items()))))\n",
    "    else:\n",
    "        combined_ops.extend(list(filter(lambda x: x[1]> 1, list(x.items()))))\n",
    "\n",
    "\n",
    "sub_workflow = [x[0] for x in list(filter(lambda x: len(x[0])>1,combined_ops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def lookup(iterable, length):\n",
    "    tees = itertools.tee(iterable, length)\n",
    "    for i, t in enumerate(tees):\n",
    "        for _ in range(i):\n",
    "            next(t, None)\n",
    "    return zip(*tees)\n",
    "\n",
    "def has_sequence(array, sequence):\n",
    "    sequence = tuple(sequence)\n",
    "    group_index = []\n",
    "    j = 0\n",
    "    for i,group in enumerate(lookup(array, len(sequence))):\n",
    "        #if j>0:\n",
    "        #    j-=1\n",
    "        #    continue\n",
    "        if group == sequence:\n",
    "            #print(i,array,group)\n",
    "            #array=array[i+len(group):]\n",
    "            #group_index.append((i,array,group))\n",
    "            #j=len(group)\n",
    "            return [i,array,group]\n",
    "        \n",
    "    #return any(group == sequence for group in lookup(array, len(sequence)))\n",
    "    return None\n",
    "\n",
    "\n",
    "all_new_proc = []\n",
    "all_det_proc = []\n",
    "for x in detail_parallel:\n",
    "    proces_det = [y[0][2] for y in x]\n",
    "    j=0\n",
    "    new_proc = []\n",
    "    det_proc = []\n",
    "    for i,y in enumerate(sub_workflow):\n",
    "        sequence = has_sequence(proces_det[j:],y)\n",
    "        if sequence!=None:\n",
    "            sequence[0] = sequence[0]+j\n",
    "            sequence[1] = proces_det\n",
    "            print(sequence)\n",
    "            new_proc = new_proc + proces_det[j:sequence[0]] + [\"sub_process_{}\".format(i)]\n",
    "            det_proc = det_proc + x[j:sequence[0]] + [ ((\"sub_process_{}\".format(i),x[j+sequence[0]:(j+sequence[0]+len(sequence[2]))]),) ]\n",
    "            j+=sequence[0]+len(sequence[2])\n",
    "    if j == 0:\n",
    "        new_proc = proces_det\n",
    "        det_proc = x\n",
    "    else:\n",
    "        new_proc = new_proc + proces_det[j:]\n",
    "        det_proc = det_proc + x[j:]\n",
    "    all_new_proc.append(new_proc)\n",
    "    all_det_proc.append(det_proc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_det_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern_process = {}\n",
    "for x in all_det_proc:\n",
    "    # skip orphan process\n",
    "    if (len(x)==1) and (len(x[0][0])!=2) and skip_orphan_nodes :\n",
    "        continue\n",
    "    for y in x:           \n",
    "        state = y[0][0]\n",
    "        #print(state)\n",
    "        # check freq_pattern_output\n",
    "        #if len(y[0])\n",
    "        #print(state)\n",
    "        #if state==\"sub_process_1\":\n",
    "        #    break\n",
    "        if len(y[0]) == 2:\n",
    "            first_process = y[0][1][0]\n",
    "            #print(first_process)\n",
    "            temp_process = process[first_process[0][0]].copy()\n",
    "            last_process = y[0][1][-1]\n",
    "            group_process = last_process[2]\n",
    "            #group_process = last_process[0]\n",
    "            if len(group_process)>0:\n",
    "                temp_process[\"output\"] = group_process[-1][4]                \n",
    "            else:\n",
    "                temp_process[\"output\"] = last_process[0][4]\n",
    "\n",
    "            #if len(group_process)>0:\n",
    "            #        temp_process[\"output\"] = group_process[-1][4]\n",
    "            \n",
    "            if state==\"sub_process_1\":\n",
    "                print(group_process)\n",
    "\n",
    "            \"\"\"\n",
    "            inside_group = []\n",
    "            for z in y[0][1]:\n",
    "                inside_state = z[0][0]\n",
    "                group_process = z[2]\n",
    "                temp_process = process[inside_state].copy()\n",
    "                if len(group_process)>0:\n",
    "                    temp_process[\"group_process\"] = [z[0]] + group_process\n",
    "                inside_group.append(temp_process)\n",
    "            \n",
    "            temp_process[\"inside_group\"] = inside_group\n",
    "            \"\"\"\n",
    "            \n",
    "            temp_process[\"freq_pattern\"] = y[0]\n",
    "            freq_pattern_process[first_process[0][0]] = temp_process\n",
    "        else:\n",
    "            #if state==\"sub_process_1\":\n",
    "            #    print(temp_process)\n",
    "\n",
    "            group_process = y[2]\n",
    "            temp_process = process[state].copy()\n",
    "            if len(group_process)>0:\n",
    "                temp_process[\"output\"] = group_process[-1][4]\n",
    "                temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            freq_pattern_process[state] = temp_process\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        group_process = y[2]\n",
    "        group_detail = []\n",
    "        try:\n",
    "            temp_process = collapsed_process[y[0][0]]\n",
    "        except:\n",
    "            temp_process = process[y[0][0]].copy()\n",
    "        if len(group_process)>0:\n",
    "            temp_process[\"output\"] = group_process[-1][4]\n",
    "            #temp_process[\"desc\"] = \"group {} {} processes\".format(temp_process[\"annotation\"],len(group_process)+1)\n",
    "            temp_process[\"group_process\"] = [y[0]] + group_process\n",
    "            #print(group_process[-1][4])            \n",
    "        collapsed_process[y[0][0]] = temp_process\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][1][-1][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_proces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pattern_process[\"state_20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_singular = []\n",
    "for y in process.keys():\n",
    "    try:\n",
    "        detail_singular.append((y,process[y][\"op\"],process[y][\"annotation\"],process[y][\"input\"],process[y][\"output\"]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parallel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in detail_parallel:\n",
    "    for y in x:\n",
    "        print(y)\n",
    "        z = y[0]\n",
    "        for zz in z[3]:\n",
    "            mg.add_edge(zz,z[0])\n",
    "        if len(y[2])>0:\n",
    "            for zz in y[2][-1][4]:\n",
    "                print(zz)\n",
    "                mg.add_edge(z[0],zz)\n",
    "        else:\n",
    "            for zz in z[4]:\n",
    "                mg.add_edge(z[0],zz)\n",
    "        #mg.add_edge(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes = [node for node, outdegree in dict(mg.out_degree(mg.nodes())).items() if outdegree == 0]\n",
    "source_nodes = [node for node, indegree in dict(mg.in_degree(mg.nodes())).items() if indegree == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes,source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_par = []\n",
    "for x in [(source, sink) for sink in sink_nodes for source in source_nodes]:\n",
    "    #print(x)\n",
    "    for path in nx.all_simple_paths(mg, source=x[0], target=x[1]):\n",
    "        print(path[0])\n",
    "        path = list(filter(lambda x:x.startswith(\"state\"),path))\n",
    "        print(path)\n",
    "        recipes_par.append(list(filter(lambda x:x!=None,[json.loads(state_cmd[state_cmd.state_id==orpe.get_state_to_step(int(yy.split(\"_\")[-1])-1)].detail.values[0])[\"operation\"] for yy in path])))\n",
    "#recipes_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "\n",
    "jellyfish.levenshtein_distance('abcbab','bcab'),jellyfish.jaro_distance('abcbab','bcab'),jellyfish.hamming_distance('abcbab','bcab'),jellyfish.jaro_similarity('abcbab','bcab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(jellyfish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x:x[-2:]==\"_0\",list(mg.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mg.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_count = {}\n",
    "#for x in detail_parallel:\n",
    "yy = [y[2] for y in detail_singular]\n",
    "for y in ngrams(yy,1):\n",
    "    try:\n",
    "        bigram_count[y]\n",
    "    except:\n",
    "        bigram_count[y] = 0\n",
    "    bigram_count[y]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bigram_count.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bigram_count.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_count = {}\n",
    "for x in detail_parallel:\n",
    "    yy = [y[0][2] for y in x]\n",
    "    for y in ngrams(yy,1):\n",
    "        try:\n",
    "            trigram_count[y]\n",
    "        except:\n",
    "            trigram_count[y] = 0\n",
    "        trigram_count[y]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_count = {}\n",
    "for x in detail_parallel:\n",
    "    yy = [y[0][2] for y in x]\n",
    "    for y in ngrams(yy,4):\n",
    "        try:\n",
    "            fourgram_count[y]\n",
    "        except:\n",
    "            fourgram_count[y] = 0\n",
    "        fourgram_count[y]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(all_parallel_test[9][1]) - set(all_parallel_test[10][1]),set(all_parallel_test[10][1]) - set(all_parallel_test[9][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_set = {}\n",
    "for i,x in enumerate(all_parallel_test[:-1]):\n",
    "    for j,y in enumerate(all_parallel_test[i+1:]):\n",
    "        temp_intersect = set(x[0]).intersection(y[0])\n",
    "        print(i,j+i+1,temp_intersect)\n",
    "        for xx in temp_intersect:\n",
    "            try:\n",
    "                possible_set[xx]\n",
    "            except:\n",
    "                possible_set[xx] = set()\n",
    "            possible_set[xx].add(i)\n",
    "            possible_set[xx].add(j+i+1)\n",
    "                         \n",
    "class TraceTicker:\n",
    "    ticker = -1\n",
    "    def __init__(self,path,possible_set,id):\n",
    "        self.path = path\n",
    "        #print(self.path)\n",
    "        self.len_path = len(path)\n",
    "        self.possible_set = possible_set\n",
    "        self.id = id\n",
    "\n",
    "    def is_end_ticker(self):\n",
    "        #print(self.len_path, self.ticker)\n",
    "        if self.len_path-1 == self.ticker:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def next_pos_ticker(self):\n",
    "        try:\n",
    "            self.possible_set[self.path[self.ticker+1]].remove(self.id)\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return self.path[self.ticker+1]\n",
    "\n",
    "    def move_up_ticker(self):\n",
    "        is_pass = False\n",
    "        #print(self.is_end_ticker())\n",
    "        if (not self.is_end_ticker()):\n",
    "            if not self.next_pos_ticker():\n",
    "                return None\n",
    "\n",
    "        try:\n",
    "            is_pass = len(self.possible_set[self.path[self.ticker+1]]) == 0            \n",
    "        except:\n",
    "            #if no lock\n",
    "            is_pass = True            \n",
    "\n",
    "        #print(is_pass,self.is_end_ticker)\n",
    "\n",
    "        if (not self.is_end_ticker()) and is_pass:\n",
    "            self.ticker+=1\n",
    "            return self.path[self.ticker]\n",
    "\n",
    "ticker = [TraceTicker(x[0],possible_set,id) for id,x in  enumerate(all_parallel_test)]\n",
    "# check end condition\n",
    "end_condition = np.sum([x.is_end_ticker() for x in ticker])\n",
    "\n",
    "\n",
    "trace_ticker = set()\n",
    "\n",
    "combined_recipe = []\n",
    "\n",
    "\n",
    "while not end_condition:\n",
    "    for id,x in enumerate(ticker):\n",
    "        xx = x.move_up_ticker()\n",
    "        #print(xx)\n",
    "        if xx != None:\n",
    "            if xx not in trace_ticker:\n",
    "                trace_ticker.add(xx)\n",
    "                #print(id,xx)\n",
    "                combined_recipe.append(xx)\n",
    "    end_condition = np.sum([x.is_end_ticker() for x in ticker]) == len(ticker)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker[3].move_up_ticker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cmd = orpe.get_all_state_command()\n",
    "temp_path_recipe = list(filter(lambda x:x!=None,[json.loads(state_cmd[state_cmd.state_id==orpe.get_state_to_step(int(yy.split(\"_\")[-1])-1)].detail.values[0])[\"operation\"] for yy in combined_recipe]))\n",
    "temp_path_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parallel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_path = nx.all_simple_paths(parallel_graph, source=\"col3_0\", target=\"col10_0\")\n",
    "#list(all_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallel_state(parallel_graph,\"col3_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cmd = orpe.get_all_state_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "\n",
    "for x in source_nodes:\n",
    "    if x.startswith(\"col\"):\n",
    "        test = parallel_state(parallel_graph,x)\n",
    "        print(x,parallel_state(parallel_graph,x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_recipe = test[1]\n",
    "#set(atomic_recipe[1]).intersection(atomic_recipe[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = [node for node, indegree in dict(parallel_graph.in_degree(parallel_graph.nodes())).items() if indegree == 0]\n",
    "source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.dfs_successors(parallel_graph,\"col3_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = parallel_graph.nodes(data=True)\n",
    "graph_dict[\"state_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_graph = nx.DiGraph()\n",
    "all_path = nx.dfs_successors(parallel_graph,\"col3_0\")\n",
    "for key,val in all_path.items():\n",
    "    if key.startswith(\"state\"):\n",
    "        try:\n",
    "            for vv in all_path[key]:\n",
    "                for jj in all_path[vv]:            \n",
    "                    state_graph.add_edge(key,jj)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(state_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_nodes = [node for node, outdegree in dict(state_graph.out_degree(state_graph.nodes())).items() if outdegree == 0]\n",
    "source_nodes = [node for node, indegree in dict(state_graph.in_degree(state_graph.nodes())).items() if indegree == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = []\n",
    "for x in [(source, sink) for sink in sink_nodes for source in source_nodes]:\n",
    "    for path in nx.all_simple_paths(state_graph, source=x[0], target=x[1]):\n",
    "        #print(path)\n",
    "        recipes.append(list(filter(lambda x:x!=None,[json.loads(state_cmd[state_cmd.state_id==orpe.get_state_to_step(int(yy.split(\"_\")[-1])-1)].detail.values[0])[\"operation\"] for yy in path])))\n",
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_column_at_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(nodes_def+edge_def+\"\\n}\")\n",
    "from graphviz import Source\n",
    "\n",
    "temp = nodes_def+edge_def+\"\\n}\"\n",
    "s = Source(temp)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select recipe based on column\n",
    "def reuse_recipe(col_id):\n",
    "    state_dep = orpe.get_state_dependency(orpe.get_column_dependency(col_id).state.tolist())\n",
    "    print(\",\".join([str(x) for x in state_dep.dep_state.unique()]))\n",
    "    state_det = pd.read_sql(\"select * from state_detail where state_id in ({})\".format(\",\".join([str(orpe.get_step_to_state(x)+1) for x in state_dep.dep_state.unique()])),orpe.conn) #orpe.conn reuse_recipe(3).state.unique()\n",
    "    state_det = {x.state_id:json.loads(x.detail)[\"operation\"] for x in state_det[[\"detail\",\"state_id\"]].to_records()}\n",
    "    #print(state_det)\n",
    "    state_list = []\n",
    "    state_ids = []\n",
    "    for x in orpe.get_state_order().sort_values(\"ord\",ascending=False).to_records():\n",
    "        try:\n",
    "            #print(state_det[x.state_id])\n",
    "            state_list.append(state_det[x.state_id])\n",
    "            state_ids.append(x.state_id)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #state_list = list(filter(lambda x: x!=None,[json.loads(x)[\"operation\"] for x in state_det.detail]))\n",
    "    return state_list,state_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test = reuse_recipe(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dep = orpe.get_state_dependency(orpe.get_column_dependency(3).state.tolist())\n",
    "for x in set(state_dep[\"input_column\"]):\n",
    "    print(x)\n",
    "    test = reuse_recipe(x)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end of reusable recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dep = orpe.get_state_dependency(orpe.get_column_dependency(1).state.tolist())\n",
    "state_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_all_column_dependency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_def = \"\"\"\n",
    "digraph \"[stackcollapse]\" {\n",
    "node [style=filled fillcolor=\"#f8f8f8\"]\n",
    "\"\"\"\n",
    "\n",
    "edge_def = \"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "col_order = {}\n",
    "\n",
    "params = set()\n",
    "process = {}\n",
    "\n",
    "max_state = orpe.get_number_of_state()\n",
    "\n",
    "for x in state_col_dep.to_records():\n",
    "    xx = json.loads(x.detail)\n",
    "\n",
    "    real_state = max_state.values[0][0]-x.state_id    \n",
    "    prev_state = max_state.values[0][0]-x.prev_state_id\n",
    "\n",
    "    if real_state == 0:\n",
    "        input_name = \"tableoriginal\"\n",
    "    else:\n",
    "        input_name = \"table{}\".format(real_state) \n",
    "\n",
    "    process[\"state{}\".format(prev_state)] = {}\n",
    "    process[\"state{}\".format(prev_state)][\"input\"] = input_name\n",
    "    process[\"state{}\".format(prev_state)][\"output\"] = \"table{}\".format(prev_state)\n",
    "    process[\"state{}\".format(prev_state)][\"desc\"] = xx[\"description\"]\n",
    "    try:\n",
    "        process[\"state{}\".format(prev_state)][\"op\"] = xx[\"operation\"][\"op\"]\n",
    "        process[\"state{}\".format(prev_state)][\"operation\"] = xx[\"operation\"]\n",
    "    except:\n",
    "        pass\n",
    "    print(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_def = \"\"\"\n",
    "digraph \"[stackcollapse]\" {\n",
    "node [style=filled fillcolor=\"#f8f8f8\"]\n",
    "\"\"\"\n",
    "\n",
    "edge_def = \"\"\n",
    "\n",
    "isinput = set()\n",
    "\n",
    "for key,val in process.items():\n",
    "    temp_desc = \"{state}\\\\n\".format(state=key)\n",
    "    try:\n",
    "        temp_desc += val[\"op\"] +\"\\\\n\"\n",
    "    except:\n",
    "        pass\n",
    "    temp_desc += val[\"desc\"]\n",
    "    nodes_def+=\"\"\"\n",
    "        {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=box tooltip=\"{tt}\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "    \"\"\".format(x=key,label=temp_desc.replace('\"',\"'\"),id=key,tt=\"\")\n",
    "    if val[\"input\"] not in isinput:\n",
    "        nodes_def+=\"\"\"\n",
    "            {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "        \"\"\".format(x=val[\"input\"],label=val[\"input\"].replace('\"',\"'\"),id=key,tt=\"\")\n",
    "        isinput.add(val[\"input\"])\n",
    "    if val[\"output\"] not in isinput:\n",
    "        nodes_def+=\"\"\"\n",
    "            {x} [label=\"{label}\" id=\"{id}\" fontsize=18 shape=oval tooltip=\"\" color=\"#b20400\" fillcolor=\"#edd6d5\"]\n",
    "        \"\"\".format(x=val[\"output\"],label=val[\"output\"].replace('\"',\"'\"),id=key,tt=\"\")\n",
    "        isinput.add(val[\"output\"])\n",
    "    edge_def+=\"\"\"\n",
    "        {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "    \"\"\".format(input=val[\"input\"],output=key,data=\"\")\n",
    "    edge_def+=\"\"\"\n",
    "        {input} -> {output} [label=\"{data}\" weight=14 color=\"#b26e37\" tooltip=\"\" labeltooltip=\"\"]    \n",
    "    \"\"\".format(input=key,output=val[\"output\"],data=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "linear_recipe = orpe.get_linear_recipe()\n",
    "\n",
    "params = set()\n",
    "process = {}\n",
    "\n",
    "max_state = orpe.get_number_of_state()\n",
    "\n",
    "for x in linear_recipe.to_records():\n",
    "    xx = json.loads(x.detail)\n",
    "\n",
    "    if x.prev_state_id == -1:\n",
    "        input_name = \"table-original\"\n",
    "    else:\n",
    "        input_name = \"table-{}\".format(x.prev_state_id) \n",
    "\n",
    "    process[\"state-{}\".format(x.state_id)] = {}\n",
    "    process[\"state-{}\".format(x.state_id)][\"input\"] = input_name\n",
    "    process[\"state-{}\".format(x.state_id)][\"output\"] = \"table-{}\".format(x.state_id)\n",
    "    process[\"state-{}\".format(x.state_id)][\"desc\"] = xx[\"description\"]\n",
    "    try:\n",
    "        process[\"state-{}\".format(x.state_id)][\"op\"] = xx[\"operation\"][\"op\"]\n",
    "        process[\"state-{}\".format(x.state_id)][\"operation\"] = xx[\"operation\"]\n",
    "    except:\n",
    "        pass\n",
    "    print(xx)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#@begin Linear_OR #@desc Linear OpenRefine Workflow\n",
    "#@param col-name:\\nevent\n",
    "#@param GRELEXPRESSION:\\ngrel:cells.year.value+'-'+cells.month.value+'-'+cells.day.value\n",
    "#@param newColumnName:\\nday\n",
    "#@param separator:\\n\"-\"\n",
    "#@param col-name:\\ndate\n",
    "#@param oldColumnName:\\ndate_2\n",
    "#@param col-name:\\nyear\n",
    "#@param InsertPosition:\\n13\n",
    "#@param oldColumnName:\\ndate_3\n",
    "#@param newColumnName:\\nyear\n",
    "#@param newColumnName:\\nmonth\n",
    "#@param newColumnName:\\nrepaired_date\n",
    "#@param EXPRESSION:\\nvalue.toNumber()\n",
    "#@param EXPRESSION:\\nvalue.toUppercase()\n",
    "#@param removeOriginalColumn:\\nTrue\n",
    "#@param col-name:\\ndish_count\n",
    "#@param oldColumnName:\\ndate_1\n",
    "#@in table0\n",
    "#@out table8\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize linear workflow\n",
    "\n",
    "output_trace = []\n",
    "for i,x in enumerate(dep_state[1:]):\n",
    "    dep_x = all_dep[all_dep.state==x]\n",
    "    #print(dep_x)\n",
    "    for y in dep_x[[\"input_column\",\"output_column\"]].to_records():\n",
    "        xx_input = xx_hist[y.input_column]\n",
    "        xx_output = xx_hist[y.output_column]\n",
    "        #print(dep_state[i-1],x)\n",
    "        #print(\"input\",xx_input[xx_input.state==dep_state[(i+1)-1]])\n",
    "        #print(\"output\",xx_output[xx_output.state==x])\n",
    "        output_trace.append((dep_state[(i+1)-1],x,y.input_column,y.output_column,xx_input[xx_input.state==dep_state[(i+1)-1]],xx_output[xx_output.state==x]))\n",
    "    #print(dep_x)\n",
    "\n",
    "from graphviz import Source\n",
    "temp = \"\"\"\n",
    "digraph {\n",
    "rankdir=TB;\n",
    "node [ shape=record ];\n",
    "splines=\"line\";\n",
    "\"\"\"\n",
    "s_coll=\"\"\n",
    "s_port=\"\"\n",
    "is_processed = []\n",
    "\n",
    "s_ah = {}\n",
    "for s in output_trace:\n",
    "    try:\n",
    "        s_ah[s[0]]\n",
    "    except:\n",
    "        s_ah[s[0]] = []\n",
    "    s_ah[s[0]].append(s)\n",
    "    if s[0]>0:\n",
    "        try:\n",
    "            s_ah[s[0]-1]\n",
    "        except:\n",
    "            s_ah[s[0]-1] = []\n",
    "        s_ah[s[0]-1].append(s)\n",
    "\n",
    "        \n",
    "#print(s_ah)\n",
    "\n",
    "s0_s1_rel = []\n",
    "\n",
    "for s in output_trace:\n",
    "    s0 = s[0]\n",
    "    s1 = s[1]\n",
    "    row_logic_s0 = self.get_row_at_state_order(s0)\n",
    "    row_logic_s1 = self.get_row_at_state_order(s1)\n",
    "    \n",
    "    s0_ex_col = False\n",
    "    s1_ex_col =False\n",
    "\n",
    "    if col in self.get_col_at_state_order(s0).col_id.values:\n",
    "        s0_ex_col = True\n",
    "    \n",
    "    if col in self.get_col_at_state_order(s1).col_id.values:\n",
    "        s1_ex_col = True\n",
    "\n",
    "    if s0 not in is_processed:\n",
    "        col_port = []\n",
    "        for x in self.get_col_at_state_order(s0).to_records():\n",
    "            is_ss = False\n",
    "            for ss in s_ah[s0]:\n",
    "                if (x.col_id==col):\n",
    "                    xx_col = xx_hist[col]\n",
    "                    #print(xx_col)\n",
    "                    #xx_col = xx_col[xx_col.state_id==self.get_state_to_step(ss[0])]\n",
    "                    xx_col = xx_col[xx_col.state==s0]\n",
    "                    #print(xx_col)\n",
    "                    xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=xx_col.value_text.values[0],row=row_logic_s1[row_logic_s1.row_id==row].level.values[0])\n",
    "                    is_ss = True\n",
    "                elif (x.col_id==ss[4].col_id.values[0]):\n",
    "                    xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=ss[4].value_text.values[0],row=row_logic_s0[row_logic_s0.row_id==row].level.values[0])\n",
    "                    #xx = \"{{<port{col_id}>{col_name}|row:{row}|<port{col_id}>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=ss[4].value_text.values[0],row=row_logic_s0.iloc[row].row_id)\n",
    "                    is_ss = True\n",
    "\n",
    "            #print(x.col_id)\n",
    "\n",
    "            if not is_ss:\n",
    "                #xx = \"{{<port{col_id}>{col_name}}}\".format(col_id=x.col_id,col_name=x.col_name)\n",
    "                xx = \"{{<port{}i>{}|<port{}o>}}\".format(x.col_id,x.col_name,x.col_id)\n",
    "                #xx = \"<port{}>{}\\n{}\".format(x.col_id,x.col_name,s[4].value_text.values[0])\n",
    "            col_port.append(xx)\n",
    "\n",
    "        s_coll+=\"\"\"\n",
    "        subgraph cluster_{step} {{\n",
    "            label=\"step {step}\";\n",
    "\n",
    "            struct{s_num}[\n",
    "                label = \"{s_label}\";\n",
    "            ];\n",
    "        }}\n",
    "        \"\"\".format(step=s[0],s_num=s0,s_label=\"|\".join(col_port))\n",
    "        is_processed.append(s0)\n",
    "\n",
    "    if s1 not in is_processed:\n",
    "        col_port = []\n",
    "        for x in self.get_col_at_state_order(s1).to_records():\n",
    "            is_ss = False\n",
    "            for ss in s_ah[s0]:\n",
    "                if (x.col_id==col):\n",
    "                    xx_col = xx_hist[col]\n",
    "                    #xx_col = xx_col[xx_col.state_id==self.get_state_to_step(ss[0])]\n",
    "                    xx_col = xx_col[xx_col.state==s1]\n",
    "                    #print(xx_col)\n",
    "                    xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=xx_col.value_text.values[0],row=row_logic_s1[row_logic_s1.row_id==row].level.values[0])\n",
    "                    is_ss = True\n",
    "                elif (x.col_id==ss[5].col_id.values[0]):\n",
    "                    #xx = \"{{<port{col_id}>{col_name}|row:{row}|<port{col_id}>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=ss[5].value_text.values[0],row=row_logic_s1.iloc[row].row_id)                                         \n",
    "                    xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=x.col_id,col_name=x.col_name,value=ss[5].value_text.values[0],row=row_logic_s1[row_logic_s1.row_id==row].level.values[0])\n",
    "                    is_ss = True\n",
    "                    \n",
    "                    #xx = \"{{<port{}i>{}|<port{}o>{}}}\".format(x.col_id,x.col_name,x.col_id,s[5].value_text.values[0])\n",
    "                    #xx = \"<port{}>{}\\n{}\".format(x.col_id,x.col_name,s[5].value_text.values[0])\n",
    "\n",
    "            #print(x.col_id)\n",
    "            if x.col_id == col:\n",
    "                s1_ex_col = True\n",
    "\n",
    "            if not is_ss:\n",
    "                #xx = \"{{<port{col_id}>{col_name}}}\".format(col_id=x.col_id,col_name=x.col_name)\n",
    "                xx = \"{{<port{}i>{}|<port{}o>}}\".format(x.col_id,x.col_name,x.col_id)                    \n",
    "\n",
    "            col_port.append(xx)\n",
    "        '''\n",
    "        for x in orpe.get_col_at_state_order(s1).to_records():\n",
    "            xx = \"<port{}>\".format(x.col_id)+x.col_name\n",
    "            col_port.append(xx)\n",
    "        '''\n",
    "        s_coll+=\"\"\"\n",
    "        subgraph cluster_{step} {{\n",
    "            label=\"step {step}\";\n",
    "            struct{s_num}[\n",
    "                label = \"{s_label}\";\n",
    "            ];\n",
    "        }}\n",
    "        \"\"\".format(step=s1,s_num=s1,s_label=\"|\".join(col_port))\n",
    "        is_processed.append(s1)\n",
    "    \n",
    "    \n",
    "    s_port+=\"\"\"\n",
    "    struct{}:port{}o -> struct{}:port{}i [ label=\"{}\" ];\n",
    "    \"\"\".format(s0,s[2],s1,s[3],all_dep[all_dep.state==s1].command.values[0])\n",
    "    s0_s1_rel.append((s0,s[2],s1,s[3]))\n",
    "\n",
    "    #print(col,s0_ex_col,s1_ex_col)\n",
    "\n",
    "    \n",
    "    if s0_ex_col and s1_ex_col and ((s0,col,s1,col) not in s0_s1_rel):\n",
    "        #s_port+=\"\"\"\n",
    "        #struct{}:port{}o -> struct{}:port{}i [ label=\"{}\" ];\n",
    "        #\"\"\".format(s0,col,s1,col,all_dep[all_dep.state==s1].command.values[0])\n",
    "        s_port+=\"\"\"\n",
    "        struct{}:port{}o -> struct{}:port{}i [ label=\"{}\" ];\n",
    "        \"\"\".format(s0,col,s1,col,\"\")\n",
    "        s0_s1_rel.append((s0,col,s1,col))\n",
    "\n",
    "    #print(s0_s1_rel)\n",
    "\n",
    "    '''\n",
    "    s_port+=\"\"\"\n",
    "    struct{source} -> struct{target} [\n",
    "        tailport = port{porto}\n",
    "        headport = port{porti}\n",
    "        label = {label}\n",
    "    ];\n",
    "    \"\"\".format(source=s0,target=s1,porto=s[2],porti=s[3],label=all_dep[all_dep.state==s1].command.values[0])\n",
    "    '''\n",
    "\n",
    "    #if s>0:\n",
    "    #    s_port+=\"\"\"\n",
    "    #    struct{}:port1 -> struct{}:port2 [ label=\"xyz\" ];\n",
    "    #    \"\"\".format(s-1,s)\n",
    "\n",
    "temp+=s_coll\n",
    "temp+=\"\"\"\n",
    "{}\n",
    "}}\n",
    "\"\"\".format(s_port)\n",
    "s = Source(temp)\n",
    "#s.view()\n",
    "#s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(wf),wf.state_viz[0].data_list[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in wf.state_viz:\n",
    "    label = []\n",
    "    for y in x.data_list:\n",
    "        if y.is_used:\n",
    "            xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=y.col_id,col_name=y.col_name,value=y.value,row=y.row)\n",
    "        else:\n",
    "            #xx = \"{{<port{col_id}i>{col_name}|row:{row}|<port{col_id}o>{value}}}\".format(col_id=y.col_id,col_name=y.col_name,value=y.value,row=y.row)\n",
    "            xx = \"{{<port{col_id}>{col_name}}}\".format(col_id=y.col_id,col_name=y.col_name,value=y.value,row=y.row)\n",
    "        label.append(xx)\n",
    "\n",
    "    s_coll = \"\"\n",
    "    s_coll+=\"\"\"\n",
    "    subgraph cluster_{step} {{\n",
    "        label=\"step {step}\";\n",
    "\n",
    "        struct{s_num}[\n",
    "            label = \"{s_label}\";\n",
    "        ];\n",
    "    }}\n",
    "    \"\"\".format(step=x.step,s_num=x.step_id,s_label=\"|\".join(label))\n",
    "    print(s_coll)\n",
    "\n",
    "    \n",
    "for x in wf.relation:    \n",
    "    s_port=\"\"\"\n",
    "    struct{}:port{}o -> struct{}:port{}i [ label=\"{}\" ];\n",
    "    \"\"\".format(x.input_step,x.input_col,x.output_col,x.output_col,x.relation)\n",
    "    print(s_port)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = wf.state_viz[0]\n",
    "tt = tt.data_list[0]\n",
    "tt.col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "temp = \"\"\"\n",
    "digraph {\n",
    "rankdir=TB;\n",
    "node [ shape=record ];\n",
    "splines=\"line\";\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.state_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "db_files = []\n",
    "for x in os.listdir():\n",
    "    if x.endswith(\".db\"):\n",
    "        db_files.append(x)\n",
    "\n",
    "global orpe,num_state\n",
    "\n",
    "@interact\n",
    "def interactive_form(file=db_files):\n",
    "    global orpe,num_state\n",
    "    orpe = ProvenanceExplorer(file)\n",
    "    num_state = orpe.get_number_of_state().num_state.values[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(col=\"2\",row=\"2\",step=\"-1\"):\n",
    "    #return df.loc[df[column] > x]\n",
    "    xx = orpe.get_cell_lineage(int(row),int(col))\n",
    "    return xx[1]\n",
    "#orpe.get_changes_each_state(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = orpe.get_cell_lineage(2,1)\n",
    "xx[1].save(\"demo.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[1].render(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(col=\"2\",row=\"3\",step=\"4\"):\n",
    "    #return df.loc[df[column] > x]\n",
    "    xx = orpe.get_cell_lineage(int(row),int(col),int(step))\n",
    "    return xx[1]\n",
    "#orpe.get_changes_each_state(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dep = orpe.get_state_dependency(7)\n",
    "dep_state = state_dep.dep_state.unique()\n",
    "all_dep = orpe.get_all_column_dependency()\n",
    "print(all_dep)\n",
    "state_dep = all_dep[all_dep.state.isin(dep_state)]\n",
    "#print(dep_state)        \n",
    "#xx = state_dep[state_dep.command!=]state_dep[[\"input_column\",\"output_column\"]].values.flatten()\n",
    "xx = state_dep[state_dep.command!=\"ColumnMoveChange\"][[\"input_column\",\"output_column\"]].values.flatten()\n",
    "#xx = state_dep[[\"input_column\",\"output_column\"]].values.flatten()\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_row_logic_to_idx(52,7561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_step_to_state(52)\n",
    "ehe = orpe.get_row_at_state_order(52) #.iloc[5].row_id\n",
    "#ehe[ehe.level==14612]\n",
    "ehe.iloc[14612]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xx[1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orpe.get_state_dependency(55)\n",
    "orpe.get_column_dependency(6).state.tolist()\n",
    "orpe.get_state_dependency(orpe.get_column_dependency(6).state.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=6        \n",
    "col_state_dep = orpe.get_column_dependency(col).state.tolist()\n",
    "state_dep = orpe.get_state_dependency(col_state_dep)\n",
    "state_dep.dep_state.unique()\n",
    "state_dep[[\"input_column\",\"output_column\"]].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = state_dep[[\"input_column\",\"output_column\"]].values.flatten()\n",
    "{x:x for x in xx}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes at state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(start_state=range(0,num_state),end_state=range(0,num_state+2)):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_changes_each_state(range(start_state,end_state+1))\n",
    "#orpe.get_changes_each_state(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Schema changes at state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(start_state=range(0,num_state),end_state=range(0,num_state+2)):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_col_at_state_order(range(start_state,end_state+1))\n",
    "\n",
    "#orpe.get_col_at_state_order(range(2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row order at state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(state_id=range(0,num_state+2)):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_row_at_state_order(state_id)\n",
    "\n",
    "#orpe.get_row_at_state_order(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(col=\"0\",row=\"3\"):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_cell_history(int(row),int(col))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapshot at state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(state=range(0,num_state+2)):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_snapshot_at_state(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "# Create Digraph object\n",
    "dot = Digraph()\n",
    "dot2 = Digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_number_of_state().num_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "temp = \"\"\"\n",
    "digraph {\n",
    "  rankdir=TB;\n",
    "  node [ shape=record ];\n",
    "\"\"\"\n",
    "s_coll=\"\"\n",
    "s_port=\"\"\n",
    "for s in range(0,orpe.get_number_of_state().num_state[0]):    \n",
    "    s_coll+=\"\"\"\n",
    "    struct{s_num}[\n",
    "        label = \"{s_label}\";\n",
    "    ];\n",
    "    \"\"\".format(s_num=s,s_label=\"|\".join(orpe.get_col_at_state_order(s).col_name.tolist()))\n",
    "    if s>0:\n",
    "        s_port+=\"\"\"\n",
    "        struct{}:port1 -> struct{}:port2 [ label=\"xyz\" ];\n",
    "        \"\"\".format(s-1,s)\n",
    "\n",
    "temp+=s_coll\n",
    "temp+=\"\"\"\n",
    "{}\n",
    "}}\n",
    "\"\"\".format(s_port)\n",
    "s = Source(temp)\n",
    "#s.view()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digraph {\n",
    "  rankdir=LR;\n",
    "  node [ shape=record ];\n",
    "\n",
    "  struct1 [\n",
    "      label = \"a|b|<port1>c\";\n",
    "  ];\n",
    "  \n",
    "  struct2 [\n",
    "      label = \"a|{<port2>b1|b2}|c\";\n",
    "  ];\n",
    "  \n",
    "  struct1:port1 -> struct2:port2 [ label=\"xyz\" ];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"|\".join(orpe.get_col_at_state_order(0).col_name.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.subgraph(dot2)\n",
    "dot.node('1')\n",
    "dot.node('2')\n",
    "\n",
    "# Add edge between 1 and 2\n",
    "dot.edges(['12'])\n",
    "dot2.node('1')\n",
    "dot2.node('2')\n",
    "\n",
    "# Add edge between 1 and 2\n",
    "dot2.edges(['12'])\n",
    "dot\n",
    "dot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Graph\n",
    "\n",
    "p = Graph(name='parent')\n",
    "p.edge('spam', 'eggs')\n",
    "\n",
    "c = Graph(name='child', node_attr={'shape': 'box'})\n",
    "c.edge('foo', 'bar')\n",
    "\n",
    "p.subgraph(c)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "temp = \"\"\"\n",
    "digraph G {\n",
    "\n",
    "  subgraph cluster_0 {\n",
    "    style=filled;\n",
    "    color=lightgrey;\n",
    "    node [style=filled,color=white];\n",
    "    a0 -> a1 -> a2 -> a3;\n",
    "    label = \"process #1\";\n",
    "  }\n",
    "\n",
    "  subgraph cluster_1 {\n",
    "    node [style=filled];\n",
    "    b0 -> b1 -> b2 -> b3;\n",
    "    label = \"process #2\";\n",
    "    color=blue\n",
    "  }\n",
    "  start -> a0;\n",
    "  start -> b0;\n",
    "  a1 -> b3;\n",
    "  b2 -> a3;\n",
    "  a3 -> a0;\n",
    "  a3 -> end;\n",
    "  b3 -> end;\n",
    "\n",
    "  start [shape=Mdiamond];\n",
    "  end [shape=Msquare];\n",
    "}\n",
    "\"\"\"\n",
    "s = Source(temp, filename=\"test.gv\", format=\"png\")\n",
    "s.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes 1 and 2\n",
    "dot.node('1')\n",
    "dot.node('2')\n",
    "\n",
    "# Add edge between 1 and 2\n",
    "dot.edges(['12'])\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_col_at_state_order(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_form(x=range(0,num_state),y=range(0,num_state)):\n",
    "    #return df.loc[df[column] > x]\n",
    "    return orpe.get_column_at_state(range(x,y+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = orpe.get_snapshot_at_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_cell_history(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_column_at_state(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_col_at_state_order(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_col_idx_to_logic(8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_col_logic_to_idx(8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = orpe.get_row_at_state(1)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_row_at_state_order(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_row_logic_to_idx(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_row_idx_to_logic(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_values_at_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.row_pos_id.tolist().index(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(orpe.cursor.execute(\"select * from col_each_state where state=8\"))\n",
    "names = list(map(lambda x: x[0], orpe.cursor.description))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = orpe.cursor.execute(\"select * from col_each_state where state=8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpe.get_column_at_state(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31983a5fbf5b1d6811369559b00cd89626668e99993316298c6929be55e73b8d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
